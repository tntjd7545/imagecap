{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "playground.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tntjd7545/imagecap/blob/master/playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "HCfepDSShDn2",
        "colab_type": "code",
        "outputId": "895c603e-c614-4877-a291-4461317b47b2",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/mithi/semantic-segmentation\n",
        "!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_road.zip\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-23 17:40:21--  https://s3.eu-central-1.amazonaws.com/avg-kitti/data_road.zip\n",
            "Resolving s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)... 52.219.72.4\n",
            "Connecting to s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)|52.219.72.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 470992343 (449M) [application/zip]\n",
            "Saving to: ‘data_road.zip’\n",
            "\n",
            "data_road.zip       100%[===================>] 449.17M  11.5MB/s    in 41s     \n",
            "\n",
            "2018-11-23 17:41:04 (10.9 MB/s) - ‘data_road.zip’ saved [470992343/470992343]\n",
            "\n",
            "unzip:  cannot find or open ./data/data_road.zip, ./data/data_road.zip.zip or ./data/data_road.zip.ZIP.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b3274dec-f9f8-430d-b4e7-e55cf05f1451\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b3274dec-f9f8-430d-b4e7-e55cf05f1451\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "jSoey5cyqnbX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "87j0vNhHq59X",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "cbbe213c-99e2-487f-dff1-07f4199e77ce"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6ec71542-fa72-4710-9f94-799949bf3c1b\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-6ec71542-fa72-4710-9f94-799949bf3c1b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving helper.py to helper.py\n",
            "Saving project_tests.py to project_tests.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LRvNDYePrBsk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp data_road.zip ./data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qd82ZRWmrMVh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip ./data/data_road.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jjAVoVXGrd9W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -r ./data_road ./data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ryirWXxuT9zK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os.path\n",
        "import warnings\n",
        "from distutils.version import LooseVersion\n",
        "import glob\n",
        "\n",
        "import helper\n",
        "import project_tests as tests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Nnac2dcT9zx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f3c85c5-7985-4560-ada0-53eab750749d"
      },
      "cell_type": "code",
      "source": [
        "# Check TensorFlow Version\n",
        "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
        "print('TensorFlow Version: {}'.format(tf.__version__))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KOPWBfarT90X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3fbf3d7-b9b0-441c-88f1-73120cec54c4"
      },
      "cell_type": "code",
      "source": [
        "# Check for a GPU\n",
        "if not tf.test.gpu_device_name():\n",
        "  warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
        "else:\n",
        "  print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default GPU Device: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KQxlbiY5T90n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_DIRECTORY = './data'\n",
        "RUNS_DIRECTORY = './runs'\n",
        "TRAINING_DATA_DIRECTORY ='./data/data_road/training'\n",
        "NUMBER_OF_IMAGES = len(glob.glob('./data/data_road/training/calib/*.*'))\n",
        "VGG_PATH = './data/vgg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dZXgCAz5T90-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NUMBER_OF_CLASSES = 2\n",
        "IMAGE_SHAPE = (160, 576)\n",
        "\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "DROPOUT = 0.75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ayh3pv7PT91J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correct_label = tf.placeholder(tf.float32, [None, IMAGE_SHAPE[0], IMAGE_SHAPE[1], NUMBER_OF_CLASSES])\n",
        "learning_rate = tf.placeholder(tf.float32)\n",
        "keep_prob = tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1se4NXZhT91S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Used for plotting to visualize if our training is going well given parameters\n",
        "all_training_losses = [] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LvDq3orZT91c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_vgg(sess, vgg_path):\n",
        "  \"\"\"\n",
        "  Load Pretrained VGG Model into TensorFlow.\n",
        "  sess: TensorFlow Session\n",
        "  vgg_path: Path to vgg folder, containing \"variables/\" and \"saved_model.pb\"\n",
        "  return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3, layer4, layer7)\n",
        "  \"\"\"\n",
        "  # load the model and weights\n",
        "  model = tf.saved_model.loader.load(sess, ['vgg16'], vgg_path)\n",
        "\n",
        "  # Get Tensors to be returned from graph\n",
        "  graph = tf.get_default_graph()\n",
        "  image_input = graph.get_tensor_by_name('image_input:0')\n",
        "  keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
        "  layer3 = graph.get_tensor_by_name('layer3_out:0')\n",
        "  layer4 = graph.get_tensor_by_name('layer4_out:0')\n",
        "  layer7 = graph.get_tensor_by_name('layer7_out:0')\n",
        "\n",
        "  return image_input, keep_prob, layer3, layer4, layer7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PKIS9mevT912",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_1x1(layer, layer_name):\n",
        "  \"\"\" Return the output of a 1x1 convolution of a layer \"\"\"\n",
        "  return tf.layers.conv2d(inputs = layer,\n",
        "                          filters =  NUMBER_OF_CLASSES,\n",
        "                          kernel_size = (1, 1),\n",
        "                          strides = (1, 1),\n",
        "                          name = layer_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8J-oYTAT92F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def upsample(layer, k, s, layer_name):\n",
        "  \"\"\" Return the output of transpose convolution given kernel_size k and strides s \"\"\"\n",
        "  # See: http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html#transposed-convolution-arithmetic\n",
        "  return tf.layers.conv2d_transpose(inputs = layer,\n",
        "                                    filters = NUMBER_OF_CLASSES,\n",
        "                                    kernel_size = (k, k),\n",
        "                                    strides = (s, s),\n",
        "                                    padding = 'same',\n",
        "                                    name = layer_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gVY_h6ZVT92N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes = NUMBER_OF_CLASSES):\n",
        "  \"\"\"\n",
        "  Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\n",
        "  vgg_layerX_out: TF Tensor for VGG Layer X output\n",
        "  num_classes: Number of classes to classify\n",
        "  return: The Tensor for the last layer of output\n",
        "  \"\"\"\n",
        "\n",
        "  # Use a shorter variable name for simplicity\n",
        "  layer3, layer4, layer7 = vgg_layer3_out, vgg_layer4_out, vgg_layer7_out\n",
        "\n",
        "  # Apply a 1x1 convolution to encoder layers\n",
        "  layer3x = conv_1x1(layer = layer3, layer_name = \"layer3conv1x1\")\n",
        "  layer4x = conv_1x1(layer = layer4, layer_name = \"layer4conv1x1\")\n",
        "  layer7x = conv_1x1(layer = layer7, layer_name = \"layer7conv1x1\")\n",
        " \n",
        "  # Add decoder layers to the network with skip connections and upsampling\n",
        "  # Note: the kernel size and strides are the same as the example in Udacity Lectures\n",
        "  #       Semantic Segmentation Scene Understanding Lesson 10-9: FCN-8 - Decoder\n",
        "  decoderlayer1 = upsample(layer = layer7x, k = 4, s = 2, layer_name = \"decoderlayer1\")\n",
        "  decoderlayer2 = tf.add(decoderlayer1, layer4x, name = \"decoderlayer2\")\n",
        "  decoderlayer3 = upsample(layer = decoderlayer2, k = 4, s = 2, layer_name = \"decoderlayer3\")\n",
        "  decoderlayer4 = tf.add(decoderlayer3, layer3x, name = \"decoderlayer4\")\n",
        "  decoderlayer_output = upsample(layer = decoderlayer4, k = 16, s = 8, layer_name = \"decoderlayer_output\")\n",
        "\n",
        "  return decoderlayer_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tiajwWzST92g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def layers_verbose(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes = NUMBER_OF_CLASSES):\n",
        "\n",
        "  # Use a shorter variable name for simplicity\n",
        "  layer3, layer4, layer7 = vgg_layer3_out, vgg_layer4_out, vgg_layer7_out\n",
        "\n",
        "  # Apply a 1x1 convolution to encoder layers\n",
        "  layer3x = conv_1x1(layer = layer3, layer_name = \"layer3conv1x1\")\n",
        "  layer4x = conv_1x1(layer = layer4, layer_name = \"layer4conv1x1\")\n",
        "  layer7x = conv_1x1(layer = layer7, layer_name = \"layer7conv1x1\")\n",
        " \n",
        "  decoderlayer1 = upsample(layer = layer7x, k = 4, s = 2, layer_name = \"decoderlayer1\")\n",
        "  decoderlayer2 = tf.add(decoderlayer1, layer4x, name = \"decoderlayer2\")\n",
        "  decoderlayer3 = upsample(layer = decoderlayer2, k = 4, s = 2, layer_name = \"decoderlayer3\")\n",
        "  decoderlayer4 = tf.add(decoderlayer3, layer3x, name = \"decoderlayer4\")\n",
        "  decoderlayer_output = upsample(layer = decoderlayer4, k = 16, s = 8, layer_name = \"decoderlayer_output\")\n",
        "\n",
        "  return layer3, layer4, layer7, layer3x, layer4x, layer7x, \\\n",
        "         decoderlayer1, decoderlayer2, decoderlayer3, decoderlayer4, decoderlayer_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vDxBr7o4T928",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def optimize(nn_last_layer, correct_label, learning_rate, num_classes = NUMBER_OF_CLASSES):\n",
        "  \"\"\"\n",
        "  Build the TensorFLow loss and optimizer operations.\n",
        "  nn_last_layer: TF Tensor of the last layer in the neural network\n",
        "  correct_label: TF Placeholder for the correct label image\n",
        "  learning_rate: TF Placeholder for the learning rate\n",
        "  num_classes: Number of classes to classify\n",
        "  return: Tuple of (logits, train_op, cross_entropy_loss)\n",
        "  \"\"\"\n",
        "  # reshape 4D tensors to 2D\n",
        "  # Each row represents a pixel, each column a class\n",
        "  logits = tf.reshape(nn_last_layer, (-1, num_classes))\n",
        "  class_labels = tf.reshape(correct_label, (-1, num_classes))\n",
        "\n",
        "  # The cross_entropy_loss is the cost which we are trying to minimize to yield higher accuracy\n",
        "  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = class_labels)\n",
        "  cross_entropy_loss = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "  # The model implements this operation to find the weights/parameters that would yield correct pixel labels\n",
        "  train_op = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy_loss)\n",
        "\n",
        "  return logits, train_op, cross_entropy_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mTNw9GP4T93H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_nn(sess, epochs, batch_size, get_batches_fn, train_op,\n",
        "             cross_entropy_loss, input_image,\n",
        "             correct_label, keep_prob, learning_rate):\n",
        "  \"\"\"\n",
        "  Train neural network and print out the loss during training.\n",
        "  sess: TF Session\n",
        "  epochs: Number of epochs\n",
        "  batch_size: Batch size\n",
        "  get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\n",
        "  train_op: TF Operation to train the neural network\n",
        "  cross_entropy_loss: TF Tensor for the amount of loss\n",
        "  input_image: TF Placeholder for input images\n",
        "  correct_label: TF Placeholder for label images\n",
        "  keep_prob: TF Placeholder for dropout keep probability\n",
        "  learning_rate: TF Placeholder for learning rate\n",
        "  \"\"\"\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    \n",
        "    losses, i = [], 0\n",
        "    \n",
        "    for images, labels in get_batches_fn(BATCH_SIZE):\n",
        "        \n",
        "      i += 1\n",
        "    \n",
        "      feed = { input_image: images,\n",
        "               correct_label: labels,\n",
        "               keep_prob: DROPOUT,\n",
        "               learning_rate: LEARNING_RATE }\n",
        "        \n",
        "      _, partial_loss = sess.run([train_op, cross_entropy_loss], feed_dict = feed)\n",
        "      \n",
        "      print(\"---> iteration: \", i, \" partial loss:\", partial_loss)\n",
        "      losses.append(partial_loss)\n",
        "          \n",
        "    training_loss = sum(losses) / len(losses)\n",
        "    all_training_losses.append(training_loss)\n",
        "    \n",
        "    print(\"------------------\")\n",
        "    print(\"epoch: \", epoch + 1, \" of \", EPOCHS, \"training loss: \", training_loss)\n",
        "    print(\"------------------\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YVBMHFSDT93r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_tests():\n",
        "  tests.test_layers(layers)\n",
        "  tests.test_optimize(optimize)\n",
        "  tests.test_for_kitti_dataset(DATA_DIRECTORY)\n",
        "  tests.test_train_nn(train_nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1c4tcywvT94Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run():\n",
        "  print(\"NUMBER OF IMAGES:\", NUMBER_OF_IMAGES)\n",
        "\n",
        "  # download vgg model\n",
        "  helper.maybe_download_pretrained_vgg(DATA_DIRECTORY)\n",
        "\n",
        "  # A function to get batches\n",
        "  get_batches_fn = helper.gen_batch_function(TRAINING_DATA_DIRECTORY, IMAGE_SHAPE)\n",
        "  \n",
        "  with tf.Session() as session:\n",
        "        \n",
        "    # Returns the three layers, keep probability and input layer from the vgg architecture\n",
        "    image_input, keep_prob, layer3, layer4, layer7 = load_vgg(session, VGG_PATH)\n",
        "\n",
        "    # The resulting network architecture, adding a decoder on top of the given vgg model\n",
        "    model_output = layers(layer3, layer4, layer7, NUMBER_OF_CLASSES)\n",
        "\n",
        "    # Returns the output logits, training operation and cost operation to be used\n",
        "    # For the logits: each row represents a pixel, each column a class\n",
        "    # training operation is what is used to get the right parameters to the model to correctly label the pixels\n",
        "    # the cross entropy loss is the cost which we are minimizing, lower cost should yield higher accuracy\n",
        "    logits, train_op, cross_entropy_loss = optimize(model_output, correct_label, learning_rate, NUMBER_OF_CLASSES)\n",
        "    \n",
        "    # Initilize all variables\n",
        "    session.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
        "\n",
        "    # train the neural network\n",
        "    train_nn(session, EPOCHS, BATCH_SIZE, get_batches_fn, \n",
        "             train_op, cross_entropy_loss, image_input,\n",
        "             correct_label, keep_prob, learning_rate)\n",
        "\n",
        "    # Save inference data\n",
        "    helper.save_inference_samples(RUNS_DIRECTORY, DATA_DIRECTORY, session, IMAGE_SHAPE, logits, keep_prob, image_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HnQhELA5T94X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "def network_shapes():\n",
        "  with tf.Session() as sess:\n",
        "    \n",
        "    x = np.random.randn(1, 160, 576, 3)\n",
        "    \n",
        "    image_input, keep_prob, layer3, layer4, layer7 = load_vgg(sess, VGG_PATH)\n",
        " \n",
        "    op = layers_verbose(layer3, layer4, layer7, NUMBER_OF_CLASSES)\n",
        "  \n",
        "    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
        "\n",
        "    l3, l4, l7, l3x, l4x, l7x, d1, s2, d3, s4, d5 = sess.run(op, feed_dict = {image_input: x, keep_prob: 1.0})\n",
        "\n",
        "    print(\"------------------\")\n",
        "    print(\"shapes of layers:\") \n",
        "    print(\"------------------\")\n",
        "\n",
        "    print(\"layer3 -->\", l3.shape)\n",
        "    print(\"layer4 -->\", l4.shape)\n",
        "    print(\"layer7 -->\", l7.shape)\n",
        "    print(\"layer3 conv1x1 -->\", l3x.shape)\n",
        "    print(\"layer4 conv1x1 -->\", l4x.shape)\n",
        "    print(\"layer7 conv1x1-->\", l7x.shape)\n",
        "    print(\"decoderlayer1 transpose: layer7 k = 4 s = 2 -->\", d1.shape)\n",
        "    print(\"decoderlayer2 skip: decoderlayer1 and layer4conv1x1 -->\", s2.shape)\n",
        "    print(\"decoderlayer3 transpose: decoderlayer2 k = 4 s = 2 -->\", d3.shape)\n",
        "    print(\"decoderlayer4 skip: decoderlayer3 and layer3conv1x1 -->\", s4.shape)\n",
        "    print(\"decoderlayer5 transpose: decoderlayer4 k = 16 s = 8 -->\", d5.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mx4Xy_zJT94q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# `network_shape()`\n",
        "- for the transpose layers **`s = stride`** and **`k = kernel/filter_size`**\n",
        "- running **`network_shape()`** will output the following:\n",
        "\n",
        "\n",
        "```\n",
        "------------------\n",
        "shapes of layers:\n",
        "------------------\n",
        "layer3 --> (1, 20, 72, 256)\n",
        "layer4 --> (1, 10, 36, 512)\n",
        "layer7 --> (1, 5, 18, 4096)\n",
        "layer3 conv1x1 --> (1, 20, 72, 2)\n",
        "layer4 conv1x1 --> (1, 10, 36, 2)\n",
        "layer7 conv1x1--> (1, 5, 18, 2)\n",
        "decoderlayer1 transpose: layer7 k = 4 s = 2 --> (1, 10, 36, 2)\n",
        "decoderlayer2 skip: decoderlayer1 and layer4conv1x1 --> (1, 10, 36, 2)\n",
        "decoderlayer3 transpose: decoderlayer2 k = 4 s = 2 --> (1, 20, 72, 2)\n",
        "decoderlayer4 skip: decoderlayer3 and layer3conv1x1 --> (1, 20, 72, 2)\n",
        "decoderlayer5 transpose: decoderlayer4 k = 16 s = 8 --> (1, 160, 576, 2)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "pP-LWUiPT94t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103067
        },
        "outputId": "fbc3fc28-8334-46bd-a833-4504692a06ba"
      },
      "cell_type": "code",
      "source": [
        "# Train the network\n",
        "run()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0.00B [00:00, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NUMBER OF IMAGES: 289\n",
            "Downloading pre-trained vgg model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "997MB [00:49, 20.2MB/s]                           \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting model...\n",
            "INFO:tensorflow:Restoring parameters from ./data/vgg/variables/variables\n",
            "WARNING:tensorflow:From <ipython-input-24-b8179cf1b687>:16: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "---> iteration:  1  partial loss: 57.66354\n",
            "---> iteration:  2  partial loss: 48.782738\n",
            "---> iteration:  3  partial loss: 36.688583\n",
            "---> iteration:  4  partial loss: 26.432547\n",
            "---> iteration:  5  partial loss: 26.891808\n",
            "---> iteration:  6  partial loss: 32.583767\n",
            "---> iteration:  7  partial loss: 19.709843\n",
            "---> iteration:  8  partial loss: 17.144985\n",
            "---> iteration:  9  partial loss: 14.626846\n",
            "---> iteration:  10  partial loss: 15.032783\n",
            "---> iteration:  11  partial loss: 13.052539\n",
            "---> iteration:  12  partial loss: 11.544759\n",
            "---> iteration:  13  partial loss: 8.550205\n",
            "---> iteration:  14  partial loss: 10.262689\n",
            "---> iteration:  15  partial loss: 9.6168375\n",
            "---> iteration:  16  partial loss: 9.403716\n",
            "---> iteration:  17  partial loss: 6.9381084\n",
            "---> iteration:  18  partial loss: 8.742708\n",
            "---> iteration:  19  partial loss: 7.5605116\n",
            "---> iteration:  20  partial loss: 5.6460495\n",
            "---> iteration:  21  partial loss: 5.6997614\n",
            "---> iteration:  22  partial loss: 5.11192\n",
            "---> iteration:  23  partial loss: 5.0638833\n",
            "---> iteration:  24  partial loss: 4.9270453\n",
            "---> iteration:  25  partial loss: 3.8026156\n",
            "---> iteration:  26  partial loss: 3.9054716\n",
            "---> iteration:  27  partial loss: 3.2791927\n",
            "---> iteration:  28  partial loss: 3.8509555\n",
            "---> iteration:  29  partial loss: 3.9979103\n",
            "---> iteration:  30  partial loss: 3.48986\n",
            "---> iteration:  31  partial loss: 3.2468088\n",
            "---> iteration:  32  partial loss: 3.6646023\n",
            "---> iteration:  33  partial loss: 2.8690064\n",
            "---> iteration:  34  partial loss: 2.6323485\n",
            "---> iteration:  35  partial loss: 3.3347952\n",
            "---> iteration:  36  partial loss: 2.152638\n",
            "---> iteration:  37  partial loss: 4.0870705\n",
            "---> iteration:  38  partial loss: 2.43765\n",
            "---> iteration:  39  partial loss: 2.648111\n",
            "---> iteration:  40  partial loss: 1.7814734\n",
            "---> iteration:  41  partial loss: 1.9902011\n",
            "---> iteration:  42  partial loss: 2.1235816\n",
            "---> iteration:  43  partial loss: 2.0541697\n",
            "---> iteration:  44  partial loss: 1.7837172\n",
            "---> iteration:  45  partial loss: 2.1182663\n",
            "---> iteration:  46  partial loss: 1.8332876\n",
            "---> iteration:  47  partial loss: 2.148335\n",
            "---> iteration:  48  partial loss: 1.4737183\n",
            "---> iteration:  49  partial loss: 2.2345178\n",
            "---> iteration:  50  partial loss: 1.7260884\n",
            "---> iteration:  51  partial loss: 1.6367568\n",
            "---> iteration:  52  partial loss: 1.5483149\n",
            "---> iteration:  53  partial loss: 2.0501451\n",
            "---> iteration:  54  partial loss: 1.8242444\n",
            "---> iteration:  55  partial loss: 1.4822937\n",
            "---> iteration:  56  partial loss: 1.5745882\n",
            "---> iteration:  57  partial loss: 1.8281049\n",
            "---> iteration:  58  partial loss: 1.444852\n",
            "---> iteration:  59  partial loss: 1.9870358\n",
            "---> iteration:  60  partial loss: 1.4580234\n",
            "---> iteration:  61  partial loss: 1.4214388\n",
            "---> iteration:  62  partial loss: 1.6570445\n",
            "---> iteration:  63  partial loss: 1.4612427\n",
            "---> iteration:  64  partial loss: 1.267052\n",
            "---> iteration:  65  partial loss: 1.450294\n",
            "---> iteration:  66  partial loss: 1.2548529\n",
            "---> iteration:  67  partial loss: 1.3089037\n",
            "---> iteration:  68  partial loss: 1.4287704\n",
            "---> iteration:  69  partial loss: 1.2039313\n",
            "---> iteration:  70  partial loss: 1.3307163\n",
            "---> iteration:  71  partial loss: 1.4821842\n",
            "---> iteration:  72  partial loss: 1.2530595\n",
            "---> iteration:  73  partial loss: 1.1690726\n",
            "---> iteration:  74  partial loss: 1.1757092\n",
            "---> iteration:  75  partial loss: 1.2961295\n",
            "---> iteration:  76  partial loss: 1.2765344\n",
            "---> iteration:  77  partial loss: 1.0849797\n",
            "---> iteration:  78  partial loss: 1.0463698\n",
            "---> iteration:  79  partial loss: 1.2970324\n",
            "---> iteration:  80  partial loss: 1.2082009\n",
            "---> iteration:  81  partial loss: 1.2568948\n",
            "---> iteration:  82  partial loss: 1.087215\n",
            "---> iteration:  83  partial loss: 1.202059\n",
            "---> iteration:  84  partial loss: 1.1272491\n",
            "---> iteration:  85  partial loss: 1.1230581\n",
            "---> iteration:  86  partial loss: 1.0148602\n",
            "---> iteration:  87  partial loss: 1.011275\n",
            "---> iteration:  88  partial loss: 0.93521184\n",
            "---> iteration:  89  partial loss: 1.0904995\n",
            "---> iteration:  90  partial loss: 1.0667245\n",
            "---> iteration:  91  partial loss: 0.93753266\n",
            "---> iteration:  92  partial loss: 1.0522408\n",
            "---> iteration:  93  partial loss: 1.0178256\n",
            "---> iteration:  94  partial loss: 1.0628967\n",
            "---> iteration:  95  partial loss: 0.9414986\n",
            "---> iteration:  96  partial loss: 0.9815453\n",
            "---> iteration:  97  partial loss: 1.1471559\n",
            "---> iteration:  98  partial loss: 0.88552874\n",
            "---> iteration:  99  partial loss: 1.0195247\n",
            "---> iteration:  100  partial loss: 1.1399219\n",
            "---> iteration:  101  partial loss: 0.9745843\n",
            "---> iteration:  102  partial loss: 0.98945343\n",
            "---> iteration:  103  partial loss: 1.035111\n",
            "---> iteration:  104  partial loss: 1.0266889\n",
            "---> iteration:  105  partial loss: 0.9312106\n",
            "---> iteration:  106  partial loss: 1.0896181\n",
            "---> iteration:  107  partial loss: 0.9216429\n",
            "---> iteration:  108  partial loss: 0.96100914\n",
            "---> iteration:  109  partial loss: 1.0081314\n",
            "---> iteration:  110  partial loss: 0.8882005\n",
            "---> iteration:  111  partial loss: 0.9289505\n",
            "---> iteration:  112  partial loss: 0.9166842\n",
            "---> iteration:  113  partial loss: 1.0169259\n",
            "---> iteration:  114  partial loss: 0.98733526\n",
            "---> iteration:  115  partial loss: 0.92295414\n",
            "---> iteration:  116  partial loss: 0.92319673\n",
            "---> iteration:  117  partial loss: 0.85818887\n",
            "---> iteration:  118  partial loss: 0.9896558\n",
            "---> iteration:  119  partial loss: 1.0058173\n",
            "---> iteration:  120  partial loss: 0.9086141\n",
            "---> iteration:  121  partial loss: 0.9359582\n",
            "---> iteration:  122  partial loss: 0.8191233\n",
            "---> iteration:  123  partial loss: 1.0644006\n",
            "---> iteration:  124  partial loss: 0.9359709\n",
            "---> iteration:  125  partial loss: 0.9668434\n",
            "---> iteration:  126  partial loss: 0.8960734\n",
            "---> iteration:  127  partial loss: 0.8732196\n",
            "---> iteration:  128  partial loss: 0.8571414\n",
            "---> iteration:  129  partial loss: 0.9187922\n",
            "---> iteration:  130  partial loss: 0.88238746\n",
            "---> iteration:  131  partial loss: 0.8213645\n",
            "---> iteration:  132  partial loss: 0.846747\n",
            "---> iteration:  133  partial loss: 0.9077528\n",
            "---> iteration:  134  partial loss: 0.82408464\n",
            "---> iteration:  135  partial loss: 0.89510584\n",
            "---> iteration:  136  partial loss: 0.9024955\n",
            "---> iteration:  137  partial loss: 0.8862911\n",
            "---> iteration:  138  partial loss: 0.8147946\n",
            "---> iteration:  139  partial loss: 0.80618864\n",
            "---> iteration:  140  partial loss: 0.88229775\n",
            "---> iteration:  141  partial loss: 0.7856929\n",
            "---> iteration:  142  partial loss: 0.85206944\n",
            "---> iteration:  143  partial loss: 0.8244529\n",
            "---> iteration:  144  partial loss: 0.80919814\n",
            "---> iteration:  145  partial loss: 0.81273276\n",
            "---> iteration:  146  partial loss: 0.9274498\n",
            "---> iteration:  147  partial loss: 0.8900086\n",
            "---> iteration:  148  partial loss: 0.8131078\n",
            "---> iteration:  149  partial loss: 0.8572253\n",
            "---> iteration:  150  partial loss: 0.83237946\n",
            "---> iteration:  151  partial loss: 0.76537377\n",
            "---> iteration:  152  partial loss: 0.8144883\n",
            "---> iteration:  153  partial loss: 0.83590317\n",
            "---> iteration:  154  partial loss: 0.82126415\n",
            "---> iteration:  155  partial loss: 0.8095249\n",
            "---> iteration:  156  partial loss: 0.786481\n",
            "---> iteration:  157  partial loss: 0.8400548\n",
            "---> iteration:  158  partial loss: 0.8632592\n",
            "---> iteration:  159  partial loss: 0.77847606\n",
            "---> iteration:  160  partial loss: 0.73814666\n",
            "---> iteration:  161  partial loss: 0.7639011\n",
            "---> iteration:  162  partial loss: 0.7417806\n",
            "---> iteration:  163  partial loss: 0.8192084\n",
            "---> iteration:  164  partial loss: 0.76279646\n",
            "---> iteration:  165  partial loss: 0.74966556\n",
            "---> iteration:  166  partial loss: 0.8553183\n",
            "---> iteration:  167  partial loss: 0.80177325\n",
            "---> iteration:  168  partial loss: 0.75460494\n",
            "---> iteration:  169  partial loss: 0.7366433\n",
            "---> iteration:  170  partial loss: 0.7648982\n",
            "---> iteration:  171  partial loss: 0.8230579\n",
            "---> iteration:  172  partial loss: 0.7628148\n",
            "---> iteration:  173  partial loss: 0.78534836\n",
            "---> iteration:  174  partial loss: 0.79598653\n",
            "---> iteration:  175  partial loss: 0.7500157\n",
            "---> iteration:  176  partial loss: 0.7348214\n",
            "---> iteration:  177  partial loss: 0.7565406\n",
            "---> iteration:  178  partial loss: 0.8081352\n",
            "---> iteration:  179  partial loss: 0.7394289\n",
            "---> iteration:  180  partial loss: 0.75449693\n",
            "---> iteration:  181  partial loss: 0.7792782\n",
            "---> iteration:  182  partial loss: 0.7489086\n",
            "---> iteration:  183  partial loss: 0.7571082\n",
            "---> iteration:  184  partial loss: 0.7544584\n",
            "---> iteration:  185  partial loss: 0.75222415\n",
            "---> iteration:  186  partial loss: 0.78068054\n",
            "---> iteration:  187  partial loss: 0.76404774\n",
            "---> iteration:  188  partial loss: 0.75020957\n",
            "---> iteration:  189  partial loss: 0.7455203\n",
            "---> iteration:  190  partial loss: 0.71957\n",
            "---> iteration:  191  partial loss: 0.77639896\n",
            "---> iteration:  192  partial loss: 0.78435516\n",
            "---> iteration:  193  partial loss: 0.75521624\n",
            "---> iteration:  194  partial loss: 0.7304862\n",
            "---> iteration:  195  partial loss: 0.72591776\n",
            "---> iteration:  196  partial loss: 0.81166357\n",
            "---> iteration:  197  partial loss: 0.7372306\n",
            "---> iteration:  198  partial loss: 0.7519025\n",
            "---> iteration:  199  partial loss: 0.7551745\n",
            "---> iteration:  200  partial loss: 0.7147468\n",
            "---> iteration:  201  partial loss: 0.71664566\n",
            "---> iteration:  202  partial loss: 0.75994164\n",
            "---> iteration:  203  partial loss: 0.7319701\n",
            "---> iteration:  204  partial loss: 0.74198407\n",
            "---> iteration:  205  partial loss: 0.71543986\n",
            "---> iteration:  206  partial loss: 0.71396655\n",
            "---> iteration:  207  partial loss: 0.74834716\n",
            "---> iteration:  208  partial loss: 0.72980565\n",
            "---> iteration:  209  partial loss: 0.7390808\n",
            "---> iteration:  210  partial loss: 0.76420456\n",
            "---> iteration:  211  partial loss: 0.72284293\n",
            "---> iteration:  212  partial loss: 0.7185155\n",
            "---> iteration:  213  partial loss: 0.70433325\n",
            "---> iteration:  214  partial loss: 0.73011506\n",
            "---> iteration:  215  partial loss: 0.711999\n",
            "---> iteration:  216  partial loss: 0.7508906\n",
            "---> iteration:  217  partial loss: 0.75341475\n",
            "---> iteration:  218  partial loss: 0.73154676\n",
            "---> iteration:  219  partial loss: 0.73663896\n",
            "---> iteration:  220  partial loss: 0.74331087\n",
            "---> iteration:  221  partial loss: 0.70108557\n",
            "---> iteration:  222  partial loss: 0.70749867\n",
            "---> iteration:  223  partial loss: 0.7574097\n",
            "---> iteration:  224  partial loss: 0.73623556\n",
            "---> iteration:  225  partial loss: 0.71951634\n",
            "---> iteration:  226  partial loss: 0.78935343\n",
            "---> iteration:  227  partial loss: 0.7065266\n",
            "---> iteration:  228  partial loss: 0.72976965\n",
            "---> iteration:  229  partial loss: 0.71829104\n",
            "---> iteration:  230  partial loss: 0.75342256\n",
            "---> iteration:  231  partial loss: 0.7323853\n",
            "---> iteration:  232  partial loss: 0.7517359\n",
            "---> iteration:  233  partial loss: 0.7098191\n",
            "---> iteration:  234  partial loss: 0.707606\n",
            "---> iteration:  235  partial loss: 0.7350131\n",
            "---> iteration:  236  partial loss: 0.71095455\n",
            "---> iteration:  237  partial loss: 0.7004156\n",
            "---> iteration:  238  partial loss: 0.69615144\n",
            "---> iteration:  239  partial loss: 0.7000843\n",
            "---> iteration:  240  partial loss: 0.7212355\n",
            "---> iteration:  241  partial loss: 0.73191273\n",
            "---> iteration:  242  partial loss: 0.70739037\n",
            "---> iteration:  243  partial loss: 0.70992804\n",
            "---> iteration:  244  partial loss: 0.7026481\n",
            "---> iteration:  245  partial loss: 0.74882674\n",
            "---> iteration:  246  partial loss: 0.7178899\n",
            "---> iteration:  247  partial loss: 0.70418876\n",
            "---> iteration:  248  partial loss: 0.7247401\n",
            "---> iteration:  249  partial loss: 0.719772\n",
            "---> iteration:  250  partial loss: 0.7003273\n",
            "---> iteration:  251  partial loss: 0.70231664\n",
            "---> iteration:  252  partial loss: 0.6991704\n",
            "---> iteration:  253  partial loss: 0.7190765\n",
            "---> iteration:  254  partial loss: 0.69406354\n",
            "---> iteration:  255  partial loss: 0.70342755\n",
            "---> iteration:  256  partial loss: 0.7077163\n",
            "---> iteration:  257  partial loss: 0.6911081\n",
            "---> iteration:  258  partial loss: 0.69519067\n",
            "---> iteration:  259  partial loss: 0.6857671\n",
            "---> iteration:  260  partial loss: 0.6760356\n",
            "---> iteration:  261  partial loss: 0.690418\n",
            "---> iteration:  262  partial loss: 0.6938975\n",
            "---> iteration:  263  partial loss: 0.6922811\n",
            "---> iteration:  264  partial loss: 0.70146275\n",
            "---> iteration:  265  partial loss: 0.6903706\n",
            "---> iteration:  266  partial loss: 0.7141898\n",
            "---> iteration:  267  partial loss: 0.6914818\n",
            "---> iteration:  268  partial loss: 0.7072309\n",
            "---> iteration:  269  partial loss: 0.68972695\n",
            "---> iteration:  270  partial loss: 0.6915809\n",
            "---> iteration:  271  partial loss: 0.6971074\n",
            "---> iteration:  272  partial loss: 0.68365765\n",
            "---> iteration:  273  partial loss: 0.7049378\n",
            "---> iteration:  274  partial loss: 0.6753963\n",
            "---> iteration:  275  partial loss: 0.67263347\n",
            "---> iteration:  276  partial loss: 0.67695564\n",
            "---> iteration:  277  partial loss: 0.6843019\n",
            "---> iteration:  278  partial loss: 0.66952556\n",
            "---> iteration:  279  partial loss: 0.6784804\n",
            "---> iteration:  280  partial loss: 0.7116751\n",
            "---> iteration:  281  partial loss: 0.68755966\n",
            "---> iteration:  282  partial loss: 0.6796862\n",
            "---> iteration:  283  partial loss: 0.6761526\n",
            "---> iteration:  284  partial loss: 0.6863678\n",
            "---> iteration:  285  partial loss: 0.6962111\n",
            "---> iteration:  286  partial loss: 0.6810001\n",
            "---> iteration:  287  partial loss: 0.6809844\n",
            "---> iteration:  288  partial loss: 0.6821654\n",
            "---> iteration:  289  partial loss: 0.70764774\n",
            "------------------\n",
            "epoch:  1  of  20 training loss:  2.3864147978670456\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.66967857\n",
            "---> iteration:  2  partial loss: 0.6619935\n",
            "---> iteration:  3  partial loss: 0.6832019\n",
            "---> iteration:  4  partial loss: 0.6807182\n",
            "---> iteration:  5  partial loss: 0.69735694\n",
            "---> iteration:  6  partial loss: 0.6884916\n",
            "---> iteration:  7  partial loss: 0.683403\n",
            "---> iteration:  8  partial loss: 0.68435764\n",
            "---> iteration:  9  partial loss: 0.67309666\n",
            "---> iteration:  10  partial loss: 0.6804407\n",
            "---> iteration:  11  partial loss: 0.66945654\n",
            "---> iteration:  12  partial loss: 0.68298155\n",
            "---> iteration:  13  partial loss: 0.66554224\n",
            "---> iteration:  14  partial loss: 0.658304\n",
            "---> iteration:  15  partial loss: 0.6856432\n",
            "---> iteration:  16  partial loss: 0.67597896\n",
            "---> iteration:  17  partial loss: 0.6771462\n",
            "---> iteration:  18  partial loss: 0.6573584\n",
            "---> iteration:  19  partial loss: 0.66800386\n",
            "---> iteration:  20  partial loss: 0.6858829\n",
            "---> iteration:  21  partial loss: 0.67395204\n",
            "---> iteration:  22  partial loss: 0.680921\n",
            "---> iteration:  23  partial loss: 0.6628288\n",
            "---> iteration:  24  partial loss: 0.66616684\n",
            "---> iteration:  25  partial loss: 0.68168855\n",
            "---> iteration:  26  partial loss: 0.6659661\n",
            "---> iteration:  27  partial loss: 0.67501444\n",
            "---> iteration:  28  partial loss: 0.66890496\n",
            "---> iteration:  29  partial loss: 0.6692233\n",
            "---> iteration:  30  partial loss: 0.6555431\n",
            "---> iteration:  31  partial loss: 0.684282\n",
            "---> iteration:  32  partial loss: 0.67700464\n",
            "---> iteration:  33  partial loss: 0.6665182\n",
            "---> iteration:  34  partial loss: 0.6480093\n",
            "---> iteration:  35  partial loss: 0.6604766\n",
            "---> iteration:  36  partial loss: 0.6492985\n",
            "---> iteration:  37  partial loss: 0.68568856\n",
            "---> iteration:  38  partial loss: 0.65349966\n",
            "---> iteration:  39  partial loss: 0.6573835\n",
            "---> iteration:  40  partial loss: 0.6657219\n",
            "---> iteration:  41  partial loss: 0.66597724\n",
            "---> iteration:  42  partial loss: 0.6522204\n",
            "---> iteration:  43  partial loss: 0.65703017\n",
            "---> iteration:  44  partial loss: 0.6645419\n",
            "---> iteration:  45  partial loss: 0.68292224\n",
            "---> iteration:  46  partial loss: 0.67057204\n",
            "---> iteration:  47  partial loss: 0.6574586\n",
            "---> iteration:  48  partial loss: 0.65694964\n",
            "---> iteration:  49  partial loss: 0.65826\n",
            "---> iteration:  50  partial loss: 0.6636031\n",
            "---> iteration:  51  partial loss: 0.65324265\n",
            "---> iteration:  52  partial loss: 0.64465934\n",
            "---> iteration:  53  partial loss: 0.6730123\n",
            "---> iteration:  54  partial loss: 0.6421101\n",
            "---> iteration:  55  partial loss: 0.65705496\n",
            "---> iteration:  56  partial loss: 0.65711725\n",
            "---> iteration:  57  partial loss: 0.6505574\n",
            "---> iteration:  58  partial loss: 0.65898895\n",
            "---> iteration:  59  partial loss: 0.6567445\n",
            "---> iteration:  60  partial loss: 0.71132386\n",
            "---> iteration:  61  partial loss: 0.6420066\n",
            "---> iteration:  62  partial loss: 0.662518\n",
            "---> iteration:  63  partial loss: 0.6468893\n",
            "---> iteration:  64  partial loss: 0.6529719\n",
            "---> iteration:  65  partial loss: 0.64077073\n",
            "---> iteration:  66  partial loss: 0.6384598\n",
            "---> iteration:  67  partial loss: 0.6745447\n",
            "---> iteration:  68  partial loss: 0.65624934\n",
            "---> iteration:  69  partial loss: 0.6467476\n",
            "---> iteration:  70  partial loss: 0.6506126\n",
            "---> iteration:  71  partial loss: 0.6454845\n",
            "---> iteration:  72  partial loss: 0.6429222\n",
            "---> iteration:  73  partial loss: 0.66445535\n",
            "---> iteration:  74  partial loss: 0.63956666\n",
            "---> iteration:  75  partial loss: 0.63734317\n",
            "---> iteration:  76  partial loss: 0.6404251\n",
            "---> iteration:  77  partial loss: 0.64721817\n",
            "---> iteration:  78  partial loss: 0.63667995\n",
            "---> iteration:  79  partial loss: 0.6596618\n",
            "---> iteration:  80  partial loss: 0.63256013\n",
            "---> iteration:  81  partial loss: 0.6574595\n",
            "---> iteration:  82  partial loss: 0.62232757\n",
            "---> iteration:  83  partial loss: 0.6483692\n",
            "---> iteration:  84  partial loss: 0.64075595\n",
            "---> iteration:  85  partial loss: 0.64035237\n",
            "---> iteration:  86  partial loss: 0.6415173\n",
            "---> iteration:  87  partial loss: 0.6365364\n",
            "---> iteration:  88  partial loss: 0.64194685\n",
            "---> iteration:  89  partial loss: 0.660723\n",
            "---> iteration:  90  partial loss: 0.62124926\n",
            "---> iteration:  91  partial loss: 0.6854079\n",
            "---> iteration:  92  partial loss: 0.6483232\n",
            "---> iteration:  93  partial loss: 0.62240505\n",
            "---> iteration:  94  partial loss: 0.6474692\n",
            "---> iteration:  95  partial loss: 0.6479873\n",
            "---> iteration:  96  partial loss: 0.6561078\n",
            "---> iteration:  97  partial loss: 0.64656276\n",
            "---> iteration:  98  partial loss: 0.63360363\n",
            "---> iteration:  99  partial loss: 0.6278863\n",
            "---> iteration:  100  partial loss: 0.6318583\n",
            "---> iteration:  101  partial loss: 0.6297905\n",
            "---> iteration:  102  partial loss: 0.6198734\n",
            "---> iteration:  103  partial loss: 0.6172868\n",
            "---> iteration:  104  partial loss: 0.61990994\n",
            "---> iteration:  105  partial loss: 0.6409518\n",
            "---> iteration:  106  partial loss: 0.61538386\n",
            "---> iteration:  107  partial loss: 0.6449819\n",
            "---> iteration:  108  partial loss: 0.6258097\n",
            "---> iteration:  109  partial loss: 0.61054105\n",
            "---> iteration:  110  partial loss: 0.609155\n",
            "---> iteration:  111  partial loss: 0.61843276\n",
            "---> iteration:  112  partial loss: 0.59995806\n",
            "---> iteration:  113  partial loss: 0.6139142\n",
            "---> iteration:  114  partial loss: 0.61528516\n",
            "---> iteration:  115  partial loss: 0.61563057\n",
            "---> iteration:  116  partial loss: 0.62642175\n",
            "---> iteration:  117  partial loss: 0.61665356\n",
            "---> iteration:  118  partial loss: 0.61458534\n",
            "---> iteration:  119  partial loss: 0.64067495\n",
            "---> iteration:  120  partial loss: 0.60382944\n",
            "---> iteration:  121  partial loss: 0.60104173\n",
            "---> iteration:  122  partial loss: 0.60132575\n",
            "---> iteration:  123  partial loss: 0.61074555\n",
            "---> iteration:  124  partial loss: 0.64423805\n",
            "---> iteration:  125  partial loss: 0.616133\n",
            "---> iteration:  126  partial loss: 0.6336098\n",
            "---> iteration:  127  partial loss: 0.5979983\n",
            "---> iteration:  128  partial loss: 0.62042594\n",
            "---> iteration:  129  partial loss: 0.59675336\n",
            "---> iteration:  130  partial loss: 0.59146833\n",
            "---> iteration:  131  partial loss: 0.6274893\n",
            "---> iteration:  132  partial loss: 0.6365471\n",
            "---> iteration:  133  partial loss: 0.60630876\n",
            "---> iteration:  134  partial loss: 0.60099953\n",
            "---> iteration:  135  partial loss: 0.60992587\n",
            "---> iteration:  136  partial loss: 0.58741945\n",
            "---> iteration:  137  partial loss: 0.61399955\n",
            "---> iteration:  138  partial loss: 0.59888905\n",
            "---> iteration:  139  partial loss: 0.5954077\n",
            "---> iteration:  140  partial loss: 0.61964864\n",
            "---> iteration:  141  partial loss: 0.5835026\n",
            "---> iteration:  142  partial loss: 0.60594547\n",
            "---> iteration:  143  partial loss: 0.6030733\n",
            "---> iteration:  144  partial loss: 0.5910103\n",
            "---> iteration:  145  partial loss: 0.5965624\n",
            "---> iteration:  146  partial loss: 0.60515314\n",
            "---> iteration:  147  partial loss: 0.59855264\n",
            "---> iteration:  148  partial loss: 0.6022184\n",
            "---> iteration:  149  partial loss: 0.60028553\n",
            "---> iteration:  150  partial loss: 0.56803095\n",
            "---> iteration:  151  partial loss: 0.5754331\n",
            "---> iteration:  152  partial loss: 0.5894321\n",
            "---> iteration:  153  partial loss: 0.62514603\n",
            "---> iteration:  154  partial loss: 0.5687607\n",
            "---> iteration:  155  partial loss: 0.5782448\n",
            "---> iteration:  156  partial loss: 0.6196466\n",
            "---> iteration:  157  partial loss: 0.55980283\n",
            "---> iteration:  158  partial loss: 0.6355467\n",
            "---> iteration:  159  partial loss: 0.5975495\n",
            "---> iteration:  160  partial loss: 0.56557465\n",
            "---> iteration:  161  partial loss: 0.5782682\n",
            "---> iteration:  162  partial loss: 0.610378\n",
            "---> iteration:  163  partial loss: 0.5824578\n",
            "---> iteration:  164  partial loss: 0.5735926\n",
            "---> iteration:  165  partial loss: 0.6030029\n",
            "---> iteration:  166  partial loss: 0.56343484\n",
            "---> iteration:  167  partial loss: 0.59313285\n",
            "---> iteration:  168  partial loss: 0.56858444\n",
            "---> iteration:  169  partial loss: 0.6050556\n",
            "---> iteration:  170  partial loss: 0.57273686\n",
            "---> iteration:  171  partial loss: 0.5811071\n",
            "---> iteration:  172  partial loss: 0.5785023\n",
            "---> iteration:  173  partial loss: 0.56543183\n",
            "---> iteration:  174  partial loss: 0.56189907\n",
            "---> iteration:  175  partial loss: 0.5944393\n",
            "---> iteration:  176  partial loss: 0.5658654\n",
            "---> iteration:  177  partial loss: 0.5542725\n",
            "---> iteration:  178  partial loss: 0.57882464\n",
            "---> iteration:  179  partial loss: 0.559029\n",
            "---> iteration:  180  partial loss: 0.5808715\n",
            "---> iteration:  181  partial loss: 0.54173356\n",
            "---> iteration:  182  partial loss: 0.5926802\n",
            "---> iteration:  183  partial loss: 0.5494706\n",
            "---> iteration:  184  partial loss: 0.5295242\n",
            "---> iteration:  185  partial loss: 0.6032777\n",
            "---> iteration:  186  partial loss: 0.5560254\n",
            "---> iteration:  187  partial loss: 0.5911787\n",
            "---> iteration:  188  partial loss: 0.58046114\n",
            "---> iteration:  189  partial loss: 0.5996248\n",
            "---> iteration:  190  partial loss: 0.5701084\n",
            "---> iteration:  191  partial loss: 0.5641558\n",
            "---> iteration:  192  partial loss: 0.53204566\n",
            "---> iteration:  193  partial loss: 0.56867546\n",
            "---> iteration:  194  partial loss: 0.55554307\n",
            "---> iteration:  195  partial loss: 0.5482991\n",
            "---> iteration:  196  partial loss: 0.65922534\n",
            "---> iteration:  197  partial loss: 0.5213891\n",
            "---> iteration:  198  partial loss: 0.56123716\n",
            "---> iteration:  199  partial loss: 0.54806614\n",
            "---> iteration:  200  partial loss: 0.5469189\n",
            "---> iteration:  201  partial loss: 0.58435315\n",
            "---> iteration:  202  partial loss: 0.51032865\n",
            "---> iteration:  203  partial loss: 0.52383965\n",
            "---> iteration:  204  partial loss: 0.54322165\n",
            "---> iteration:  205  partial loss: 0.52915084\n",
            "---> iteration:  206  partial loss: 0.5724261\n",
            "---> iteration:  207  partial loss: 0.54867226\n",
            "---> iteration:  208  partial loss: 0.5746563\n",
            "---> iteration:  209  partial loss: 0.5764305\n",
            "---> iteration:  210  partial loss: 0.51265615\n",
            "---> iteration:  211  partial loss: 0.54272026\n",
            "---> iteration:  212  partial loss: 0.56479305\n",
            "---> iteration:  213  partial loss: 0.4964715\n",
            "---> iteration:  214  partial loss: 0.5318234\n",
            "---> iteration:  215  partial loss: 0.52945536\n",
            "---> iteration:  216  partial loss: 0.53569484\n",
            "---> iteration:  217  partial loss: 0.519117\n",
            "---> iteration:  218  partial loss: 0.528799\n",
            "---> iteration:  219  partial loss: 0.535922\n",
            "---> iteration:  220  partial loss: 0.51912886\n",
            "---> iteration:  221  partial loss: 0.52345335\n",
            "---> iteration:  222  partial loss: 0.57603616\n",
            "---> iteration:  223  partial loss: 0.54093397\n",
            "---> iteration:  224  partial loss: 0.519524\n",
            "---> iteration:  225  partial loss: 0.56019676\n",
            "---> iteration:  226  partial loss: 0.5241359\n",
            "---> iteration:  227  partial loss: 0.5537816\n",
            "---> iteration:  228  partial loss: 0.5000661\n",
            "---> iteration:  229  partial loss: 0.5323253\n",
            "---> iteration:  230  partial loss: 0.5393322\n",
            "---> iteration:  231  partial loss: 0.47691578\n",
            "---> iteration:  232  partial loss: 0.48395982\n",
            "---> iteration:  233  partial loss: 0.4963667\n",
            "---> iteration:  234  partial loss: 0.51883996\n",
            "---> iteration:  235  partial loss: 0.5061065\n",
            "---> iteration:  236  partial loss: 0.5403336\n",
            "---> iteration:  237  partial loss: 0.5201786\n",
            "---> iteration:  238  partial loss: 0.49463356\n",
            "---> iteration:  239  partial loss: 0.5616248\n",
            "---> iteration:  240  partial loss: 0.44657215\n",
            "---> iteration:  241  partial loss: 0.5229446\n",
            "---> iteration:  242  partial loss: 0.4726504\n",
            "---> iteration:  243  partial loss: 0.49096832\n",
            "---> iteration:  244  partial loss: 0.560875\n",
            "---> iteration:  245  partial loss: 0.50719506\n",
            "---> iteration:  246  partial loss: 0.45614505\n",
            "---> iteration:  247  partial loss: 0.4868364\n",
            "---> iteration:  248  partial loss: 0.5255048\n",
            "---> iteration:  249  partial loss: 0.44711235\n",
            "---> iteration:  250  partial loss: 0.4710378\n",
            "---> iteration:  251  partial loss: 0.49786007\n",
            "---> iteration:  252  partial loss: 0.44763675\n",
            "---> iteration:  253  partial loss: 0.47383672\n",
            "---> iteration:  254  partial loss: 0.5353581\n",
            "---> iteration:  255  partial loss: 0.5192946\n",
            "---> iteration:  256  partial loss: 0.4190778\n",
            "---> iteration:  257  partial loss: 0.485003\n",
            "---> iteration:  258  partial loss: 0.39822048\n",
            "---> iteration:  259  partial loss: 0.47593525\n",
            "---> iteration:  260  partial loss: 0.43439135\n",
            "---> iteration:  261  partial loss: 0.4744659\n",
            "---> iteration:  262  partial loss: 0.5169384\n",
            "---> iteration:  263  partial loss: 0.50276\n",
            "---> iteration:  264  partial loss: 0.49056184\n",
            "---> iteration:  265  partial loss: 0.47403073\n",
            "---> iteration:  266  partial loss: 0.46992826\n",
            "---> iteration:  267  partial loss: 0.46354064\n",
            "---> iteration:  268  partial loss: 0.45237663\n",
            "---> iteration:  269  partial loss: 0.5148882\n",
            "---> iteration:  270  partial loss: 0.45772842\n",
            "---> iteration:  271  partial loss: 0.44819146\n",
            "---> iteration:  272  partial loss: 0.45202467\n",
            "---> iteration:  273  partial loss: 0.45438987\n",
            "---> iteration:  274  partial loss: 0.4223876\n",
            "---> iteration:  275  partial loss: 0.43162555\n",
            "---> iteration:  276  partial loss: 0.41581306\n",
            "---> iteration:  277  partial loss: 0.4343088\n",
            "---> iteration:  278  partial loss: 0.44580358\n",
            "---> iteration:  279  partial loss: 0.44221237\n",
            "---> iteration:  280  partial loss: 0.43711445\n",
            "---> iteration:  281  partial loss: 0.44863713\n",
            "---> iteration:  282  partial loss: 0.40749308\n",
            "---> iteration:  283  partial loss: 0.4033621\n",
            "---> iteration:  284  partial loss: 0.55685645\n",
            "---> iteration:  285  partial loss: 0.45071182\n",
            "---> iteration:  286  partial loss: 0.54033345\n",
            "---> iteration:  287  partial loss: 0.5083331\n",
            "---> iteration:  288  partial loss: 0.40120724\n",
            "---> iteration:  289  partial loss: 0.45149612\n",
            "------------------\n",
            "epoch:  2  of  20 training loss:  0.5864714098430422\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.35688904\n",
            "---> iteration:  2  partial loss: 0.44739324\n",
            "---> iteration:  3  partial loss: 0.45663425\n",
            "---> iteration:  4  partial loss: 0.4152357\n",
            "---> iteration:  5  partial loss: 0.34673128\n",
            "---> iteration:  6  partial loss: 0.40420178\n",
            "---> iteration:  7  partial loss: 0.40348867\n",
            "---> iteration:  8  partial loss: 0.41820976\n",
            "---> iteration:  9  partial loss: 0.35786742\n",
            "---> iteration:  10  partial loss: 0.5538765\n",
            "---> iteration:  11  partial loss: 0.41311303\n",
            "---> iteration:  12  partial loss: 0.3530979\n",
            "---> iteration:  13  partial loss: 0.38350806\n",
            "---> iteration:  14  partial loss: 0.42839515\n",
            "---> iteration:  15  partial loss: 0.41216508\n",
            "---> iteration:  16  partial loss: 0.358508\n",
            "---> iteration:  17  partial loss: 0.37955102\n",
            "---> iteration:  18  partial loss: 0.34509757\n",
            "---> iteration:  19  partial loss: 0.32603613\n",
            "---> iteration:  20  partial loss: 0.3955291\n",
            "---> iteration:  21  partial loss: 0.4411923\n",
            "---> iteration:  22  partial loss: 0.38826632\n",
            "---> iteration:  23  partial loss: 0.3679189\n",
            "---> iteration:  24  partial loss: 0.39586547\n",
            "---> iteration:  25  partial loss: 0.41237175\n",
            "---> iteration:  26  partial loss: 0.3920586\n",
            "---> iteration:  27  partial loss: 0.42600945\n",
            "---> iteration:  28  partial loss: 0.294389\n",
            "---> iteration:  29  partial loss: 0.33566087\n",
            "---> iteration:  30  partial loss: 0.3648449\n",
            "---> iteration:  31  partial loss: 0.3614751\n",
            "---> iteration:  32  partial loss: 0.36094397\n",
            "---> iteration:  33  partial loss: 0.3458366\n",
            "---> iteration:  34  partial loss: 0.37369007\n",
            "---> iteration:  35  partial loss: 0.37222654\n",
            "---> iteration:  36  partial loss: 0.28071243\n",
            "---> iteration:  37  partial loss: 0.36750674\n",
            "---> iteration:  38  partial loss: 0.336328\n",
            "---> iteration:  39  partial loss: 0.38710776\n",
            "---> iteration:  40  partial loss: 0.36100948\n",
            "---> iteration:  41  partial loss: 0.33753312\n",
            "---> iteration:  42  partial loss: 0.25949973\n",
            "---> iteration:  43  partial loss: 0.2973384\n",
            "---> iteration:  44  partial loss: 0.39103988\n",
            "---> iteration:  45  partial loss: 0.3809877\n",
            "---> iteration:  46  partial loss: 0.330076\n",
            "---> iteration:  47  partial loss: 0.5396984\n",
            "---> iteration:  48  partial loss: 0.32441682\n",
            "---> iteration:  49  partial loss: 0.38809034\n",
            "---> iteration:  50  partial loss: 0.38781485\n",
            "---> iteration:  51  partial loss: 0.40266356\n",
            "---> iteration:  52  partial loss: 0.36008734\n",
            "---> iteration:  53  partial loss: 0.34033394\n",
            "---> iteration:  54  partial loss: 0.39112642\n",
            "---> iteration:  55  partial loss: 0.3376446\n",
            "---> iteration:  56  partial loss: 0.35490826\n",
            "---> iteration:  57  partial loss: 0.38529018\n",
            "---> iteration:  58  partial loss: 0.31551474\n",
            "---> iteration:  59  partial loss: 0.31213352\n",
            "---> iteration:  60  partial loss: 0.27453133\n",
            "---> iteration:  61  partial loss: 0.32525516\n",
            "---> iteration:  62  partial loss: 0.3533782\n",
            "---> iteration:  63  partial loss: 0.2670036\n",
            "---> iteration:  64  partial loss: 0.25764388\n",
            "---> iteration:  65  partial loss: 0.34069258\n",
            "---> iteration:  66  partial loss: 0.30135867\n",
            "---> iteration:  67  partial loss: 0.3150052\n",
            "---> iteration:  68  partial loss: 0.29982525\n",
            "---> iteration:  69  partial loss: 0.29134023\n",
            "---> iteration:  70  partial loss: 0.3478046\n",
            "---> iteration:  71  partial loss: 0.19515546\n",
            "---> iteration:  72  partial loss: 0.3062887\n",
            "---> iteration:  73  partial loss: 0.28723302\n",
            "---> iteration:  74  partial loss: 0.27223268\n",
            "---> iteration:  75  partial loss: 0.35247853\n",
            "---> iteration:  76  partial loss: 0.37449482\n",
            "---> iteration:  77  partial loss: 0.29813012\n",
            "---> iteration:  78  partial loss: 0.30159223\n",
            "---> iteration:  79  partial loss: 0.25821948\n",
            "---> iteration:  80  partial loss: 0.33114386\n",
            "---> iteration:  81  partial loss: 0.3382705\n",
            "---> iteration:  82  partial loss: 0.30937916\n",
            "---> iteration:  83  partial loss: 0.3864458\n",
            "---> iteration:  84  partial loss: 0.27908176\n",
            "---> iteration:  85  partial loss: 0.27259225\n",
            "---> iteration:  86  partial loss: 0.2777405\n",
            "---> iteration:  87  partial loss: 0.25764725\n",
            "---> iteration:  88  partial loss: 0.29101104\n",
            "---> iteration:  89  partial loss: 0.37418136\n",
            "---> iteration:  90  partial loss: 0.27461958\n",
            "---> iteration:  91  partial loss: 0.30823177\n",
            "---> iteration:  92  partial loss: 0.26642424\n",
            "---> iteration:  93  partial loss: 0.2879154\n",
            "---> iteration:  94  partial loss: 0.24007294\n",
            "---> iteration:  95  partial loss: 0.2513997\n",
            "---> iteration:  96  partial loss: 0.24085312\n",
            "---> iteration:  97  partial loss: 0.30283937\n",
            "---> iteration:  98  partial loss: 0.28674394\n",
            "---> iteration:  99  partial loss: 0.27416942\n",
            "---> iteration:  100  partial loss: 0.2525711\n",
            "---> iteration:  101  partial loss: 0.25931802\n",
            "---> iteration:  102  partial loss: 0.4334811\n",
            "---> iteration:  103  partial loss: 0.29424247\n",
            "---> iteration:  104  partial loss: 0.30996773\n",
            "---> iteration:  105  partial loss: 0.19938178\n",
            "---> iteration:  106  partial loss: 0.24339245\n",
            "---> iteration:  107  partial loss: 0.20894915\n",
            "---> iteration:  108  partial loss: 0.25092322\n",
            "---> iteration:  109  partial loss: 0.25566864\n",
            "---> iteration:  110  partial loss: 0.2223103\n",
            "---> iteration:  111  partial loss: 0.28871074\n",
            "---> iteration:  112  partial loss: 0.17468153\n",
            "---> iteration:  113  partial loss: 0.21827202\n",
            "---> iteration:  114  partial loss: 0.26494226\n",
            "---> iteration:  115  partial loss: 0.4270245\n",
            "---> iteration:  116  partial loss: 0.27750745\n",
            "---> iteration:  117  partial loss: 0.26753548\n",
            "---> iteration:  118  partial loss: 0.2678258\n",
            "---> iteration:  119  partial loss: 0.2574194\n",
            "---> iteration:  120  partial loss: 0.22505002\n",
            "---> iteration:  121  partial loss: 0.24220975\n",
            "---> iteration:  122  partial loss: 0.21273112\n",
            "---> iteration:  123  partial loss: 0.23003246\n",
            "---> iteration:  124  partial loss: 0.23290358\n",
            "---> iteration:  125  partial loss: 0.34057176\n",
            "---> iteration:  126  partial loss: 0.33862308\n",
            "---> iteration:  127  partial loss: 0.28968912\n",
            "---> iteration:  128  partial loss: 0.21657749\n",
            "---> iteration:  129  partial loss: 0.24254926\n",
            "---> iteration:  130  partial loss: 0.2465204\n",
            "---> iteration:  131  partial loss: 0.30699998\n",
            "---> iteration:  132  partial loss: 0.32672086\n",
            "---> iteration:  133  partial loss: 0.31369388\n",
            "---> iteration:  134  partial loss: 0.17722322\n",
            "---> iteration:  135  partial loss: 0.24936329\n",
            "---> iteration:  136  partial loss: 0.29226667\n",
            "---> iteration:  137  partial loss: 0.37990794\n",
            "---> iteration:  138  partial loss: 0.35878643\n",
            "---> iteration:  139  partial loss: 0.21491407\n",
            "---> iteration:  140  partial loss: 0.35825247\n",
            "---> iteration:  141  partial loss: 0.24938497\n",
            "---> iteration:  142  partial loss: 0.22767203\n",
            "---> iteration:  143  partial loss: 0.25901812\n",
            "---> iteration:  144  partial loss: 0.22012195\n",
            "---> iteration:  145  partial loss: 0.27171427\n",
            "---> iteration:  146  partial loss: 0.3161241\n",
            "---> iteration:  147  partial loss: 0.30851257\n",
            "---> iteration:  148  partial loss: 0.29625544\n",
            "---> iteration:  149  partial loss: 0.20644625\n",
            "---> iteration:  150  partial loss: 0.28955\n",
            "---> iteration:  151  partial loss: 0.36861438\n",
            "---> iteration:  152  partial loss: 0.2824301\n",
            "---> iteration:  153  partial loss: 0.2480526\n",
            "---> iteration:  154  partial loss: 0.24026494\n",
            "---> iteration:  155  partial loss: 0.27866763\n",
            "---> iteration:  156  partial loss: 0.23935162\n",
            "---> iteration:  157  partial loss: 0.26521754\n",
            "---> iteration:  158  partial loss: 0.28231376\n",
            "---> iteration:  159  partial loss: 0.29271248\n",
            "---> iteration:  160  partial loss: 0.2882125\n",
            "---> iteration:  161  partial loss: 0.23848106\n",
            "---> iteration:  162  partial loss: 0.22204725\n",
            "---> iteration:  163  partial loss: 0.18831068\n",
            "---> iteration:  164  partial loss: 0.24868482\n",
            "---> iteration:  165  partial loss: 0.29375103\n",
            "---> iteration:  166  partial loss: 0.49542356\n",
            "---> iteration:  167  partial loss: 0.21038501\n",
            "---> iteration:  168  partial loss: 0.17070639\n",
            "---> iteration:  169  partial loss: 0.14805284\n",
            "---> iteration:  170  partial loss: 0.27078778\n",
            "---> iteration:  171  partial loss: 0.19474591\n",
            "---> iteration:  172  partial loss: 0.33616987\n",
            "---> iteration:  173  partial loss: 0.16512494\n",
            "---> iteration:  174  partial loss: 0.21625629\n",
            "---> iteration:  175  partial loss: 0.3505321\n",
            "---> iteration:  176  partial loss: 0.47694394\n",
            "---> iteration:  177  partial loss: 0.19938463\n",
            "---> iteration:  178  partial loss: 0.32572475\n",
            "---> iteration:  179  partial loss: 0.13991179\n",
            "---> iteration:  180  partial loss: 0.17506927\n",
            "---> iteration:  181  partial loss: 0.2668631\n",
            "---> iteration:  182  partial loss: 0.30769375\n",
            "---> iteration:  183  partial loss: 0.19200219\n",
            "---> iteration:  184  partial loss: 0.19473447\n",
            "---> iteration:  185  partial loss: 0.29403162\n",
            "---> iteration:  186  partial loss: 0.25232247\n",
            "---> iteration:  187  partial loss: 0.2611486\n",
            "---> iteration:  188  partial loss: 0.11963752\n",
            "---> iteration:  189  partial loss: 0.20795321\n",
            "---> iteration:  190  partial loss: 0.1138141\n",
            "---> iteration:  191  partial loss: 0.29079467\n",
            "---> iteration:  192  partial loss: 0.26176035\n",
            "---> iteration:  193  partial loss: 0.18686791\n",
            "---> iteration:  194  partial loss: 0.23561122\n",
            "---> iteration:  195  partial loss: 0.22786318\n",
            "---> iteration:  196  partial loss: 0.28956226\n",
            "---> iteration:  197  partial loss: 0.30800846\n",
            "---> iteration:  198  partial loss: 0.42309082\n",
            "---> iteration:  199  partial loss: 0.3211358\n",
            "---> iteration:  200  partial loss: 0.24923812\n",
            "---> iteration:  201  partial loss: 0.18914147\n",
            "---> iteration:  202  partial loss: 0.19126168\n",
            "---> iteration:  203  partial loss: 0.25420207\n",
            "---> iteration:  204  partial loss: 0.22321409\n",
            "---> iteration:  205  partial loss: 0.24229114\n",
            "---> iteration:  206  partial loss: 0.17047319\n",
            "---> iteration:  207  partial loss: 0.35962135\n",
            "---> iteration:  208  partial loss: 0.16286147\n",
            "---> iteration:  209  partial loss: 0.19262521\n",
            "---> iteration:  210  partial loss: 0.2612099\n",
            "---> iteration:  211  partial loss: 0.23583935\n",
            "---> iteration:  212  partial loss: 0.29162422\n",
            "---> iteration:  213  partial loss: 0.16696317\n",
            "---> iteration:  214  partial loss: 0.2702706\n",
            "---> iteration:  215  partial loss: 0.20728934\n",
            "---> iteration:  216  partial loss: 0.1990726\n",
            "---> iteration:  217  partial loss: 0.36938846\n",
            "---> iteration:  218  partial loss: 0.23497185\n",
            "---> iteration:  219  partial loss: 0.16487537\n",
            "---> iteration:  220  partial loss: 0.19659077\n",
            "---> iteration:  221  partial loss: 0.1752523\n",
            "---> iteration:  222  partial loss: 0.10246013\n",
            "---> iteration:  223  partial loss: 0.18721737\n",
            "---> iteration:  224  partial loss: 0.22152469\n",
            "---> iteration:  225  partial loss: 0.2514448\n",
            "---> iteration:  226  partial loss: 0.242192\n",
            "---> iteration:  227  partial loss: 0.42345065\n",
            "---> iteration:  228  partial loss: 0.29023853\n",
            "---> iteration:  229  partial loss: 0.13270126\n",
            "---> iteration:  230  partial loss: 0.21987775\n",
            "---> iteration:  231  partial loss: 0.21312086\n",
            "---> iteration:  232  partial loss: 0.18434325\n",
            "---> iteration:  233  partial loss: 0.13442\n",
            "---> iteration:  234  partial loss: 0.25567335\n",
            "---> iteration:  235  partial loss: 0.26898047\n",
            "---> iteration:  236  partial loss: 0.17260377\n",
            "---> iteration:  237  partial loss: 0.2200812\n",
            "---> iteration:  238  partial loss: 0.22306472\n",
            "---> iteration:  239  partial loss: 0.17894182\n",
            "---> iteration:  240  partial loss: 0.18663774\n",
            "---> iteration:  241  partial loss: 0.2052662\n",
            "---> iteration:  242  partial loss: 0.38585505\n",
            "---> iteration:  243  partial loss: 0.24460576\n",
            "---> iteration:  244  partial loss: 0.25662446\n",
            "---> iteration:  245  partial loss: 0.24773873\n",
            "---> iteration:  246  partial loss: 0.25694603\n",
            "---> iteration:  247  partial loss: 0.3521612\n",
            "---> iteration:  248  partial loss: 0.22938152\n",
            "---> iteration:  249  partial loss: 0.24071664\n",
            "---> iteration:  250  partial loss: 0.22192451\n",
            "---> iteration:  251  partial loss: 0.21789928\n",
            "---> iteration:  252  partial loss: 0.3694903\n",
            "---> iteration:  253  partial loss: 0.14505678\n",
            "---> iteration:  254  partial loss: 0.22728437\n",
            "---> iteration:  255  partial loss: 0.2885377\n",
            "---> iteration:  256  partial loss: 0.14872421\n",
            "---> iteration:  257  partial loss: 0.2620476\n",
            "---> iteration:  258  partial loss: 0.19501585\n",
            "---> iteration:  259  partial loss: 0.29127988\n",
            "---> iteration:  260  partial loss: 0.21773097\n",
            "---> iteration:  261  partial loss: 0.18635233\n",
            "---> iteration:  262  partial loss: 0.19935772\n",
            "---> iteration:  263  partial loss: 0.38487294\n",
            "---> iteration:  264  partial loss: 0.28902924\n",
            "---> iteration:  265  partial loss: 0.17561804\n",
            "---> iteration:  266  partial loss: 0.30359486\n",
            "---> iteration:  267  partial loss: 0.1881584\n",
            "---> iteration:  268  partial loss: 0.12959188\n",
            "---> iteration:  269  partial loss: 0.096871875\n",
            "---> iteration:  270  partial loss: 0.21559335\n",
            "---> iteration:  271  partial loss: 0.09665095\n",
            "---> iteration:  272  partial loss: 0.11178644\n",
            "---> iteration:  273  partial loss: 0.31007543\n",
            "---> iteration:  274  partial loss: 0.23360418\n",
            "---> iteration:  275  partial loss: 0.28179458\n",
            "---> iteration:  276  partial loss: 0.22937153\n",
            "---> iteration:  277  partial loss: 0.27500656\n",
            "---> iteration:  278  partial loss: 0.23228855\n",
            "---> iteration:  279  partial loss: 0.2781928\n",
            "---> iteration:  280  partial loss: 0.24220295\n",
            "---> iteration:  281  partial loss: 0.17638247\n",
            "---> iteration:  282  partial loss: 0.23163852\n",
            "---> iteration:  283  partial loss: 0.118276\n",
            "---> iteration:  284  partial loss: 0.14847104\n",
            "---> iteration:  285  partial loss: 0.3137977\n",
            "---> iteration:  286  partial loss: 0.18482526\n",
            "---> iteration:  287  partial loss: 0.3114011\n",
            "---> iteration:  288  partial loss: 0.35548007\n",
            "---> iteration:  289  partial loss: 0.34014493\n",
            "------------------\n",
            "epoch:  3  of  20 training loss:  0.2810078793331001\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.12849827\n",
            "---> iteration:  2  partial loss: 0.20059107\n",
            "---> iteration:  3  partial loss: 0.33818755\n",
            "---> iteration:  4  partial loss: 0.39797083\n",
            "---> iteration:  5  partial loss: 0.27574328\n",
            "---> iteration:  6  partial loss: 0.19262832\n",
            "---> iteration:  7  partial loss: 0.19069515\n",
            "---> iteration:  8  partial loss: 0.15055333\n",
            "---> iteration:  9  partial loss: 0.26223975\n",
            "---> iteration:  10  partial loss: 0.2722037\n",
            "---> iteration:  11  partial loss: 0.27647656\n",
            "---> iteration:  12  partial loss: 0.3935874\n",
            "---> iteration:  13  partial loss: 0.2023091\n",
            "---> iteration:  14  partial loss: 0.17327975\n",
            "---> iteration:  15  partial loss: 0.17848693\n",
            "---> iteration:  16  partial loss: 0.23160617\n",
            "---> iteration:  17  partial loss: 0.14843425\n",
            "---> iteration:  18  partial loss: 0.24996682\n",
            "---> iteration:  19  partial loss: 0.2471799\n",
            "---> iteration:  20  partial loss: 0.38333434\n",
            "---> iteration:  21  partial loss: 0.17286831\n",
            "---> iteration:  22  partial loss: 0.24775535\n",
            "---> iteration:  23  partial loss: 0.087404884\n",
            "---> iteration:  24  partial loss: 0.22223167\n",
            "---> iteration:  25  partial loss: 0.26967874\n",
            "---> iteration:  26  partial loss: 0.24194753\n",
            "---> iteration:  27  partial loss: 0.115625024\n",
            "---> iteration:  28  partial loss: 0.21418375\n",
            "---> iteration:  29  partial loss: 0.24217182\n",
            "---> iteration:  30  partial loss: 0.19342685\n",
            "---> iteration:  31  partial loss: 0.16156125\n",
            "---> iteration:  32  partial loss: 0.36989263\n",
            "---> iteration:  33  partial loss: 0.42790878\n",
            "---> iteration:  34  partial loss: 0.5684337\n",
            "---> iteration:  35  partial loss: 0.2426247\n",
            "---> iteration:  36  partial loss: 0.39588273\n",
            "---> iteration:  37  partial loss: 0.16881368\n",
            "---> iteration:  38  partial loss: 0.15614104\n",
            "---> iteration:  39  partial loss: 0.29040587\n",
            "---> iteration:  40  partial loss: 0.27248624\n",
            "---> iteration:  41  partial loss: 0.36601818\n",
            "---> iteration:  42  partial loss: 0.10850862\n",
            "---> iteration:  43  partial loss: 0.28160068\n",
            "---> iteration:  44  partial loss: 0.26175958\n",
            "---> iteration:  45  partial loss: 0.18897073\n",
            "---> iteration:  46  partial loss: 0.1545881\n",
            "---> iteration:  47  partial loss: 0.36059478\n",
            "---> iteration:  48  partial loss: 0.3226368\n",
            "---> iteration:  49  partial loss: 0.31890506\n",
            "---> iteration:  50  partial loss: 0.26221272\n",
            "---> iteration:  51  partial loss: 0.22488526\n",
            "---> iteration:  52  partial loss: 0.23221307\n",
            "---> iteration:  53  partial loss: 0.12682942\n",
            "---> iteration:  54  partial loss: 0.21350297\n",
            "---> iteration:  55  partial loss: 0.23574442\n",
            "---> iteration:  56  partial loss: 0.15666755\n",
            "---> iteration:  57  partial loss: 0.24597809\n",
            "---> iteration:  58  partial loss: 0.2962599\n",
            "---> iteration:  59  partial loss: 0.43862665\n",
            "---> iteration:  60  partial loss: 0.18994607\n",
            "---> iteration:  61  partial loss: 0.37514725\n",
            "---> iteration:  62  partial loss: 0.13975717\n",
            "---> iteration:  63  partial loss: 0.19438557\n",
            "---> iteration:  64  partial loss: 0.25889897\n",
            "---> iteration:  65  partial loss: 0.2719346\n",
            "---> iteration:  66  partial loss: 0.2090173\n",
            "---> iteration:  67  partial loss: 0.23791648\n",
            "---> iteration:  68  partial loss: 0.22141302\n",
            "---> iteration:  69  partial loss: 0.34231436\n",
            "---> iteration:  70  partial loss: 0.17013606\n",
            "---> iteration:  71  partial loss: 0.25406307\n",
            "---> iteration:  72  partial loss: 0.29614574\n",
            "---> iteration:  73  partial loss: 0.21316156\n",
            "---> iteration:  74  partial loss: 0.18445978\n",
            "---> iteration:  75  partial loss: 0.14879881\n",
            "---> iteration:  76  partial loss: 0.17074515\n",
            "---> iteration:  77  partial loss: 0.23196869\n",
            "---> iteration:  78  partial loss: 0.23199941\n",
            "---> iteration:  79  partial loss: 0.18173781\n",
            "---> iteration:  80  partial loss: 0.20403822\n",
            "---> iteration:  81  partial loss: 0.23235261\n",
            "---> iteration:  82  partial loss: 0.21466558\n",
            "---> iteration:  83  partial loss: 0.37447008\n",
            "---> iteration:  84  partial loss: 0.22564575\n",
            "---> iteration:  85  partial loss: 0.16213295\n",
            "---> iteration:  86  partial loss: 0.084680766\n",
            "---> iteration:  87  partial loss: 0.20590223\n",
            "---> iteration:  88  partial loss: 0.20877036\n",
            "---> iteration:  89  partial loss: 0.17252623\n",
            "---> iteration:  90  partial loss: 0.21824792\n",
            "---> iteration:  91  partial loss: 0.23172751\n",
            "---> iteration:  92  partial loss: 0.24105327\n",
            "---> iteration:  93  partial loss: 0.11218084\n",
            "---> iteration:  94  partial loss: 0.19122782\n",
            "---> iteration:  95  partial loss: 0.10037143\n",
            "---> iteration:  96  partial loss: 0.14441009\n",
            "---> iteration:  97  partial loss: 0.2667807\n",
            "---> iteration:  98  partial loss: 0.19869739\n",
            "---> iteration:  99  partial loss: 0.31112954\n",
            "---> iteration:  100  partial loss: 0.16889532\n",
            "---> iteration:  101  partial loss: 0.19074702\n",
            "---> iteration:  102  partial loss: 0.16049977\n",
            "---> iteration:  103  partial loss: 0.11686184\n",
            "---> iteration:  104  partial loss: 0.16628009\n",
            "---> iteration:  105  partial loss: 0.26519895\n",
            "---> iteration:  106  partial loss: 0.17568268\n",
            "---> iteration:  107  partial loss: 0.16213694\n",
            "---> iteration:  108  partial loss: 0.11228311\n",
            "---> iteration:  109  partial loss: 0.13418797\n",
            "---> iteration:  110  partial loss: 0.14298554\n",
            "---> iteration:  111  partial loss: 0.368219\n",
            "---> iteration:  112  partial loss: 0.18703309\n",
            "---> iteration:  113  partial loss: 0.2537335\n",
            "---> iteration:  114  partial loss: 0.108750336\n",
            "---> iteration:  115  partial loss: 0.17322637\n",
            "---> iteration:  116  partial loss: 0.42271882\n",
            "---> iteration:  117  partial loss: 0.10170663\n",
            "---> iteration:  118  partial loss: 0.24429466\n",
            "---> iteration:  119  partial loss: 0.13675179\n",
            "---> iteration:  120  partial loss: 0.15841953\n",
            "---> iteration:  121  partial loss: 0.19758871\n",
            "---> iteration:  122  partial loss: 0.14831212\n",
            "---> iteration:  123  partial loss: 0.13776422\n",
            "---> iteration:  124  partial loss: 0.12168352\n",
            "---> iteration:  125  partial loss: 0.19315028\n",
            "---> iteration:  126  partial loss: 0.22843789\n",
            "---> iteration:  127  partial loss: 0.21775492\n",
            "---> iteration:  128  partial loss: 0.0962222\n",
            "---> iteration:  129  partial loss: 0.25585938\n",
            "---> iteration:  130  partial loss: 0.09131189\n",
            "---> iteration:  131  partial loss: 0.17739832\n",
            "---> iteration:  132  partial loss: 0.17412099\n",
            "---> iteration:  133  partial loss: 0.100960374\n",
            "---> iteration:  134  partial loss: 0.42851308\n",
            "---> iteration:  135  partial loss: 0.29790232\n",
            "---> iteration:  136  partial loss: 0.22841394\n",
            "---> iteration:  137  partial loss: 0.22785322\n",
            "---> iteration:  138  partial loss: 0.15693851\n",
            "---> iteration:  139  partial loss: 0.1457083\n",
            "---> iteration:  140  partial loss: 0.19619446\n",
            "---> iteration:  141  partial loss: 0.37276638\n",
            "---> iteration:  142  partial loss: 0.26472867\n",
            "---> iteration:  143  partial loss: 0.10108948\n",
            "---> iteration:  144  partial loss: 0.26160106\n",
            "---> iteration:  145  partial loss: 0.2667014\n",
            "---> iteration:  146  partial loss: 0.1984426\n",
            "---> iteration:  147  partial loss: 0.2274089\n",
            "---> iteration:  148  partial loss: 0.18281756\n",
            "---> iteration:  149  partial loss: 0.22068094\n",
            "---> iteration:  150  partial loss: 0.17664865\n",
            "---> iteration:  151  partial loss: 0.21741089\n",
            "---> iteration:  152  partial loss: 0.13975106\n",
            "---> iteration:  153  partial loss: 0.14636731\n",
            "---> iteration:  154  partial loss: 0.20962806\n",
            "---> iteration:  155  partial loss: 0.13048768\n",
            "---> iteration:  156  partial loss: 0.17538257\n",
            "---> iteration:  157  partial loss: 0.2820808\n",
            "---> iteration:  158  partial loss: 0.14765885\n",
            "---> iteration:  159  partial loss: 0.19643062\n",
            "---> iteration:  160  partial loss: 0.14893797\n",
            "---> iteration:  161  partial loss: 0.12059927\n",
            "---> iteration:  162  partial loss: 0.17625555\n",
            "---> iteration:  163  partial loss: 0.17592616\n",
            "---> iteration:  164  partial loss: 0.22918633\n",
            "---> iteration:  165  partial loss: 0.13094491\n",
            "---> iteration:  166  partial loss: 0.17297289\n",
            "---> iteration:  167  partial loss: 0.18257077\n",
            "---> iteration:  168  partial loss: 0.23135822\n",
            "---> iteration:  169  partial loss: 0.15419716\n",
            "---> iteration:  170  partial loss: 0.30459434\n",
            "---> iteration:  171  partial loss: 0.21065606\n",
            "---> iteration:  172  partial loss: 0.184498\n",
            "---> iteration:  173  partial loss: 0.19429223\n",
            "---> iteration:  174  partial loss: 0.27533132\n",
            "---> iteration:  175  partial loss: 0.16202271\n",
            "---> iteration:  176  partial loss: 0.42046517\n",
            "---> iteration:  177  partial loss: 0.29795393\n",
            "---> iteration:  178  partial loss: 0.15775667\n",
            "---> iteration:  179  partial loss: 0.19149043\n",
            "---> iteration:  180  partial loss: 0.10897825\n",
            "---> iteration:  181  partial loss: 0.27148592\n",
            "---> iteration:  182  partial loss: 0.22768548\n",
            "---> iteration:  183  partial loss: 0.2988466\n",
            "---> iteration:  184  partial loss: 0.1575909\n",
            "---> iteration:  185  partial loss: 0.2129356\n",
            "---> iteration:  186  partial loss: 0.24274614\n",
            "---> iteration:  187  partial loss: 0.18040653\n",
            "---> iteration:  188  partial loss: 0.17951784\n",
            "---> iteration:  189  partial loss: 0.1807257\n",
            "---> iteration:  190  partial loss: 0.2190473\n",
            "---> iteration:  191  partial loss: 0.22237918\n",
            "---> iteration:  192  partial loss: 0.09765501\n",
            "---> iteration:  193  partial loss: 0.27640486\n",
            "---> iteration:  194  partial loss: 0.22455367\n",
            "---> iteration:  195  partial loss: 0.20589527\n",
            "---> iteration:  196  partial loss: 0.1604007\n",
            "---> iteration:  197  partial loss: 0.15879816\n",
            "---> iteration:  198  partial loss: 0.10627774\n",
            "---> iteration:  199  partial loss: 0.15224938\n",
            "---> iteration:  200  partial loss: 0.21290635\n",
            "---> iteration:  201  partial loss: 0.36049896\n",
            "---> iteration:  202  partial loss: 0.1768916\n",
            "---> iteration:  203  partial loss: 0.15757474\n",
            "---> iteration:  204  partial loss: 0.18949063\n",
            "---> iteration:  205  partial loss: 0.2931945\n",
            "---> iteration:  206  partial loss: 0.27721316\n",
            "---> iteration:  207  partial loss: 0.25715128\n",
            "---> iteration:  208  partial loss: 0.1349846\n",
            "---> iteration:  209  partial loss: 0.18429706\n",
            "---> iteration:  210  partial loss: 0.2199558\n",
            "---> iteration:  211  partial loss: 0.17123382\n",
            "---> iteration:  212  partial loss: 0.16703884\n",
            "---> iteration:  213  partial loss: 0.22174247\n",
            "---> iteration:  214  partial loss: 0.22546221\n",
            "---> iteration:  215  partial loss: 0.16748971\n",
            "---> iteration:  216  partial loss: 0.19466361\n",
            "---> iteration:  217  partial loss: 0.34927478\n",
            "---> iteration:  218  partial loss: 0.19677675\n",
            "---> iteration:  219  partial loss: 0.14195554\n",
            "---> iteration:  220  partial loss: 0.15803663\n",
            "---> iteration:  221  partial loss: 0.15300746\n",
            "---> iteration:  222  partial loss: 0.23468721\n",
            "---> iteration:  223  partial loss: 0.10701936\n",
            "---> iteration:  224  partial loss: 0.2252676\n",
            "---> iteration:  225  partial loss: 0.1432641\n",
            "---> iteration:  226  partial loss: 0.2259535\n",
            "---> iteration:  227  partial loss: 0.18538657\n",
            "---> iteration:  228  partial loss: 0.14609338\n",
            "---> iteration:  229  partial loss: 0.17428264\n",
            "---> iteration:  230  partial loss: 0.122709125\n",
            "---> iteration:  231  partial loss: 0.13106224\n",
            "---> iteration:  232  partial loss: 0.1653413\n",
            "---> iteration:  233  partial loss: 0.1452559\n",
            "---> iteration:  234  partial loss: 0.28588066\n",
            "---> iteration:  235  partial loss: 0.299308\n",
            "---> iteration:  236  partial loss: 0.17817561\n",
            "---> iteration:  237  partial loss: 0.12271666\n",
            "---> iteration:  238  partial loss: 0.20134912\n",
            "---> iteration:  239  partial loss: 0.43365288\n",
            "---> iteration:  240  partial loss: 0.19419348\n",
            "---> iteration:  241  partial loss: 0.13500716\n",
            "---> iteration:  242  partial loss: 0.17949024\n",
            "---> iteration:  243  partial loss: 0.075581945\n",
            "---> iteration:  244  partial loss: 0.32614258\n",
            "---> iteration:  245  partial loss: 0.18601172\n",
            "---> iteration:  246  partial loss: 0.20746985\n",
            "---> iteration:  247  partial loss: 0.1632212\n",
            "---> iteration:  248  partial loss: 0.19903566\n",
            "---> iteration:  249  partial loss: 0.3281921\n",
            "---> iteration:  250  partial loss: 0.22486109\n",
            "---> iteration:  251  partial loss: 0.1793215\n",
            "---> iteration:  252  partial loss: 0.20773938\n",
            "---> iteration:  253  partial loss: 0.1808261\n",
            "---> iteration:  254  partial loss: 0.15325196\n",
            "---> iteration:  255  partial loss: 0.24949697\n",
            "---> iteration:  256  partial loss: 0.18705419\n",
            "---> iteration:  257  partial loss: 0.18503532\n",
            "---> iteration:  258  partial loss: 0.19751011\n",
            "---> iteration:  259  partial loss: 0.14360367\n",
            "---> iteration:  260  partial loss: 0.14439172\n",
            "---> iteration:  261  partial loss: 0.13166788\n",
            "---> iteration:  262  partial loss: 0.147947\n",
            "---> iteration:  263  partial loss: 0.23446931\n",
            "---> iteration:  264  partial loss: 0.08021935\n",
            "---> iteration:  265  partial loss: 0.20780815\n",
            "---> iteration:  266  partial loss: 0.16113445\n",
            "---> iteration:  267  partial loss: 0.15954195\n",
            "---> iteration:  268  partial loss: 0.28078076\n",
            "---> iteration:  269  partial loss: 0.16314127\n",
            "---> iteration:  270  partial loss: 0.19668257\n",
            "---> iteration:  271  partial loss: 0.13388237\n",
            "---> iteration:  272  partial loss: 0.18015993\n",
            "---> iteration:  273  partial loss: 0.1403671\n",
            "---> iteration:  274  partial loss: 0.17228685\n",
            "---> iteration:  275  partial loss: 0.1687633\n",
            "---> iteration:  276  partial loss: 0.16294166\n",
            "---> iteration:  277  partial loss: 0.19792221\n",
            "---> iteration:  278  partial loss: 0.11363303\n",
            "---> iteration:  279  partial loss: 0.13246131\n",
            "---> iteration:  280  partial loss: 0.070412755\n",
            "---> iteration:  281  partial loss: 0.18706144\n",
            "---> iteration:  282  partial loss: 0.15356107\n",
            "---> iteration:  283  partial loss: 0.19199483\n",
            "---> iteration:  284  partial loss: 0.33222175\n",
            "---> iteration:  285  partial loss: 0.23220916\n",
            "---> iteration:  286  partial loss: 0.19766003\n",
            "---> iteration:  287  partial loss: 0.23725113\n",
            "---> iteration:  288  partial loss: 0.15416268\n",
            "---> iteration:  289  partial loss: 0.21040861\n",
            "------------------\n",
            "epoch:  4  of  20 training loss:  0.20897125022221602\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.17391983\n",
            "---> iteration:  2  partial loss: 0.1737463\n",
            "---> iteration:  3  partial loss: 0.12636852\n",
            "---> iteration:  4  partial loss: 0.17262831\n",
            "---> iteration:  5  partial loss: 0.17568766\n",
            "---> iteration:  6  partial loss: 0.16710904\n",
            "---> iteration:  7  partial loss: 0.20956402\n",
            "---> iteration:  8  partial loss: 0.2210334\n",
            "---> iteration:  9  partial loss: 0.11786546\n",
            "---> iteration:  10  partial loss: 0.13926254\n",
            "---> iteration:  11  partial loss: 0.1270726\n",
            "---> iteration:  12  partial loss: 0.14356448\n",
            "---> iteration:  13  partial loss: 0.07313464\n",
            "---> iteration:  14  partial loss: 0.12534672\n",
            "---> iteration:  15  partial loss: 0.13909307\n",
            "---> iteration:  16  partial loss: 0.16212046\n",
            "---> iteration:  17  partial loss: 0.18541849\n",
            "---> iteration:  18  partial loss: 0.37062284\n",
            "---> iteration:  19  partial loss: 0.110114455\n",
            "---> iteration:  20  partial loss: 0.18461066\n",
            "---> iteration:  21  partial loss: 0.23007336\n",
            "---> iteration:  22  partial loss: 0.18410191\n",
            "---> iteration:  23  partial loss: 0.24100047\n",
            "---> iteration:  24  partial loss: 0.15196706\n",
            "---> iteration:  25  partial loss: 0.08152617\n",
            "---> iteration:  26  partial loss: 0.12068401\n",
            "---> iteration:  27  partial loss: 0.11007321\n",
            "---> iteration:  28  partial loss: 0.16660161\n",
            "---> iteration:  29  partial loss: 0.14574511\n",
            "---> iteration:  30  partial loss: 0.15305711\n",
            "---> iteration:  31  partial loss: 0.14754906\n",
            "---> iteration:  32  partial loss: 0.2957641\n",
            "---> iteration:  33  partial loss: 0.12047556\n",
            "---> iteration:  34  partial loss: 0.14729589\n",
            "---> iteration:  35  partial loss: 0.15455052\n",
            "---> iteration:  36  partial loss: 0.07718526\n",
            "---> iteration:  37  partial loss: 0.11520871\n",
            "---> iteration:  38  partial loss: 0.1453393\n",
            "---> iteration:  39  partial loss: 0.14987528\n",
            "---> iteration:  40  partial loss: 0.20105974\n",
            "---> iteration:  41  partial loss: 0.36773974\n",
            "---> iteration:  42  partial loss: 0.19082135\n",
            "---> iteration:  43  partial loss: 0.13916934\n",
            "---> iteration:  44  partial loss: 0.15223148\n",
            "---> iteration:  45  partial loss: 0.20712297\n",
            "---> iteration:  46  partial loss: 0.21420956\n",
            "---> iteration:  47  partial loss: 0.1687363\n",
            "---> iteration:  48  partial loss: 0.27807644\n",
            "---> iteration:  49  partial loss: 0.17513186\n",
            "---> iteration:  50  partial loss: 0.13424772\n",
            "---> iteration:  51  partial loss: 0.08217308\n",
            "---> iteration:  52  partial loss: 0.067407005\n",
            "---> iteration:  53  partial loss: 0.251972\n",
            "---> iteration:  54  partial loss: 0.17130056\n",
            "---> iteration:  55  partial loss: 0.18317477\n",
            "---> iteration:  56  partial loss: 0.21986595\n",
            "---> iteration:  57  partial loss: 0.27521858\n",
            "---> iteration:  58  partial loss: 0.14523458\n",
            "---> iteration:  59  partial loss: 0.17557721\n",
            "---> iteration:  60  partial loss: 0.1953043\n",
            "---> iteration:  61  partial loss: 0.20498887\n",
            "---> iteration:  62  partial loss: 0.213378\n",
            "---> iteration:  63  partial loss: 0.22590853\n",
            "---> iteration:  64  partial loss: 0.10992623\n",
            "---> iteration:  65  partial loss: 0.20849423\n",
            "---> iteration:  66  partial loss: 0.1365621\n",
            "---> iteration:  67  partial loss: 0.20843798\n",
            "---> iteration:  68  partial loss: 0.102839\n",
            "---> iteration:  69  partial loss: 0.22721036\n",
            "---> iteration:  70  partial loss: 0.10841772\n",
            "---> iteration:  71  partial loss: 0.17924902\n",
            "---> iteration:  72  partial loss: 0.206615\n",
            "---> iteration:  73  partial loss: 0.15549332\n",
            "---> iteration:  74  partial loss: 0.12317066\n",
            "---> iteration:  75  partial loss: 0.17928551\n",
            "---> iteration:  76  partial loss: 0.10816311\n",
            "---> iteration:  77  partial loss: 0.16663285\n",
            "---> iteration:  78  partial loss: 0.3975543\n",
            "---> iteration:  79  partial loss: 0.13285597\n",
            "---> iteration:  80  partial loss: 0.1867204\n",
            "---> iteration:  81  partial loss: 0.15209953\n",
            "---> iteration:  82  partial loss: 0.139884\n",
            "---> iteration:  83  partial loss: 0.22399831\n",
            "---> iteration:  84  partial loss: 0.120252006\n",
            "---> iteration:  85  partial loss: 0.11847886\n",
            "---> iteration:  86  partial loss: 0.11565151\n",
            "---> iteration:  87  partial loss: 0.07315555\n",
            "---> iteration:  88  partial loss: 0.15307212\n",
            "---> iteration:  89  partial loss: 0.12628555\n",
            "---> iteration:  90  partial loss: 0.18234141\n",
            "---> iteration:  91  partial loss: 0.11565849\n",
            "---> iteration:  92  partial loss: 0.19153917\n",
            "---> iteration:  93  partial loss: 0.06845648\n",
            "---> iteration:  94  partial loss: 0.19893909\n",
            "---> iteration:  95  partial loss: 0.1332435\n",
            "---> iteration:  96  partial loss: 0.22523524\n",
            "---> iteration:  97  partial loss: 0.35603395\n",
            "---> iteration:  98  partial loss: 0.07587102\n",
            "---> iteration:  99  partial loss: 0.20887998\n",
            "---> iteration:  100  partial loss: 0.1043116\n",
            "---> iteration:  101  partial loss: 0.14608352\n",
            "---> iteration:  102  partial loss: 0.12851158\n",
            "---> iteration:  103  partial loss: 0.15653148\n",
            "---> iteration:  104  partial loss: 0.07621074\n",
            "---> iteration:  105  partial loss: 0.23515782\n",
            "---> iteration:  106  partial loss: 0.24708311\n",
            "---> iteration:  107  partial loss: 0.15094733\n",
            "---> iteration:  108  partial loss: 0.15339817\n",
            "---> iteration:  109  partial loss: 0.15583766\n",
            "---> iteration:  110  partial loss: 0.10543818\n",
            "---> iteration:  111  partial loss: 0.2037654\n",
            "---> iteration:  112  partial loss: 0.58322847\n",
            "---> iteration:  113  partial loss: 0.19211379\n",
            "---> iteration:  114  partial loss: 0.18070988\n",
            "---> iteration:  115  partial loss: 0.09737234\n",
            "---> iteration:  116  partial loss: 0.2865442\n",
            "---> iteration:  117  partial loss: 0.114793755\n",
            "---> iteration:  118  partial loss: 0.22500384\n",
            "---> iteration:  119  partial loss: 0.083726734\n",
            "---> iteration:  120  partial loss: 0.21407992\n",
            "---> iteration:  121  partial loss: 0.10525412\n",
            "---> iteration:  122  partial loss: 0.20043\n",
            "---> iteration:  123  partial loss: 0.16395156\n",
            "---> iteration:  124  partial loss: 0.124144405\n",
            "---> iteration:  125  partial loss: 0.14456029\n",
            "---> iteration:  126  partial loss: 0.18352906\n",
            "---> iteration:  127  partial loss: 0.18865217\n",
            "---> iteration:  128  partial loss: 0.10860682\n",
            "---> iteration:  129  partial loss: 0.15495694\n",
            "---> iteration:  130  partial loss: 0.25974986\n",
            "---> iteration:  131  partial loss: 0.10216146\n",
            "---> iteration:  132  partial loss: 0.13877144\n",
            "---> iteration:  133  partial loss: 0.21065372\n",
            "---> iteration:  134  partial loss: 0.14113623\n",
            "---> iteration:  135  partial loss: 0.122040264\n",
            "---> iteration:  136  partial loss: 0.1905776\n",
            "---> iteration:  137  partial loss: 0.1442101\n",
            "---> iteration:  138  partial loss: 0.26494056\n",
            "---> iteration:  139  partial loss: 0.08958628\n",
            "---> iteration:  140  partial loss: 0.124946296\n",
            "---> iteration:  141  partial loss: 0.090973325\n",
            "---> iteration:  142  partial loss: 0.17873946\n",
            "---> iteration:  143  partial loss: 0.17128165\n",
            "---> iteration:  144  partial loss: 0.16424571\n",
            "---> iteration:  145  partial loss: 0.2198828\n",
            "---> iteration:  146  partial loss: 0.15488017\n",
            "---> iteration:  147  partial loss: 0.16960917\n",
            "---> iteration:  148  partial loss: 0.0958613\n",
            "---> iteration:  149  partial loss: 0.13162749\n",
            "---> iteration:  150  partial loss: 0.15315568\n",
            "---> iteration:  151  partial loss: 0.17663038\n",
            "---> iteration:  152  partial loss: 0.17705725\n",
            "---> iteration:  153  partial loss: 0.35692725\n",
            "---> iteration:  154  partial loss: 0.17559165\n",
            "---> iteration:  155  partial loss: 0.15943138\n",
            "---> iteration:  156  partial loss: 0.19088432\n",
            "---> iteration:  157  partial loss: 0.19911797\n",
            "---> iteration:  158  partial loss: 0.17999995\n",
            "---> iteration:  159  partial loss: 0.15087596\n",
            "---> iteration:  160  partial loss: 0.16114427\n",
            "---> iteration:  161  partial loss: 0.17175601\n",
            "---> iteration:  162  partial loss: 0.15792088\n",
            "---> iteration:  163  partial loss: 0.2706884\n",
            "---> iteration:  164  partial loss: 0.16403218\n",
            "---> iteration:  165  partial loss: 0.1384641\n",
            "---> iteration:  166  partial loss: 0.09452233\n",
            "---> iteration:  167  partial loss: 0.39235178\n",
            "---> iteration:  168  partial loss: 0.42797983\n",
            "---> iteration:  169  partial loss: 0.24446738\n",
            "---> iteration:  170  partial loss: 0.12905575\n",
            "---> iteration:  171  partial loss: 0.14556095\n",
            "---> iteration:  172  partial loss: 0.26109076\n",
            "---> iteration:  173  partial loss: 0.096913084\n",
            "---> iteration:  174  partial loss: 0.21473694\n",
            "---> iteration:  175  partial loss: 0.10524055\n",
            "---> iteration:  176  partial loss: 0.16783169\n",
            "---> iteration:  177  partial loss: 0.16089384\n",
            "---> iteration:  178  partial loss: 0.26774436\n",
            "---> iteration:  179  partial loss: 0.12138602\n",
            "---> iteration:  180  partial loss: 0.13539262\n",
            "---> iteration:  181  partial loss: 0.15172872\n",
            "---> iteration:  182  partial loss: 0.16735879\n",
            "---> iteration:  183  partial loss: 0.15622658\n",
            "---> iteration:  184  partial loss: 0.1603022\n",
            "---> iteration:  185  partial loss: 0.20157379\n",
            "---> iteration:  186  partial loss: 0.10360088\n",
            "---> iteration:  187  partial loss: 0.18697518\n",
            "---> iteration:  188  partial loss: 0.1377829\n",
            "---> iteration:  189  partial loss: 0.119516596\n",
            "---> iteration:  190  partial loss: 0.24781999\n",
            "---> iteration:  191  partial loss: 0.12259893\n",
            "---> iteration:  192  partial loss: 0.2544607\n",
            "---> iteration:  193  partial loss: 0.15676911\n",
            "---> iteration:  194  partial loss: 0.12268225\n",
            "---> iteration:  195  partial loss: 0.15281516\n",
            "---> iteration:  196  partial loss: 0.19081572\n",
            "---> iteration:  197  partial loss: 0.10458969\n",
            "---> iteration:  198  partial loss: 0.14575692\n",
            "---> iteration:  199  partial loss: 0.15363775\n",
            "---> iteration:  200  partial loss: 0.07966933\n",
            "---> iteration:  201  partial loss: 0.13092694\n",
            "---> iteration:  202  partial loss: 0.106048256\n",
            "---> iteration:  203  partial loss: 0.10229974\n",
            "---> iteration:  204  partial loss: 0.11959849\n",
            "---> iteration:  205  partial loss: 0.23868565\n",
            "---> iteration:  206  partial loss: 0.1385646\n",
            "---> iteration:  207  partial loss: 0.05943021\n",
            "---> iteration:  208  partial loss: 0.19949125\n",
            "---> iteration:  209  partial loss: 0.08107885\n",
            "---> iteration:  210  partial loss: 0.19808076\n",
            "---> iteration:  211  partial loss: 0.2222307\n",
            "---> iteration:  212  partial loss: 0.20579945\n",
            "---> iteration:  213  partial loss: 0.12840612\n",
            "---> iteration:  214  partial loss: 0.12999384\n",
            "---> iteration:  215  partial loss: 0.11253016\n",
            "---> iteration:  216  partial loss: 0.15491554\n",
            "---> iteration:  217  partial loss: 0.18820104\n",
            "---> iteration:  218  partial loss: 0.26310027\n",
            "---> iteration:  219  partial loss: 0.23660016\n",
            "---> iteration:  220  partial loss: 0.09376042\n",
            "---> iteration:  221  partial loss: 0.21966071\n",
            "---> iteration:  222  partial loss: 0.102870435\n",
            "---> iteration:  223  partial loss: 0.24415572\n",
            "---> iteration:  224  partial loss: 0.17720683\n",
            "---> iteration:  225  partial loss: 0.17710854\n",
            "---> iteration:  226  partial loss: 0.13082771\n",
            "---> iteration:  227  partial loss: 0.08895088\n",
            "---> iteration:  228  partial loss: 0.14482294\n",
            "---> iteration:  229  partial loss: 0.12562495\n",
            "---> iteration:  230  partial loss: 0.1798451\n",
            "---> iteration:  231  partial loss: 0.112984106\n",
            "---> iteration:  232  partial loss: 0.12967232\n",
            "---> iteration:  233  partial loss: 0.20372711\n",
            "---> iteration:  234  partial loss: 0.21835984\n",
            "---> iteration:  235  partial loss: 0.13469933\n",
            "---> iteration:  236  partial loss: 0.19618079\n",
            "---> iteration:  237  partial loss: 0.081612594\n",
            "---> iteration:  238  partial loss: 0.17858073\n",
            "---> iteration:  239  partial loss: 0.13259576\n",
            "---> iteration:  240  partial loss: 0.1170234\n",
            "---> iteration:  241  partial loss: 0.12032748\n",
            "---> iteration:  242  partial loss: 0.12631372\n",
            "---> iteration:  243  partial loss: 0.14326195\n",
            "---> iteration:  244  partial loss: 0.12730849\n",
            "---> iteration:  245  partial loss: 0.16661029\n",
            "---> iteration:  246  partial loss: 0.2058748\n",
            "---> iteration:  247  partial loss: 0.10139503\n",
            "---> iteration:  248  partial loss: 0.26345363\n",
            "---> iteration:  249  partial loss: 0.16540596\n",
            "---> iteration:  250  partial loss: 0.21196993\n",
            "---> iteration:  251  partial loss: 0.12878735\n",
            "---> iteration:  252  partial loss: 0.15152588\n",
            "---> iteration:  253  partial loss: 0.21165064\n",
            "---> iteration:  254  partial loss: 0.19759992\n",
            "---> iteration:  255  partial loss: 0.21465577\n",
            "---> iteration:  256  partial loss: 0.066101655\n",
            "---> iteration:  257  partial loss: 0.1247209\n",
            "---> iteration:  258  partial loss: 0.113895044\n",
            "---> iteration:  259  partial loss: 0.11099376\n",
            "---> iteration:  260  partial loss: 0.25032568\n",
            "---> iteration:  261  partial loss: 0.20842785\n",
            "---> iteration:  262  partial loss: 0.11490008\n",
            "---> iteration:  263  partial loss: 0.19697258\n",
            "---> iteration:  264  partial loss: 0.16745202\n",
            "---> iteration:  265  partial loss: 0.3862534\n",
            "---> iteration:  266  partial loss: 0.10964329\n",
            "---> iteration:  267  partial loss: 0.11040728\n",
            "---> iteration:  268  partial loss: 0.25322902\n",
            "---> iteration:  269  partial loss: 0.13657942\n",
            "---> iteration:  270  partial loss: 0.1507745\n",
            "---> iteration:  271  partial loss: 0.18803611\n",
            "---> iteration:  272  partial loss: 0.21892077\n",
            "---> iteration:  273  partial loss: 0.19706193\n",
            "---> iteration:  274  partial loss: 0.16972438\n",
            "---> iteration:  275  partial loss: 0.08652207\n",
            "---> iteration:  276  partial loss: 0.097518414\n",
            "---> iteration:  277  partial loss: 0.12958862\n",
            "---> iteration:  278  partial loss: 0.14803787\n",
            "---> iteration:  279  partial loss: 0.15064253\n",
            "---> iteration:  280  partial loss: 0.1569763\n",
            "---> iteration:  281  partial loss: 0.09050007\n",
            "---> iteration:  282  partial loss: 0.38258585\n",
            "---> iteration:  283  partial loss: 0.06677385\n",
            "---> iteration:  284  partial loss: 0.11086195\n",
            "---> iteration:  285  partial loss: 0.05941462\n",
            "---> iteration:  286  partial loss: 0.3194499\n",
            "---> iteration:  287  partial loss: 0.14384927\n",
            "---> iteration:  288  partial loss: 0.11854619\n",
            "---> iteration:  289  partial loss: 0.10023471\n",
            "------------------\n",
            "epoch:  5  of  20 training loss:  0.1675355089087181\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.12849557\n",
            "---> iteration:  2  partial loss: 0.13336642\n",
            "---> iteration:  3  partial loss: 0.07012088\n",
            "---> iteration:  4  partial loss: 0.23398745\n",
            "---> iteration:  5  partial loss: 0.12003457\n",
            "---> iteration:  6  partial loss: 0.16195835\n",
            "---> iteration:  7  partial loss: 0.30948716\n",
            "---> iteration:  8  partial loss: 0.2260027\n",
            "---> iteration:  9  partial loss: 0.14009707\n",
            "---> iteration:  10  partial loss: 0.17680258\n",
            "---> iteration:  11  partial loss: 0.22322392\n",
            "---> iteration:  12  partial loss: 0.15538746\n",
            "---> iteration:  13  partial loss: 0.25952145\n",
            "---> iteration:  14  partial loss: 0.27268282\n",
            "---> iteration:  15  partial loss: 0.081084155\n",
            "---> iteration:  16  partial loss: 0.1300938\n",
            "---> iteration:  17  partial loss: 0.15924953\n",
            "---> iteration:  18  partial loss: 0.14971335\n",
            "---> iteration:  19  partial loss: 0.12785953\n",
            "---> iteration:  20  partial loss: 0.555783\n",
            "---> iteration:  21  partial loss: 0.19300054\n",
            "---> iteration:  22  partial loss: 0.13391148\n",
            "---> iteration:  23  partial loss: 0.21552241\n",
            "---> iteration:  24  partial loss: 0.18230422\n",
            "---> iteration:  25  partial loss: 0.15572543\n",
            "---> iteration:  26  partial loss: 0.18907204\n",
            "---> iteration:  27  partial loss: 0.18700664\n",
            "---> iteration:  28  partial loss: 0.1651879\n",
            "---> iteration:  29  partial loss: 0.13678981\n",
            "---> iteration:  30  partial loss: 0.1714244\n",
            "---> iteration:  31  partial loss: 0.11789786\n",
            "---> iteration:  32  partial loss: 0.08944772\n",
            "---> iteration:  33  partial loss: 0.12443507\n",
            "---> iteration:  34  partial loss: 0.18125759\n",
            "---> iteration:  35  partial loss: 0.13873345\n",
            "---> iteration:  36  partial loss: 0.09016406\n",
            "---> iteration:  37  partial loss: 0.07042706\n",
            "---> iteration:  38  partial loss: 0.21919517\n",
            "---> iteration:  39  partial loss: 0.16997589\n",
            "---> iteration:  40  partial loss: 0.20665672\n",
            "---> iteration:  41  partial loss: 0.18512948\n",
            "---> iteration:  42  partial loss: 0.15352465\n",
            "---> iteration:  43  partial loss: 0.110453986\n",
            "---> iteration:  44  partial loss: 0.12103487\n",
            "---> iteration:  45  partial loss: 0.17596987\n",
            "---> iteration:  46  partial loss: 0.21451248\n",
            "---> iteration:  47  partial loss: 0.31734347\n",
            "---> iteration:  48  partial loss: 0.12900844\n",
            "---> iteration:  49  partial loss: 0.25759947\n",
            "---> iteration:  50  partial loss: 0.078283705\n",
            "---> iteration:  51  partial loss: 0.16495207\n",
            "---> iteration:  52  partial loss: 0.22445984\n",
            "---> iteration:  53  partial loss: 0.17718697\n",
            "---> iteration:  54  partial loss: 0.1086532\n",
            "---> iteration:  55  partial loss: 0.16414109\n",
            "---> iteration:  56  partial loss: 0.062914245\n",
            "---> iteration:  57  partial loss: 0.16665623\n",
            "---> iteration:  58  partial loss: 0.11695786\n",
            "---> iteration:  59  partial loss: 0.13099453\n",
            "---> iteration:  60  partial loss: 0.19113813\n",
            "---> iteration:  61  partial loss: 0.098740354\n",
            "---> iteration:  62  partial loss: 0.065194935\n",
            "---> iteration:  63  partial loss: 0.16530582\n",
            "---> iteration:  64  partial loss: 0.10825655\n",
            "---> iteration:  65  partial loss: 0.22329992\n",
            "---> iteration:  66  partial loss: 0.109262615\n",
            "---> iteration:  67  partial loss: 0.1341966\n",
            "---> iteration:  68  partial loss: 0.16590594\n",
            "---> iteration:  69  partial loss: 0.15633684\n",
            "---> iteration:  70  partial loss: 0.24286215\n",
            "---> iteration:  71  partial loss: 0.14950757\n",
            "---> iteration:  72  partial loss: 0.12124558\n",
            "---> iteration:  73  partial loss: 0.20143467\n",
            "---> iteration:  74  partial loss: 0.17464162\n",
            "---> iteration:  75  partial loss: 0.13197462\n",
            "---> iteration:  76  partial loss: 0.17079714\n",
            "---> iteration:  77  partial loss: 0.13198994\n",
            "---> iteration:  78  partial loss: 0.12776853\n",
            "---> iteration:  79  partial loss: 0.15027788\n",
            "---> iteration:  80  partial loss: 0.33728865\n",
            "---> iteration:  81  partial loss: 0.101939194\n",
            "---> iteration:  82  partial loss: 0.18498462\n",
            "---> iteration:  83  partial loss: 0.11723048\n",
            "---> iteration:  84  partial loss: 0.10649132\n",
            "---> iteration:  85  partial loss: 0.092458114\n",
            "---> iteration:  86  partial loss: 0.2070988\n",
            "---> iteration:  87  partial loss: 0.09188103\n",
            "---> iteration:  88  partial loss: 0.15734597\n",
            "---> iteration:  89  partial loss: 0.13404058\n",
            "---> iteration:  90  partial loss: 0.15030651\n",
            "---> iteration:  91  partial loss: 0.09308275\n",
            "---> iteration:  92  partial loss: 0.23704354\n",
            "---> iteration:  93  partial loss: 0.11967953\n",
            "---> iteration:  94  partial loss: 0.17352295\n",
            "---> iteration:  95  partial loss: 0.16982186\n",
            "---> iteration:  96  partial loss: 0.16994354\n",
            "---> iteration:  97  partial loss: 0.14073794\n",
            "---> iteration:  98  partial loss: 0.29051667\n",
            "---> iteration:  99  partial loss: 0.29208788\n",
            "---> iteration:  100  partial loss: 0.14013876\n",
            "---> iteration:  101  partial loss: 0.27242923\n",
            "---> iteration:  102  partial loss: 0.24339566\n",
            "---> iteration:  103  partial loss: 0.16452502\n",
            "---> iteration:  104  partial loss: 0.20485634\n",
            "---> iteration:  105  partial loss: 0.106191635\n",
            "---> iteration:  106  partial loss: 0.18780693\n",
            "---> iteration:  107  partial loss: 0.14533918\n",
            "---> iteration:  108  partial loss: 0.07684191\n",
            "---> iteration:  109  partial loss: 0.13879035\n",
            "---> iteration:  110  partial loss: 0.18866976\n",
            "---> iteration:  111  partial loss: 0.1691785\n",
            "---> iteration:  112  partial loss: 0.12955062\n",
            "---> iteration:  113  partial loss: 0.23167396\n",
            "---> iteration:  114  partial loss: 0.21121216\n",
            "---> iteration:  115  partial loss: 0.117832705\n",
            "---> iteration:  116  partial loss: 0.07439274\n",
            "---> iteration:  117  partial loss: 0.18654782\n",
            "---> iteration:  118  partial loss: 0.09758834\n",
            "---> iteration:  119  partial loss: 0.09727014\n",
            "---> iteration:  120  partial loss: 0.21853748\n",
            "---> iteration:  121  partial loss: 0.22433832\n",
            "---> iteration:  122  partial loss: 0.17949902\n",
            "---> iteration:  123  partial loss: 0.13762626\n",
            "---> iteration:  124  partial loss: 0.107737385\n",
            "---> iteration:  125  partial loss: 0.05349389\n",
            "---> iteration:  126  partial loss: 0.12394544\n",
            "---> iteration:  127  partial loss: 0.12255116\n",
            "---> iteration:  128  partial loss: 0.12487911\n",
            "---> iteration:  129  partial loss: 0.11483635\n",
            "---> iteration:  130  partial loss: 0.054788627\n",
            "---> iteration:  131  partial loss: 0.14841045\n",
            "---> iteration:  132  partial loss: 0.18450809\n",
            "---> iteration:  133  partial loss: 0.14685698\n",
            "---> iteration:  134  partial loss: 0.2037444\n",
            "---> iteration:  135  partial loss: 0.16307282\n",
            "---> iteration:  136  partial loss: 0.12653826\n",
            "---> iteration:  137  partial loss: 0.120643385\n",
            "---> iteration:  138  partial loss: 0.16493173\n",
            "---> iteration:  139  partial loss: 0.09686455\n",
            "---> iteration:  140  partial loss: 0.106017984\n",
            "---> iteration:  141  partial loss: 0.14850594\n",
            "---> iteration:  142  partial loss: 0.12707837\n",
            "---> iteration:  143  partial loss: 0.09898437\n",
            "---> iteration:  144  partial loss: 0.0998025\n",
            "---> iteration:  145  partial loss: 0.10988615\n",
            "---> iteration:  146  partial loss: 0.043325085\n",
            "---> iteration:  147  partial loss: 0.10619106\n",
            "---> iteration:  148  partial loss: 0.2471311\n",
            "---> iteration:  149  partial loss: 0.118509166\n",
            "---> iteration:  150  partial loss: 0.15127781\n",
            "---> iteration:  151  partial loss: 0.074705355\n",
            "---> iteration:  152  partial loss: 0.18892199\n",
            "---> iteration:  153  partial loss: 0.20640178\n",
            "---> iteration:  154  partial loss: 0.22323062\n",
            "---> iteration:  155  partial loss: 0.10318124\n",
            "---> iteration:  156  partial loss: 0.1186087\n",
            "---> iteration:  157  partial loss: 0.075749785\n",
            "---> iteration:  158  partial loss: 0.10450465\n",
            "---> iteration:  159  partial loss: 0.10067387\n",
            "---> iteration:  160  partial loss: 0.15744622\n",
            "---> iteration:  161  partial loss: 0.23214154\n",
            "---> iteration:  162  partial loss: 0.08119485\n",
            "---> iteration:  163  partial loss: 0.19780691\n",
            "---> iteration:  164  partial loss: 0.088116616\n",
            "---> iteration:  165  partial loss: 0.2802756\n",
            "---> iteration:  166  partial loss: 0.18162054\n",
            "---> iteration:  167  partial loss: 0.17808333\n",
            "---> iteration:  168  partial loss: 0.07968942\n",
            "---> iteration:  169  partial loss: 0.23767734\n",
            "---> iteration:  170  partial loss: 0.15858121\n",
            "---> iteration:  171  partial loss: 0.26051152\n",
            "---> iteration:  172  partial loss: 0.21145636\n",
            "---> iteration:  173  partial loss: 0.06724647\n",
            "---> iteration:  174  partial loss: 0.22571926\n",
            "---> iteration:  175  partial loss: 0.16157065\n",
            "---> iteration:  176  partial loss: 0.11978107\n",
            "---> iteration:  177  partial loss: 0.10026116\n",
            "---> iteration:  178  partial loss: 0.19269216\n",
            "---> iteration:  179  partial loss: 0.21351974\n",
            "---> iteration:  180  partial loss: 0.089273624\n",
            "---> iteration:  181  partial loss: 0.1316864\n",
            "---> iteration:  182  partial loss: 0.05472974\n",
            "---> iteration:  183  partial loss: 0.1242164\n",
            "---> iteration:  184  partial loss: 0.11309355\n",
            "---> iteration:  185  partial loss: 0.11202115\n",
            "---> iteration:  186  partial loss: 0.15504767\n",
            "---> iteration:  187  partial loss: 0.07746205\n",
            "---> iteration:  188  partial loss: 0.1326147\n",
            "---> iteration:  189  partial loss: 0.10619538\n",
            "---> iteration:  190  partial loss: 0.06521204\n",
            "---> iteration:  191  partial loss: 0.11039478\n",
            "---> iteration:  192  partial loss: 0.13158211\n",
            "---> iteration:  193  partial loss: 0.15989344\n",
            "---> iteration:  194  partial loss: 0.14583398\n",
            "---> iteration:  195  partial loss: 0.106759496\n",
            "---> iteration:  196  partial loss: 0.1103685\n",
            "---> iteration:  197  partial loss: 0.081556894\n",
            "---> iteration:  198  partial loss: 0.12825835\n",
            "---> iteration:  199  partial loss: 0.12389338\n",
            "---> iteration:  200  partial loss: 0.09436196\n",
            "---> iteration:  201  partial loss: 0.07655346\n",
            "---> iteration:  202  partial loss: 0.17696781\n",
            "---> iteration:  203  partial loss: 0.056856737\n",
            "---> iteration:  204  partial loss: 0.08479938\n",
            "---> iteration:  205  partial loss: 0.054261457\n",
            "---> iteration:  206  partial loss: 0.060638025\n",
            "---> iteration:  207  partial loss: 0.12485113\n",
            "---> iteration:  208  partial loss: 0.11794033\n",
            "---> iteration:  209  partial loss: 0.20922159\n",
            "---> iteration:  210  partial loss: 0.061553545\n",
            "---> iteration:  211  partial loss: 0.07517137\n",
            "---> iteration:  212  partial loss: 0.08058404\n",
            "---> iteration:  213  partial loss: 0.13773575\n",
            "---> iteration:  214  partial loss: 0.18066336\n",
            "---> iteration:  215  partial loss: 0.10249077\n",
            "---> iteration:  216  partial loss: 0.15281838\n",
            "---> iteration:  217  partial loss: 0.12489311\n",
            "---> iteration:  218  partial loss: 0.10072469\n",
            "---> iteration:  219  partial loss: 0.24657881\n",
            "---> iteration:  220  partial loss: 0.1961282\n",
            "---> iteration:  221  partial loss: 0.1648967\n",
            "---> iteration:  222  partial loss: 0.1638019\n",
            "---> iteration:  223  partial loss: 0.095321774\n",
            "---> iteration:  224  partial loss: 0.10231046\n",
            "---> iteration:  225  partial loss: 0.13435744\n",
            "---> iteration:  226  partial loss: 0.15628435\n",
            "---> iteration:  227  partial loss: 0.11450802\n",
            "---> iteration:  228  partial loss: 0.14241616\n",
            "---> iteration:  229  partial loss: 0.10099123\n",
            "---> iteration:  230  partial loss: 0.12217757\n",
            "---> iteration:  231  partial loss: 0.09779966\n",
            "---> iteration:  232  partial loss: 0.09665433\n",
            "---> iteration:  233  partial loss: 0.36611167\n",
            "---> iteration:  234  partial loss: 0.12305247\n",
            "---> iteration:  235  partial loss: 0.16781244\n",
            "---> iteration:  236  partial loss: 0.06949535\n",
            "---> iteration:  237  partial loss: 0.12090919\n",
            "---> iteration:  238  partial loss: 0.17520064\n",
            "---> iteration:  239  partial loss: 0.09355126\n",
            "---> iteration:  240  partial loss: 0.106472746\n",
            "---> iteration:  241  partial loss: 0.16186552\n",
            "---> iteration:  242  partial loss: 0.20608366\n",
            "---> iteration:  243  partial loss: 0.1784754\n",
            "---> iteration:  244  partial loss: 0.10335651\n",
            "---> iteration:  245  partial loss: 0.18645604\n",
            "---> iteration:  246  partial loss: 0.07874244\n",
            "---> iteration:  247  partial loss: 0.09319795\n",
            "---> iteration:  248  partial loss: 0.32741475\n",
            "---> iteration:  249  partial loss: 0.11363891\n",
            "---> iteration:  250  partial loss: 0.14440818\n",
            "---> iteration:  251  partial loss: 0.13643607\n",
            "---> iteration:  252  partial loss: 0.17772536\n",
            "---> iteration:  253  partial loss: 0.10224132\n",
            "---> iteration:  254  partial loss: 0.22499008\n",
            "---> iteration:  255  partial loss: 0.071439885\n",
            "---> iteration:  256  partial loss: 0.13911693\n",
            "---> iteration:  257  partial loss: 0.11265405\n",
            "---> iteration:  258  partial loss: 0.066363506\n",
            "---> iteration:  259  partial loss: 0.098784626\n",
            "---> iteration:  260  partial loss: 0.08401756\n",
            "---> iteration:  261  partial loss: 0.11939377\n",
            "---> iteration:  262  partial loss: 0.14223391\n",
            "---> iteration:  263  partial loss: 0.109939545\n",
            "---> iteration:  264  partial loss: 0.093755364\n",
            "---> iteration:  265  partial loss: 0.20363905\n",
            "---> iteration:  266  partial loss: 0.20439722\n",
            "---> iteration:  267  partial loss: 0.056245167\n",
            "---> iteration:  268  partial loss: 0.07747919\n",
            "---> iteration:  269  partial loss: 0.06423275\n",
            "---> iteration:  270  partial loss: 0.0862755\n",
            "---> iteration:  271  partial loss: 0.14161676\n",
            "---> iteration:  272  partial loss: 0.09555374\n",
            "---> iteration:  273  partial loss: 0.12120525\n",
            "---> iteration:  274  partial loss: 0.12858844\n",
            "---> iteration:  275  partial loss: 0.10355345\n",
            "---> iteration:  276  partial loss: 0.0482193\n",
            "---> iteration:  277  partial loss: 0.07785127\n",
            "---> iteration:  278  partial loss: 0.14281833\n",
            "---> iteration:  279  partial loss: 0.05479717\n",
            "---> iteration:  280  partial loss: 0.1503183\n",
            "---> iteration:  281  partial loss: 0.111268386\n",
            "---> iteration:  282  partial loss: 0.08375778\n",
            "---> iteration:  283  partial loss: 0.121039785\n",
            "---> iteration:  284  partial loss: 0.24663337\n",
            "---> iteration:  285  partial loss: 0.087360665\n",
            "---> iteration:  286  partial loss: 0.1343988\n",
            "---> iteration:  287  partial loss: 0.1508017\n",
            "---> iteration:  288  partial loss: 0.111591846\n",
            "---> iteration:  289  partial loss: 0.16356672\n",
            "------------------\n",
            "epoch:  6  of  20 training loss:  0.14571132211846052\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.13698858\n",
            "---> iteration:  2  partial loss: 0.26562744\n",
            "---> iteration:  3  partial loss: 0.07128921\n",
            "---> iteration:  4  partial loss: 0.14479378\n",
            "---> iteration:  5  partial loss: 0.15232173\n",
            "---> iteration:  6  partial loss: 0.17589162\n",
            "---> iteration:  7  partial loss: 0.1646706\n",
            "---> iteration:  8  partial loss: 0.13496988\n",
            "---> iteration:  9  partial loss: 0.15639946\n",
            "---> iteration:  10  partial loss: 0.18065476\n",
            "---> iteration:  11  partial loss: 0.11195502\n",
            "---> iteration:  12  partial loss: 0.13227046\n",
            "---> iteration:  13  partial loss: 0.06713925\n",
            "---> iteration:  14  partial loss: 0.10390002\n",
            "---> iteration:  15  partial loss: 0.09295085\n",
            "---> iteration:  16  partial loss: 0.14147954\n",
            "---> iteration:  17  partial loss: 0.062388662\n",
            "---> iteration:  18  partial loss: 0.20807154\n",
            "---> iteration:  19  partial loss: 0.076162696\n",
            "---> iteration:  20  partial loss: 0.09156643\n",
            "---> iteration:  21  partial loss: 0.09148318\n",
            "---> iteration:  22  partial loss: 0.13297343\n",
            "---> iteration:  23  partial loss: 0.11624082\n",
            "---> iteration:  24  partial loss: 0.1501404\n",
            "---> iteration:  25  partial loss: 0.11956691\n",
            "---> iteration:  26  partial loss: 0.066991106\n",
            "---> iteration:  27  partial loss: 0.074924864\n",
            "---> iteration:  28  partial loss: 0.15750726\n",
            "---> iteration:  29  partial loss: 0.08733506\n",
            "---> iteration:  30  partial loss: 0.09228832\n",
            "---> iteration:  31  partial loss: 0.042560022\n",
            "---> iteration:  32  partial loss: 0.047774643\n",
            "---> iteration:  33  partial loss: 0.10860776\n",
            "---> iteration:  34  partial loss: 0.18214226\n",
            "---> iteration:  35  partial loss: 0.11588069\n",
            "---> iteration:  36  partial loss: 0.09158408\n",
            "---> iteration:  37  partial loss: 0.14526772\n",
            "---> iteration:  38  partial loss: 0.18147036\n",
            "---> iteration:  39  partial loss: 0.1148241\n",
            "---> iteration:  40  partial loss: 0.1165427\n",
            "---> iteration:  41  partial loss: 0.12022152\n",
            "---> iteration:  42  partial loss: 0.10114554\n",
            "---> iteration:  43  partial loss: 0.15957347\n",
            "---> iteration:  44  partial loss: 0.06040942\n",
            "---> iteration:  45  partial loss: 0.12242521\n",
            "---> iteration:  46  partial loss: 0.10758028\n",
            "---> iteration:  47  partial loss: 0.1422832\n",
            "---> iteration:  48  partial loss: 0.1444582\n",
            "---> iteration:  49  partial loss: 0.069500804\n",
            "---> iteration:  50  partial loss: 0.109987214\n",
            "---> iteration:  51  partial loss: 0.12874398\n",
            "---> iteration:  52  partial loss: 0.11050056\n",
            "---> iteration:  53  partial loss: 0.056551997\n",
            "---> iteration:  54  partial loss: 0.19698717\n",
            "---> iteration:  55  partial loss: 0.1339948\n",
            "---> iteration:  56  partial loss: 0.14614783\n",
            "---> iteration:  57  partial loss: 0.17428118\n",
            "---> iteration:  58  partial loss: 0.083936\n",
            "---> iteration:  59  partial loss: 0.08724318\n",
            "---> iteration:  60  partial loss: 0.06909785\n",
            "---> iteration:  61  partial loss: 0.07415567\n",
            "---> iteration:  62  partial loss: 0.11179747\n",
            "---> iteration:  63  partial loss: 0.24668692\n",
            "---> iteration:  64  partial loss: 0.103654034\n",
            "---> iteration:  65  partial loss: 0.2827473\n",
            "---> iteration:  66  partial loss: 0.076652296\n",
            "---> iteration:  67  partial loss: 0.20911273\n",
            "---> iteration:  68  partial loss: 0.15279952\n",
            "---> iteration:  69  partial loss: 0.11499318\n",
            "---> iteration:  70  partial loss: 0.07949663\n",
            "---> iteration:  71  partial loss: 0.09622591\n",
            "---> iteration:  72  partial loss: 0.07562931\n",
            "---> iteration:  73  partial loss: 0.11843355\n",
            "---> iteration:  74  partial loss: 0.11212337\n",
            "---> iteration:  75  partial loss: 0.23014374\n",
            "---> iteration:  76  partial loss: 0.098804705\n",
            "---> iteration:  77  partial loss: 0.14340557\n",
            "---> iteration:  78  partial loss: 0.058641486\n",
            "---> iteration:  79  partial loss: 0.2091616\n",
            "---> iteration:  80  partial loss: 0.11876848\n",
            "---> iteration:  81  partial loss: 0.19665463\n",
            "---> iteration:  82  partial loss: 0.04182034\n",
            "---> iteration:  83  partial loss: 0.186328\n",
            "---> iteration:  84  partial loss: 0.11574289\n",
            "---> iteration:  85  partial loss: 0.3337609\n",
            "---> iteration:  86  partial loss: 0.1376289\n",
            "---> iteration:  87  partial loss: 0.15096337\n",
            "---> iteration:  88  partial loss: 0.11654216\n",
            "---> iteration:  89  partial loss: 0.110450424\n",
            "---> iteration:  90  partial loss: 0.081721716\n",
            "---> iteration:  91  partial loss: 0.10987058\n",
            "---> iteration:  92  partial loss: 0.15192837\n",
            "---> iteration:  93  partial loss: 0.1213156\n",
            "---> iteration:  94  partial loss: 0.1041717\n",
            "---> iteration:  95  partial loss: 0.084440984\n",
            "---> iteration:  96  partial loss: 0.14030993\n",
            "---> iteration:  97  partial loss: 0.30158705\n",
            "---> iteration:  98  partial loss: 0.1272252\n",
            "---> iteration:  99  partial loss: 0.1266388\n",
            "---> iteration:  100  partial loss: 0.1352243\n",
            "---> iteration:  101  partial loss: 0.14545572\n",
            "---> iteration:  102  partial loss: 0.1479807\n",
            "---> iteration:  103  partial loss: 0.09510331\n",
            "---> iteration:  104  partial loss: 0.050346475\n",
            "---> iteration:  105  partial loss: 0.14745088\n",
            "---> iteration:  106  partial loss: 0.12793225\n",
            "---> iteration:  107  partial loss: 0.117393926\n",
            "---> iteration:  108  partial loss: 0.079905234\n",
            "---> iteration:  109  partial loss: 0.087094165\n",
            "---> iteration:  110  partial loss: 0.056007247\n",
            "---> iteration:  111  partial loss: 0.10176849\n",
            "---> iteration:  112  partial loss: 0.06504353\n",
            "---> iteration:  113  partial loss: 0.0958605\n",
            "---> iteration:  114  partial loss: 0.053501446\n",
            "---> iteration:  115  partial loss: 0.11725006\n",
            "---> iteration:  116  partial loss: 0.061052363\n",
            "---> iteration:  117  partial loss: 0.10519801\n",
            "---> iteration:  118  partial loss: 0.2096542\n",
            "---> iteration:  119  partial loss: 0.12547393\n",
            "---> iteration:  120  partial loss: 0.11862312\n",
            "---> iteration:  121  partial loss: 0.17521763\n",
            "---> iteration:  122  partial loss: 0.15346786\n",
            "---> iteration:  123  partial loss: 0.1402568\n",
            "---> iteration:  124  partial loss: 0.09178202\n",
            "---> iteration:  125  partial loss: 0.25968218\n",
            "---> iteration:  126  partial loss: 0.08407793\n",
            "---> iteration:  127  partial loss: 0.06636417\n",
            "---> iteration:  128  partial loss: 0.13785614\n",
            "---> iteration:  129  partial loss: 0.16743103\n",
            "---> iteration:  130  partial loss: 0.10106792\n",
            "---> iteration:  131  partial loss: 0.118035085\n",
            "---> iteration:  132  partial loss: 0.118845455\n",
            "---> iteration:  133  partial loss: 0.09127808\n",
            "---> iteration:  134  partial loss: 0.07153635\n",
            "---> iteration:  135  partial loss: 0.09023187\n",
            "---> iteration:  136  partial loss: 0.19099933\n",
            "---> iteration:  137  partial loss: 0.09987223\n",
            "---> iteration:  138  partial loss: 0.06523117\n",
            "---> iteration:  139  partial loss: 0.1459696\n",
            "---> iteration:  140  partial loss: 0.119330764\n",
            "---> iteration:  141  partial loss: 0.06456195\n",
            "---> iteration:  142  partial loss: 0.21597432\n",
            "---> iteration:  143  partial loss: 0.10310973\n",
            "---> iteration:  144  partial loss: 0.25017536\n",
            "---> iteration:  145  partial loss: 0.09494904\n",
            "---> iteration:  146  partial loss: 0.11446469\n",
            "---> iteration:  147  partial loss: 0.15938997\n",
            "---> iteration:  148  partial loss: 0.1099581\n",
            "---> iteration:  149  partial loss: 0.10218469\n",
            "---> iteration:  150  partial loss: 0.1635621\n",
            "---> iteration:  151  partial loss: 0.094089404\n",
            "---> iteration:  152  partial loss: 0.1227245\n",
            "---> iteration:  153  partial loss: 0.30947164\n",
            "---> iteration:  154  partial loss: 0.13876863\n",
            "---> iteration:  155  partial loss: 0.111265525\n",
            "---> iteration:  156  partial loss: 0.10031039\n",
            "---> iteration:  157  partial loss: 0.08113153\n",
            "---> iteration:  158  partial loss: 0.105379224\n",
            "---> iteration:  159  partial loss: 0.10768471\n",
            "---> iteration:  160  partial loss: 0.2786451\n",
            "---> iteration:  161  partial loss: 0.1793226\n",
            "---> iteration:  162  partial loss: 0.3228163\n",
            "---> iteration:  163  partial loss: 0.114638925\n",
            "---> iteration:  164  partial loss: 0.110644996\n",
            "---> iteration:  165  partial loss: 0.123107664\n",
            "---> iteration:  166  partial loss: 0.10811297\n",
            "---> iteration:  167  partial loss: 0.11355146\n",
            "---> iteration:  168  partial loss: 0.117140464\n",
            "---> iteration:  169  partial loss: 0.07110885\n",
            "---> iteration:  170  partial loss: 0.07635958\n",
            "---> iteration:  171  partial loss: 0.07316461\n",
            "---> iteration:  172  partial loss: 0.06275546\n",
            "---> iteration:  173  partial loss: 0.15353942\n",
            "---> iteration:  174  partial loss: 0.07916353\n",
            "---> iteration:  175  partial loss: 0.05318186\n",
            "---> iteration:  176  partial loss: 0.11212294\n",
            "---> iteration:  177  partial loss: 0.14593743\n",
            "---> iteration:  178  partial loss: 0.08144425\n",
            "---> iteration:  179  partial loss: 0.10881055\n",
            "---> iteration:  180  partial loss: 0.085359655\n",
            "---> iteration:  181  partial loss: 0.13812235\n",
            "---> iteration:  182  partial loss: 0.23667069\n",
            "---> iteration:  183  partial loss: 0.07417221\n",
            "---> iteration:  184  partial loss: 0.1516205\n",
            "---> iteration:  185  partial loss: 0.15248841\n",
            "---> iteration:  186  partial loss: 0.09889305\n",
            "---> iteration:  187  partial loss: 0.083006315\n",
            "---> iteration:  188  partial loss: 0.08781623\n",
            "---> iteration:  189  partial loss: 0.13780525\n",
            "---> iteration:  190  partial loss: 0.25526175\n",
            "---> iteration:  191  partial loss: 0.06896697\n",
            "---> iteration:  192  partial loss: 0.09335791\n",
            "---> iteration:  193  partial loss: 0.10319745\n",
            "---> iteration:  194  partial loss: 0.17667699\n",
            "---> iteration:  195  partial loss: 0.109633036\n",
            "---> iteration:  196  partial loss: 0.23478499\n",
            "---> iteration:  197  partial loss: 0.14135182\n",
            "---> iteration:  198  partial loss: 0.13573186\n",
            "---> iteration:  199  partial loss: 0.17132753\n",
            "---> iteration:  200  partial loss: 0.12961352\n",
            "---> iteration:  201  partial loss: 0.13750438\n",
            "---> iteration:  202  partial loss: 0.19316965\n",
            "---> iteration:  203  partial loss: 0.11367635\n",
            "---> iteration:  204  partial loss: 0.058835473\n",
            "---> iteration:  205  partial loss: 0.18253067\n",
            "---> iteration:  206  partial loss: 0.14594902\n",
            "---> iteration:  207  partial loss: 0.09034897\n",
            "---> iteration:  208  partial loss: 0.07591722\n",
            "---> iteration:  209  partial loss: 0.105096996\n",
            "---> iteration:  210  partial loss: 0.14338394\n",
            "---> iteration:  211  partial loss: 0.049426496\n",
            "---> iteration:  212  partial loss: 0.22537664\n",
            "---> iteration:  213  partial loss: 0.075619906\n",
            "---> iteration:  214  partial loss: 0.11964836\n",
            "---> iteration:  215  partial loss: 0.108462535\n",
            "---> iteration:  216  partial loss: 0.049846765\n",
            "---> iteration:  217  partial loss: 0.051651467\n",
            "---> iteration:  218  partial loss: 0.23312314\n",
            "---> iteration:  219  partial loss: 0.11897057\n",
            "---> iteration:  220  partial loss: 0.0875486\n",
            "---> iteration:  221  partial loss: 0.17012224\n",
            "---> iteration:  222  partial loss: 0.13892706\n",
            "---> iteration:  223  partial loss: 0.16372433\n",
            "---> iteration:  224  partial loss: 0.19134182\n",
            "---> iteration:  225  partial loss: 0.121493824\n",
            "---> iteration:  226  partial loss: 0.17715825\n",
            "---> iteration:  227  partial loss: 0.120041296\n",
            "---> iteration:  228  partial loss: 0.093154736\n",
            "---> iteration:  229  partial loss: 0.14824682\n",
            "---> iteration:  230  partial loss: 0.07578087\n",
            "---> iteration:  231  partial loss: 0.13237627\n",
            "---> iteration:  232  partial loss: 0.071334444\n",
            "---> iteration:  233  partial loss: 0.04984542\n",
            "---> iteration:  234  partial loss: 0.15641649\n",
            "---> iteration:  235  partial loss: 0.09836066\n",
            "---> iteration:  236  partial loss: 0.085823655\n",
            "---> iteration:  237  partial loss: 0.09663346\n",
            "---> iteration:  238  partial loss: 0.20404524\n",
            "---> iteration:  239  partial loss: 0.0798721\n",
            "---> iteration:  240  partial loss: 0.09155271\n",
            "---> iteration:  241  partial loss: 0.13265604\n",
            "---> iteration:  242  partial loss: 0.19247767\n",
            "---> iteration:  243  partial loss: 0.18470123\n",
            "---> iteration:  244  partial loss: 0.1262697\n",
            "---> iteration:  245  partial loss: 0.18200451\n",
            "---> iteration:  246  partial loss: 0.103713505\n",
            "---> iteration:  247  partial loss: 0.1714823\n",
            "---> iteration:  248  partial loss: 0.10646454\n",
            "---> iteration:  249  partial loss: 0.10416656\n",
            "---> iteration:  250  partial loss: 0.14128672\n",
            "---> iteration:  251  partial loss: 0.16884303\n",
            "---> iteration:  252  partial loss: 0.07073316\n",
            "---> iteration:  253  partial loss: 0.1095587\n",
            "---> iteration:  254  partial loss: 0.2123236\n",
            "---> iteration:  255  partial loss: 0.1624641\n",
            "---> iteration:  256  partial loss: 0.08109224\n",
            "---> iteration:  257  partial loss: 0.10577458\n",
            "---> iteration:  258  partial loss: 0.2369568\n",
            "---> iteration:  259  partial loss: 0.07396531\n",
            "---> iteration:  260  partial loss: 0.087551355\n",
            "---> iteration:  261  partial loss: 0.26992333\n",
            "---> iteration:  262  partial loss: 0.08586604\n",
            "---> iteration:  263  partial loss: 0.14181232\n",
            "---> iteration:  264  partial loss: 0.10682606\n",
            "---> iteration:  265  partial loss: 0.17008762\n",
            "---> iteration:  266  partial loss: 0.087371394\n",
            "---> iteration:  267  partial loss: 0.080007404\n",
            "---> iteration:  268  partial loss: 0.10565371\n",
            "---> iteration:  269  partial loss: 0.110013716\n",
            "---> iteration:  270  partial loss: 0.11196141\n",
            "---> iteration:  271  partial loss: 0.13727835\n",
            "---> iteration:  272  partial loss: 0.07077726\n",
            "---> iteration:  273  partial loss: 0.15495588\n",
            "---> iteration:  274  partial loss: 0.030961\n",
            "---> iteration:  275  partial loss: 0.15847604\n",
            "---> iteration:  276  partial loss: 0.07940677\n",
            "---> iteration:  277  partial loss: 0.07098058\n",
            "---> iteration:  278  partial loss: 0.29682624\n",
            "---> iteration:  279  partial loss: 0.07625511\n",
            "---> iteration:  280  partial loss: 0.1217641\n",
            "---> iteration:  281  partial loss: 0.10124626\n",
            "---> iteration:  282  partial loss: 0.055137053\n",
            "---> iteration:  283  partial loss: 0.1498077\n",
            "---> iteration:  284  partial loss: 0.20094736\n",
            "---> iteration:  285  partial loss: 0.094476074\n",
            "---> iteration:  286  partial loss: 0.15266141\n",
            "---> iteration:  287  partial loss: 0.06444038\n",
            "---> iteration:  288  partial loss: 0.100956894\n",
            "---> iteration:  289  partial loss: 0.10323889\n",
            "------------------\n",
            "epoch:  7  of  20 training loss:  0.12593279903993063\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.11512674\n",
            "---> iteration:  2  partial loss: 0.056847733\n",
            "---> iteration:  3  partial loss: 0.14242662\n",
            "---> iteration:  4  partial loss: 0.22991778\n",
            "---> iteration:  5  partial loss: 0.09813718\n",
            "---> iteration:  6  partial loss: 0.27818707\n",
            "---> iteration:  7  partial loss: 0.14453115\n",
            "---> iteration:  8  partial loss: 0.14760014\n",
            "---> iteration:  9  partial loss: 0.05603548\n",
            "---> iteration:  10  partial loss: 0.14213516\n",
            "---> iteration:  11  partial loss: 0.1589194\n",
            "---> iteration:  12  partial loss: 0.1251467\n",
            "---> iteration:  13  partial loss: 0.109715804\n",
            "---> iteration:  14  partial loss: 0.080040924\n",
            "---> iteration:  15  partial loss: 0.1519532\n",
            "---> iteration:  16  partial loss: 0.12077444\n",
            "---> iteration:  17  partial loss: 0.13785644\n",
            "---> iteration:  18  partial loss: 0.08576797\n",
            "---> iteration:  19  partial loss: 0.07372274\n",
            "---> iteration:  20  partial loss: 0.08090303\n",
            "---> iteration:  21  partial loss: 0.18095703\n",
            "---> iteration:  22  partial loss: 0.17736672\n",
            "---> iteration:  23  partial loss: 0.12988049\n",
            "---> iteration:  24  partial loss: 0.19712274\n",
            "---> iteration:  25  partial loss: 0.13205954\n",
            "---> iteration:  26  partial loss: 0.15661725\n",
            "---> iteration:  27  partial loss: 0.10370085\n",
            "---> iteration:  28  partial loss: 0.14452055\n",
            "---> iteration:  29  partial loss: 0.1017773\n",
            "---> iteration:  30  partial loss: 0.058445804\n",
            "---> iteration:  31  partial loss: 0.06824263\n",
            "---> iteration:  32  partial loss: 0.08916107\n",
            "---> iteration:  33  partial loss: 0.056822047\n",
            "---> iteration:  34  partial loss: 0.14915715\n",
            "---> iteration:  35  partial loss: 0.07612216\n",
            "---> iteration:  36  partial loss: 0.12792505\n",
            "---> iteration:  37  partial loss: 0.1259144\n",
            "---> iteration:  38  partial loss: 0.11983455\n",
            "---> iteration:  39  partial loss: 0.05442343\n",
            "---> iteration:  40  partial loss: 0.06554291\n",
            "---> iteration:  41  partial loss: 0.09659004\n",
            "---> iteration:  42  partial loss: 0.09599701\n",
            "---> iteration:  43  partial loss: 0.069279745\n",
            "---> iteration:  44  partial loss: 0.1420786\n",
            "---> iteration:  45  partial loss: 0.07772601\n",
            "---> iteration:  46  partial loss: 0.17818218\n",
            "---> iteration:  47  partial loss: 0.09125105\n",
            "---> iteration:  48  partial loss: 0.25084254\n",
            "---> iteration:  49  partial loss: 0.10344716\n",
            "---> iteration:  50  partial loss: 0.05360224\n",
            "---> iteration:  51  partial loss: 0.08500751\n",
            "---> iteration:  52  partial loss: 0.22499335\n",
            "---> iteration:  53  partial loss: 0.099646196\n",
            "---> iteration:  54  partial loss: 0.15582138\n",
            "---> iteration:  55  partial loss: 0.102628775\n",
            "---> iteration:  56  partial loss: 0.16904193\n",
            "---> iteration:  57  partial loss: 0.12197243\n",
            "---> iteration:  58  partial loss: 0.11116899\n",
            "---> iteration:  59  partial loss: 0.101817615\n",
            "---> iteration:  60  partial loss: 0.15809016\n",
            "---> iteration:  61  partial loss: 0.078568906\n",
            "---> iteration:  62  partial loss: 0.18459931\n",
            "---> iteration:  63  partial loss: 0.17267504\n",
            "---> iteration:  64  partial loss: 0.08536527\n",
            "---> iteration:  65  partial loss: 0.09595462\n",
            "---> iteration:  66  partial loss: 0.093370885\n",
            "---> iteration:  67  partial loss: 0.1125341\n",
            "---> iteration:  68  partial loss: 0.09339611\n",
            "---> iteration:  69  partial loss: 0.09914335\n",
            "---> iteration:  70  partial loss: 0.11793503\n",
            "---> iteration:  71  partial loss: 0.25553656\n",
            "---> iteration:  72  partial loss: 0.046123356\n",
            "---> iteration:  73  partial loss: 0.05796774\n",
            "---> iteration:  74  partial loss: 0.09666182\n",
            "---> iteration:  75  partial loss: 0.06431672\n",
            "---> iteration:  76  partial loss: 0.044514038\n",
            "---> iteration:  77  partial loss: 0.103118196\n",
            "---> iteration:  78  partial loss: 0.0834566\n",
            "---> iteration:  79  partial loss: 0.14545849\n",
            "---> iteration:  80  partial loss: 0.12811999\n",
            "---> iteration:  81  partial loss: 0.11130581\n",
            "---> iteration:  82  partial loss: 0.14193992\n",
            "---> iteration:  83  partial loss: 0.17202307\n",
            "---> iteration:  84  partial loss: 0.1437912\n",
            "---> iteration:  85  partial loss: 0.102503054\n",
            "---> iteration:  86  partial loss: 0.069247164\n",
            "---> iteration:  87  partial loss: 0.10626702\n",
            "---> iteration:  88  partial loss: 0.12096327\n",
            "---> iteration:  89  partial loss: 0.16859426\n",
            "---> iteration:  90  partial loss: 0.117291495\n",
            "---> iteration:  91  partial loss: 0.04884599\n",
            "---> iteration:  92  partial loss: 0.052566264\n",
            "---> iteration:  93  partial loss: 0.060317144\n",
            "---> iteration:  94  partial loss: 0.10215829\n",
            "---> iteration:  95  partial loss: 0.041817002\n",
            "---> iteration:  96  partial loss: 0.10125954\n",
            "---> iteration:  97  partial loss: 0.15814959\n",
            "---> iteration:  98  partial loss: 0.08731519\n",
            "---> iteration:  99  partial loss: 0.047026232\n",
            "---> iteration:  100  partial loss: 0.105590515\n",
            "---> iteration:  101  partial loss: 0.13286515\n",
            "---> iteration:  102  partial loss: 0.13898453\n",
            "---> iteration:  103  partial loss: 0.13981777\n",
            "---> iteration:  104  partial loss: 0.058215782\n",
            "---> iteration:  105  partial loss: 0.2643585\n",
            "---> iteration:  106  partial loss: 0.18053351\n",
            "---> iteration:  107  partial loss: 0.14987539\n",
            "---> iteration:  108  partial loss: 0.051800825\n",
            "---> iteration:  109  partial loss: 0.13000564\n",
            "---> iteration:  110  partial loss: 0.11064733\n",
            "---> iteration:  111  partial loss: 0.11210081\n",
            "---> iteration:  112  partial loss: 0.20858182\n",
            "---> iteration:  113  partial loss: 0.14919993\n",
            "---> iteration:  114  partial loss: 0.06415748\n",
            "---> iteration:  115  partial loss: 0.10158893\n",
            "---> iteration:  116  partial loss: 0.1784832\n",
            "---> iteration:  117  partial loss: 0.045958064\n",
            "---> iteration:  118  partial loss: 0.0669087\n",
            "---> iteration:  119  partial loss: 0.05689887\n",
            "---> iteration:  120  partial loss: 0.10474221\n",
            "---> iteration:  121  partial loss: 0.16117424\n",
            "---> iteration:  122  partial loss: 0.095822945\n",
            "---> iteration:  123  partial loss: 0.10561658\n",
            "---> iteration:  124  partial loss: 0.10385556\n",
            "---> iteration:  125  partial loss: 0.110267416\n",
            "---> iteration:  126  partial loss: 0.14220141\n",
            "---> iteration:  127  partial loss: 0.05977345\n",
            "---> iteration:  128  partial loss: 0.06752823\n",
            "---> iteration:  129  partial loss: 0.1019857\n",
            "---> iteration:  130  partial loss: 0.1311007\n",
            "---> iteration:  131  partial loss: 0.063916594\n",
            "---> iteration:  132  partial loss: 0.063018\n",
            "---> iteration:  133  partial loss: 0.055793125\n",
            "---> iteration:  134  partial loss: 0.14395429\n",
            "---> iteration:  135  partial loss: 0.09310511\n",
            "---> iteration:  136  partial loss: 0.13376644\n",
            "---> iteration:  137  partial loss: 0.1054285\n",
            "---> iteration:  138  partial loss: 0.079919346\n",
            "---> iteration:  139  partial loss: 0.099503815\n",
            "---> iteration:  140  partial loss: 0.08724716\n",
            "---> iteration:  141  partial loss: 0.22443531\n",
            "---> iteration:  142  partial loss: 0.07704146\n",
            "---> iteration:  143  partial loss: 0.06587192\n",
            "---> iteration:  144  partial loss: 0.053891957\n",
            "---> iteration:  145  partial loss: 0.15824395\n",
            "---> iteration:  146  partial loss: 0.09339895\n",
            "---> iteration:  147  partial loss: 0.09511884\n",
            "---> iteration:  148  partial loss: 0.14381352\n",
            "---> iteration:  149  partial loss: 0.08938679\n",
            "---> iteration:  150  partial loss: 0.117988884\n",
            "---> iteration:  151  partial loss: 0.057904307\n",
            "---> iteration:  152  partial loss: 0.07965723\n",
            "---> iteration:  153  partial loss: 0.10664829\n",
            "---> iteration:  154  partial loss: 0.08910709\n",
            "---> iteration:  155  partial loss: 0.12865931\n",
            "---> iteration:  156  partial loss: 0.09431324\n",
            "---> iteration:  157  partial loss: 0.09883994\n",
            "---> iteration:  158  partial loss: 0.13252339\n",
            "---> iteration:  159  partial loss: 0.12683584\n",
            "---> iteration:  160  partial loss: 0.10352353\n",
            "---> iteration:  161  partial loss: 0.13463432\n",
            "---> iteration:  162  partial loss: 0.08984\n",
            "---> iteration:  163  partial loss: 0.1381302\n",
            "---> iteration:  164  partial loss: 0.10338106\n",
            "---> iteration:  165  partial loss: 0.25719053\n",
            "---> iteration:  166  partial loss: 0.09902047\n",
            "---> iteration:  167  partial loss: 0.06554504\n",
            "---> iteration:  168  partial loss: 0.118070774\n",
            "---> iteration:  169  partial loss: 0.12065661\n",
            "---> iteration:  170  partial loss: 0.10166367\n",
            "---> iteration:  171  partial loss: 0.0870489\n",
            "---> iteration:  172  partial loss: 0.23055226\n",
            "---> iteration:  173  partial loss: 0.1178821\n",
            "---> iteration:  174  partial loss: 0.17356706\n",
            "---> iteration:  175  partial loss: 0.3161801\n",
            "---> iteration:  176  partial loss: 0.17603748\n",
            "---> iteration:  177  partial loss: 0.077538416\n",
            "---> iteration:  178  partial loss: 0.115359835\n",
            "---> iteration:  179  partial loss: 0.07794865\n",
            "---> iteration:  180  partial loss: 0.078278616\n",
            "---> iteration:  181  partial loss: 0.18560536\n",
            "---> iteration:  182  partial loss: 0.12926117\n",
            "---> iteration:  183  partial loss: 0.055911038\n",
            "---> iteration:  184  partial loss: 0.07493097\n",
            "---> iteration:  185  partial loss: 0.09038744\n",
            "---> iteration:  186  partial loss: 0.12050795\n",
            "---> iteration:  187  partial loss: 0.10040447\n",
            "---> iteration:  188  partial loss: 0.09637841\n",
            "---> iteration:  189  partial loss: 0.06966227\n",
            "---> iteration:  190  partial loss: 0.10578893\n",
            "---> iteration:  191  partial loss: 0.13175255\n",
            "---> iteration:  192  partial loss: 0.10818231\n",
            "---> iteration:  193  partial loss: 0.07495212\n",
            "---> iteration:  194  partial loss: 0.12911573\n",
            "---> iteration:  195  partial loss: 0.04923149\n",
            "---> iteration:  196  partial loss: 0.15261835\n",
            "---> iteration:  197  partial loss: 0.18306813\n",
            "---> iteration:  198  partial loss: 0.102337115\n",
            "---> iteration:  199  partial loss: 0.08359215\n",
            "---> iteration:  200  partial loss: 0.12069399\n",
            "---> iteration:  201  partial loss: 0.046043873\n",
            "---> iteration:  202  partial loss: 0.11666534\n",
            "---> iteration:  203  partial loss: 0.0664869\n",
            "---> iteration:  204  partial loss: 0.067396164\n",
            "---> iteration:  205  partial loss: 0.06282251\n",
            "---> iteration:  206  partial loss: 0.17256592\n",
            "---> iteration:  207  partial loss: 0.041341133\n",
            "---> iteration:  208  partial loss: 0.13283053\n",
            "---> iteration:  209  partial loss: 0.29155213\n",
            "---> iteration:  210  partial loss: 0.07269109\n",
            "---> iteration:  211  partial loss: 0.043868054\n",
            "---> iteration:  212  partial loss: 0.09707059\n",
            "---> iteration:  213  partial loss: 0.082351215\n",
            "---> iteration:  214  partial loss: 0.07480066\n",
            "---> iteration:  215  partial loss: 0.09588999\n",
            "---> iteration:  216  partial loss: 0.089693315\n",
            "---> iteration:  217  partial loss: 0.13830374\n",
            "---> iteration:  218  partial loss: 0.08588542\n",
            "---> iteration:  219  partial loss: 0.070170544\n",
            "---> iteration:  220  partial loss: 0.12457827\n",
            "---> iteration:  221  partial loss: 0.10766629\n",
            "---> iteration:  222  partial loss: 0.040644545\n",
            "---> iteration:  223  partial loss: 0.1909017\n",
            "---> iteration:  224  partial loss: 0.11220463\n",
            "---> iteration:  225  partial loss: 0.114832975\n",
            "---> iteration:  226  partial loss: 0.0863374\n",
            "---> iteration:  227  partial loss: 0.06267631\n",
            "---> iteration:  228  partial loss: 0.18219422\n",
            "---> iteration:  229  partial loss: 0.093771756\n",
            "---> iteration:  230  partial loss: 0.088622645\n",
            "---> iteration:  231  partial loss: 0.13487352\n",
            "---> iteration:  232  partial loss: 0.10264155\n",
            "---> iteration:  233  partial loss: 0.07013916\n",
            "---> iteration:  234  partial loss: 0.067937985\n",
            "---> iteration:  235  partial loss: 0.15616272\n",
            "---> iteration:  236  partial loss: 0.03811029\n",
            "---> iteration:  237  partial loss: 0.14690478\n",
            "---> iteration:  238  partial loss: 0.07643236\n",
            "---> iteration:  239  partial loss: 0.15037933\n",
            "---> iteration:  240  partial loss: 0.113534726\n",
            "---> iteration:  241  partial loss: 0.072724074\n",
            "---> iteration:  242  partial loss: 0.03806874\n",
            "---> iteration:  243  partial loss: 0.059988275\n",
            "---> iteration:  244  partial loss: 0.07527043\n",
            "---> iteration:  245  partial loss: 0.1739401\n",
            "---> iteration:  246  partial loss: 0.079157315\n",
            "---> iteration:  247  partial loss: 0.19806167\n",
            "---> iteration:  248  partial loss: 0.056714036\n",
            "---> iteration:  249  partial loss: 0.17697972\n",
            "---> iteration:  250  partial loss: 0.07144894\n",
            "---> iteration:  251  partial loss: 0.113727085\n",
            "---> iteration:  252  partial loss: 0.09053015\n",
            "---> iteration:  253  partial loss: 0.09403826\n",
            "---> iteration:  254  partial loss: 0.06092946\n",
            "---> iteration:  255  partial loss: 0.056477997\n",
            "---> iteration:  256  partial loss: 0.09404918\n",
            "---> iteration:  257  partial loss: 0.096765645\n",
            "---> iteration:  258  partial loss: 0.12336342\n",
            "---> iteration:  259  partial loss: 0.070664026\n",
            "---> iteration:  260  partial loss: 0.087433\n",
            "---> iteration:  261  partial loss: 0.058937613\n",
            "---> iteration:  262  partial loss: 0.08557748\n",
            "---> iteration:  263  partial loss: 0.0643808\n",
            "---> iteration:  264  partial loss: 0.110537\n",
            "---> iteration:  265  partial loss: 0.11182826\n",
            "---> iteration:  266  partial loss: 0.13611321\n",
            "---> iteration:  267  partial loss: 0.06338775\n",
            "---> iteration:  268  partial loss: 0.06848295\n",
            "---> iteration:  269  partial loss: 0.07913885\n",
            "---> iteration:  270  partial loss: 0.13109827\n",
            "---> iteration:  271  partial loss: 0.28611326\n",
            "---> iteration:  272  partial loss: 0.06912394\n",
            "---> iteration:  273  partial loss: 0.09100081\n",
            "---> iteration:  274  partial loss: 0.11510162\n",
            "---> iteration:  275  partial loss: 0.1246419\n",
            "---> iteration:  276  partial loss: 0.08129088\n",
            "---> iteration:  277  partial loss: 0.14989552\n",
            "---> iteration:  278  partial loss: 0.18868889\n",
            "---> iteration:  279  partial loss: 0.27808324\n",
            "---> iteration:  280  partial loss: 0.06868651\n",
            "---> iteration:  281  partial loss: 0.12677261\n",
            "---> iteration:  282  partial loss: 0.060802225\n",
            "---> iteration:  283  partial loss: 0.1723131\n",
            "---> iteration:  284  partial loss: 0.21439166\n",
            "---> iteration:  285  partial loss: 0.072501004\n",
            "---> iteration:  286  partial loss: 0.13075015\n",
            "---> iteration:  287  partial loss: 0.16341706\n",
            "---> iteration:  288  partial loss: 0.1023081\n",
            "---> iteration:  289  partial loss: 0.14366236\n",
            "------------------\n",
            "epoch:  8  of  20 training loss:  0.1125898343546374\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.08462249\n",
            "---> iteration:  2  partial loss: 0.12673442\n",
            "---> iteration:  3  partial loss: 0.08581548\n",
            "---> iteration:  4  partial loss: 0.13222927\n",
            "---> iteration:  5  partial loss: 0.14275733\n",
            "---> iteration:  6  partial loss: 0.12324511\n",
            "---> iteration:  7  partial loss: 0.08813784\n",
            "---> iteration:  8  partial loss: 0.1041123\n",
            "---> iteration:  9  partial loss: 0.0627614\n",
            "---> iteration:  10  partial loss: 0.057657894\n",
            "---> iteration:  11  partial loss: 0.07757225\n",
            "---> iteration:  12  partial loss: 0.1372833\n",
            "---> iteration:  13  partial loss: 0.051060673\n",
            "---> iteration:  14  partial loss: 0.1371687\n",
            "---> iteration:  15  partial loss: 0.073754415\n",
            "---> iteration:  16  partial loss: 0.08860496\n",
            "---> iteration:  17  partial loss: 0.10500166\n",
            "---> iteration:  18  partial loss: 0.06805114\n",
            "---> iteration:  19  partial loss: 0.039362863\n",
            "---> iteration:  20  partial loss: 0.117476694\n",
            "---> iteration:  21  partial loss: 0.050062217\n",
            "---> iteration:  22  partial loss: 0.1089374\n",
            "---> iteration:  23  partial loss: 0.057282902\n",
            "---> iteration:  24  partial loss: 0.12995394\n",
            "---> iteration:  25  partial loss: 0.101888\n",
            "---> iteration:  26  partial loss: 0.09341774\n",
            "---> iteration:  27  partial loss: 0.2571507\n",
            "---> iteration:  28  partial loss: 0.049826358\n",
            "---> iteration:  29  partial loss: 0.07549378\n",
            "---> iteration:  30  partial loss: 0.040381357\n",
            "---> iteration:  31  partial loss: 0.23898003\n",
            "---> iteration:  32  partial loss: 0.044456128\n",
            "---> iteration:  33  partial loss: 0.09202296\n",
            "---> iteration:  34  partial loss: 0.106980845\n",
            "---> iteration:  35  partial loss: 0.07426575\n",
            "---> iteration:  36  partial loss: 0.17351732\n",
            "---> iteration:  37  partial loss: 0.12016226\n",
            "---> iteration:  38  partial loss: 0.034794442\n",
            "---> iteration:  39  partial loss: 0.050275154\n",
            "---> iteration:  40  partial loss: 0.10862965\n",
            "---> iteration:  41  partial loss: 0.10734826\n",
            "---> iteration:  42  partial loss: 0.12420967\n",
            "---> iteration:  43  partial loss: 0.07342968\n",
            "---> iteration:  44  partial loss: 0.07644249\n",
            "---> iteration:  45  partial loss: 0.08092698\n",
            "---> iteration:  46  partial loss: 0.1173993\n",
            "---> iteration:  47  partial loss: 0.10344332\n",
            "---> iteration:  48  partial loss: 0.07492087\n",
            "---> iteration:  49  partial loss: 0.16260332\n",
            "---> iteration:  50  partial loss: 0.15546587\n",
            "---> iteration:  51  partial loss: 0.18586722\n",
            "---> iteration:  52  partial loss: 0.06321924\n",
            "---> iteration:  53  partial loss: 0.12046749\n",
            "---> iteration:  54  partial loss: 0.0859431\n",
            "---> iteration:  55  partial loss: 0.16599518\n",
            "---> iteration:  56  partial loss: 0.09516854\n",
            "---> iteration:  57  partial loss: 0.074706286\n",
            "---> iteration:  58  partial loss: 0.055045646\n",
            "---> iteration:  59  partial loss: 0.061562713\n",
            "---> iteration:  60  partial loss: 0.081850484\n",
            "---> iteration:  61  partial loss: 0.048061963\n",
            "---> iteration:  62  partial loss: 0.051597416\n",
            "---> iteration:  63  partial loss: 0.124795154\n",
            "---> iteration:  64  partial loss: 0.052339915\n",
            "---> iteration:  65  partial loss: 0.09659286\n",
            "---> iteration:  66  partial loss: 0.07894433\n",
            "---> iteration:  67  partial loss: 0.10848203\n",
            "---> iteration:  68  partial loss: 0.047766067\n",
            "---> iteration:  69  partial loss: 0.093715794\n",
            "---> iteration:  70  partial loss: 0.06699191\n",
            "---> iteration:  71  partial loss: 0.09867645\n",
            "---> iteration:  72  partial loss: 0.057416983\n",
            "---> iteration:  73  partial loss: 0.10342234\n",
            "---> iteration:  74  partial loss: 0.09341489\n",
            "---> iteration:  75  partial loss: 0.124649875\n",
            "---> iteration:  76  partial loss: 0.04758093\n",
            "---> iteration:  77  partial loss: 0.052101422\n",
            "---> iteration:  78  partial loss: 0.16323994\n",
            "---> iteration:  79  partial loss: 0.16652451\n",
            "---> iteration:  80  partial loss: 0.069290906\n",
            "---> iteration:  81  partial loss: 0.0718798\n",
            "---> iteration:  82  partial loss: 0.11435863\n",
            "---> iteration:  83  partial loss: 0.1112897\n",
            "---> iteration:  84  partial loss: 0.058466922\n",
            "---> iteration:  85  partial loss: 0.08109505\n",
            "---> iteration:  86  partial loss: 0.089934625\n",
            "---> iteration:  87  partial loss: 0.09714877\n",
            "---> iteration:  88  partial loss: 0.061640084\n",
            "---> iteration:  89  partial loss: 0.046886954\n",
            "---> iteration:  90  partial loss: 0.0594323\n",
            "---> iteration:  91  partial loss: 0.11089654\n",
            "---> iteration:  92  partial loss: 0.06480112\n",
            "---> iteration:  93  partial loss: 0.052854992\n",
            "---> iteration:  94  partial loss: 0.060109228\n",
            "---> iteration:  95  partial loss: 0.040678468\n",
            "---> iteration:  96  partial loss: 0.027818918\n",
            "---> iteration:  97  partial loss: 0.24204263\n",
            "---> iteration:  98  partial loss: 0.050571326\n",
            "---> iteration:  99  partial loss: 0.108182\n",
            "---> iteration:  100  partial loss: 0.06314835\n",
            "---> iteration:  101  partial loss: 0.11399284\n",
            "---> iteration:  102  partial loss: 0.1359467\n",
            "---> iteration:  103  partial loss: 0.120274045\n",
            "---> iteration:  104  partial loss: 0.18148738\n",
            "---> iteration:  105  partial loss: 0.12230926\n",
            "---> iteration:  106  partial loss: 0.11223946\n",
            "---> iteration:  107  partial loss: 0.12921378\n",
            "---> iteration:  108  partial loss: 0.11059821\n",
            "---> iteration:  109  partial loss: 0.10072291\n",
            "---> iteration:  110  partial loss: 0.16219738\n",
            "---> iteration:  111  partial loss: 0.05493588\n",
            "---> iteration:  112  partial loss: 0.21556066\n",
            "---> iteration:  113  partial loss: 0.11030847\n",
            "---> iteration:  114  partial loss: 0.07138104\n",
            "---> iteration:  115  partial loss: 0.089486174\n",
            "---> iteration:  116  partial loss: 0.16160242\n",
            "---> iteration:  117  partial loss: 0.10781801\n",
            "---> iteration:  118  partial loss: 0.054759137\n",
            "---> iteration:  119  partial loss: 0.061436404\n",
            "---> iteration:  120  partial loss: 0.066813946\n",
            "---> iteration:  121  partial loss: 0.10100199\n",
            "---> iteration:  122  partial loss: 0.059567373\n",
            "---> iteration:  123  partial loss: 0.07712421\n",
            "---> iteration:  124  partial loss: 0.11603252\n",
            "---> iteration:  125  partial loss: 0.092654124\n",
            "---> iteration:  126  partial loss: 0.13774908\n",
            "---> iteration:  127  partial loss: 0.11297981\n",
            "---> iteration:  128  partial loss: 0.11063563\n",
            "---> iteration:  129  partial loss: 0.08127318\n",
            "---> iteration:  130  partial loss: 0.1475904\n",
            "---> iteration:  131  partial loss: 0.12615831\n",
            "---> iteration:  132  partial loss: 0.07904637\n",
            "---> iteration:  133  partial loss: 0.2083788\n",
            "---> iteration:  134  partial loss: 0.073788114\n",
            "---> iteration:  135  partial loss: 0.047102492\n",
            "---> iteration:  136  partial loss: 0.14709112\n",
            "---> iteration:  137  partial loss: 0.09439637\n",
            "---> iteration:  138  partial loss: 0.07008375\n",
            "---> iteration:  139  partial loss: 0.10872415\n",
            "---> iteration:  140  partial loss: 0.052022032\n",
            "---> iteration:  141  partial loss: 0.099025294\n",
            "---> iteration:  142  partial loss: 0.17327286\n",
            "---> iteration:  143  partial loss: 0.1504032\n",
            "---> iteration:  144  partial loss: 0.12656347\n",
            "---> iteration:  145  partial loss: 0.15581514\n",
            "---> iteration:  146  partial loss: 0.0972618\n",
            "---> iteration:  147  partial loss: 0.12848453\n",
            "---> iteration:  148  partial loss: 0.13041998\n",
            "---> iteration:  149  partial loss: 0.04272327\n",
            "---> iteration:  150  partial loss: 0.09118379\n",
            "---> iteration:  151  partial loss: 0.20655777\n",
            "---> iteration:  152  partial loss: 0.15735085\n",
            "---> iteration:  153  partial loss: 0.15367946\n",
            "---> iteration:  154  partial loss: 0.081385076\n",
            "---> iteration:  155  partial loss: 0.05444016\n",
            "---> iteration:  156  partial loss: 0.08565133\n",
            "---> iteration:  157  partial loss: 0.093688644\n",
            "---> iteration:  158  partial loss: 0.0845809\n",
            "---> iteration:  159  partial loss: 0.06169856\n",
            "---> iteration:  160  partial loss: 0.09466758\n",
            "---> iteration:  161  partial loss: 0.082435615\n",
            "---> iteration:  162  partial loss: 0.13113499\n",
            "---> iteration:  163  partial loss: 0.13097903\n",
            "---> iteration:  164  partial loss: 0.041668493\n",
            "---> iteration:  165  partial loss: 0.081080385\n",
            "---> iteration:  166  partial loss: 0.05656498\n",
            "---> iteration:  167  partial loss: 0.09638854\n",
            "---> iteration:  168  partial loss: 0.12878916\n",
            "---> iteration:  169  partial loss: 0.0858028\n",
            "---> iteration:  170  partial loss: 0.08551359\n",
            "---> iteration:  171  partial loss: 0.049787946\n",
            "---> iteration:  172  partial loss: 0.043977123\n",
            "---> iteration:  173  partial loss: 0.05396583\n",
            "---> iteration:  174  partial loss: 0.089698434\n",
            "---> iteration:  175  partial loss: 0.08984827\n",
            "---> iteration:  176  partial loss: 0.0678619\n",
            "---> iteration:  177  partial loss: 0.09298931\n",
            "---> iteration:  178  partial loss: 0.043819305\n",
            "---> iteration:  179  partial loss: 0.044519026\n",
            "---> iteration:  180  partial loss: 0.08162216\n",
            "---> iteration:  181  partial loss: 0.09893502\n",
            "---> iteration:  182  partial loss: 0.094135016\n",
            "---> iteration:  183  partial loss: 0.08107891\n",
            "---> iteration:  184  partial loss: 0.04818713\n",
            "---> iteration:  185  partial loss: 0.09743771\n",
            "---> iteration:  186  partial loss: 0.13099976\n",
            "---> iteration:  187  partial loss: 0.33712086\n",
            "---> iteration:  188  partial loss: 0.07448131\n",
            "---> iteration:  189  partial loss: 0.081400424\n",
            "---> iteration:  190  partial loss: 0.07640939\n",
            "---> iteration:  191  partial loss: 0.15582423\n",
            "---> iteration:  192  partial loss: 0.10976618\n",
            "---> iteration:  193  partial loss: 0.14006759\n",
            "---> iteration:  194  partial loss: 0.079326354\n",
            "---> iteration:  195  partial loss: 0.18934387\n",
            "---> iteration:  196  partial loss: 0.09046781\n",
            "---> iteration:  197  partial loss: 0.17281969\n",
            "---> iteration:  198  partial loss: 0.066831596\n",
            "---> iteration:  199  partial loss: 0.053718153\n",
            "---> iteration:  200  partial loss: 0.14585876\n",
            "---> iteration:  201  partial loss: 0.14427455\n",
            "---> iteration:  202  partial loss: 0.043570418\n",
            "---> iteration:  203  partial loss: 0.10773737\n",
            "---> iteration:  204  partial loss: 0.07892913\n",
            "---> iteration:  205  partial loss: 0.08027577\n",
            "---> iteration:  206  partial loss: 0.08440688\n",
            "---> iteration:  207  partial loss: 0.049664117\n",
            "---> iteration:  208  partial loss: 0.16391435\n",
            "---> iteration:  209  partial loss: 0.081178844\n",
            "---> iteration:  210  partial loss: 0.096812144\n",
            "---> iteration:  211  partial loss: 0.07622235\n",
            "---> iteration:  212  partial loss: 0.053707927\n",
            "---> iteration:  213  partial loss: 0.05013078\n",
            "---> iteration:  214  partial loss: 0.062261555\n",
            "---> iteration:  215  partial loss: 0.09518067\n",
            "---> iteration:  216  partial loss: 0.110107355\n",
            "---> iteration:  217  partial loss: 0.04181952\n",
            "---> iteration:  218  partial loss: 0.06454483\n",
            "---> iteration:  219  partial loss: 0.050539937\n",
            "---> iteration:  220  partial loss: 0.08532703\n",
            "---> iteration:  221  partial loss: 0.11115089\n",
            "---> iteration:  222  partial loss: 0.0810973\n",
            "---> iteration:  223  partial loss: 0.084808975\n",
            "---> iteration:  224  partial loss: 0.050101377\n",
            "---> iteration:  225  partial loss: 0.1264857\n",
            "---> iteration:  226  partial loss: 0.052925207\n",
            "---> iteration:  227  partial loss: 0.031306017\n",
            "---> iteration:  228  partial loss: 0.16806121\n",
            "---> iteration:  229  partial loss: 0.12951204\n",
            "---> iteration:  230  partial loss: 0.029321201\n",
            "---> iteration:  231  partial loss: 0.15150723\n",
            "---> iteration:  232  partial loss: 0.06147518\n",
            "---> iteration:  233  partial loss: 0.088701226\n",
            "---> iteration:  234  partial loss: 0.096604116\n",
            "---> iteration:  235  partial loss: 0.09604424\n",
            "---> iteration:  236  partial loss: 0.039528064\n",
            "---> iteration:  237  partial loss: 0.0766159\n",
            "---> iteration:  238  partial loss: 0.04882141\n",
            "---> iteration:  239  partial loss: 0.22476773\n",
            "---> iteration:  240  partial loss: 0.106091954\n",
            "---> iteration:  241  partial loss: 0.04768486\n",
            "---> iteration:  242  partial loss: 0.08103943\n",
            "---> iteration:  243  partial loss: 0.10867063\n",
            "---> iteration:  244  partial loss: 0.09067298\n",
            "---> iteration:  245  partial loss: 0.28566265\n",
            "---> iteration:  246  partial loss: 0.09082599\n",
            "---> iteration:  247  partial loss: 0.070514634\n",
            "---> iteration:  248  partial loss: 0.071235776\n",
            "---> iteration:  249  partial loss: 0.10106004\n",
            "---> iteration:  250  partial loss: 0.08460455\n",
            "---> iteration:  251  partial loss: 0.14166863\n",
            "---> iteration:  252  partial loss: 0.10396809\n",
            "---> iteration:  253  partial loss: 0.08602387\n",
            "---> iteration:  254  partial loss: 0.033374853\n",
            "---> iteration:  255  partial loss: 0.14777495\n",
            "---> iteration:  256  partial loss: 0.069359235\n",
            "---> iteration:  257  partial loss: 0.07982218\n",
            "---> iteration:  258  partial loss: 0.08003656\n",
            "---> iteration:  259  partial loss: 0.082167596\n",
            "---> iteration:  260  partial loss: 0.17291352\n",
            "---> iteration:  261  partial loss: 0.058089223\n",
            "---> iteration:  262  partial loss: 0.10403654\n",
            "---> iteration:  263  partial loss: 0.044225395\n",
            "---> iteration:  264  partial loss: 0.1078075\n",
            "---> iteration:  265  partial loss: 0.06052568\n",
            "---> iteration:  266  partial loss: 0.07303303\n",
            "---> iteration:  267  partial loss: 0.16189042\n",
            "---> iteration:  268  partial loss: 0.12088916\n",
            "---> iteration:  269  partial loss: 0.19544424\n",
            "---> iteration:  270  partial loss: 0.095221266\n",
            "---> iteration:  271  partial loss: 0.09888267\n",
            "---> iteration:  272  partial loss: 0.114856064\n",
            "---> iteration:  273  partial loss: 0.1031545\n",
            "---> iteration:  274  partial loss: 0.097545646\n",
            "---> iteration:  275  partial loss: 0.13117178\n",
            "---> iteration:  276  partial loss: 0.17715353\n",
            "---> iteration:  277  partial loss: 0.044555254\n",
            "---> iteration:  278  partial loss: 0.09018932\n",
            "---> iteration:  279  partial loss: 0.097569436\n",
            "---> iteration:  280  partial loss: 0.111222\n",
            "---> iteration:  281  partial loss: 0.10976425\n",
            "---> iteration:  282  partial loss: 0.044467323\n",
            "---> iteration:  283  partial loss: 0.06272933\n",
            "---> iteration:  284  partial loss: 0.096969955\n",
            "---> iteration:  285  partial loss: 0.11112201\n",
            "---> iteration:  286  partial loss: 0.085645914\n",
            "---> iteration:  287  partial loss: 0.053761736\n",
            "---> iteration:  288  partial loss: 0.122237615\n",
            "---> iteration:  289  partial loss: 0.08536683\n",
            "------------------\n",
            "epoch:  9  of  20 training loss:  0.09757398710840713\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.15087543\n",
            "---> iteration:  2  partial loss: 0.07081978\n",
            "---> iteration:  3  partial loss: 0.08152028\n",
            "---> iteration:  4  partial loss: 0.102453955\n",
            "---> iteration:  5  partial loss: 0.10312903\n",
            "---> iteration:  6  partial loss: 0.07097566\n",
            "---> iteration:  7  partial loss: 0.09750703\n",
            "---> iteration:  8  partial loss: 0.078096665\n",
            "---> iteration:  9  partial loss: 0.09099758\n",
            "---> iteration:  10  partial loss: 0.041308127\n",
            "---> iteration:  11  partial loss: 0.057127427\n",
            "---> iteration:  12  partial loss: 0.05786517\n",
            "---> iteration:  13  partial loss: 0.33011737\n",
            "---> iteration:  14  partial loss: 0.053930644\n",
            "---> iteration:  15  partial loss: 0.061473988\n",
            "---> iteration:  16  partial loss: 0.047153898\n",
            "---> iteration:  17  partial loss: 0.13961641\n",
            "---> iteration:  18  partial loss: 0.0735395\n",
            "---> iteration:  19  partial loss: 0.0824614\n",
            "---> iteration:  20  partial loss: 0.055054452\n",
            "---> iteration:  21  partial loss: 0.061949763\n",
            "---> iteration:  22  partial loss: 0.03608426\n",
            "---> iteration:  23  partial loss: 0.08267627\n",
            "---> iteration:  24  partial loss: 0.064912036\n",
            "---> iteration:  25  partial loss: 0.115664825\n",
            "---> iteration:  26  partial loss: 0.09398784\n",
            "---> iteration:  27  partial loss: 0.08566005\n",
            "---> iteration:  28  partial loss: 0.062490284\n",
            "---> iteration:  29  partial loss: 0.19145347\n",
            "---> iteration:  30  partial loss: 0.070602894\n",
            "---> iteration:  31  partial loss: 0.04833994\n",
            "---> iteration:  32  partial loss: 0.10495818\n",
            "---> iteration:  33  partial loss: 0.0475822\n",
            "---> iteration:  34  partial loss: 0.1387391\n",
            "---> iteration:  35  partial loss: 0.10859232\n",
            "---> iteration:  36  partial loss: 0.122882545\n",
            "---> iteration:  37  partial loss: 0.046552047\n",
            "---> iteration:  38  partial loss: 0.16234896\n",
            "---> iteration:  39  partial loss: 0.12335303\n",
            "---> iteration:  40  partial loss: 0.12985721\n",
            "---> iteration:  41  partial loss: 0.15267363\n",
            "---> iteration:  42  partial loss: 0.124009684\n",
            "---> iteration:  43  partial loss: 0.10724994\n",
            "---> iteration:  44  partial loss: 0.16341467\n",
            "---> iteration:  45  partial loss: 0.05335941\n",
            "---> iteration:  46  partial loss: 0.110031106\n",
            "---> iteration:  47  partial loss: 0.04035246\n",
            "---> iteration:  48  partial loss: 0.07926972\n",
            "---> iteration:  49  partial loss: 0.10014898\n",
            "---> iteration:  50  partial loss: 0.17170455\n",
            "---> iteration:  51  partial loss: 0.05137644\n",
            "---> iteration:  52  partial loss: 0.085349634\n",
            "---> iteration:  53  partial loss: 0.07331829\n",
            "---> iteration:  54  partial loss: 0.22145674\n",
            "---> iteration:  55  partial loss: 0.08388825\n",
            "---> iteration:  56  partial loss: 0.14013043\n",
            "---> iteration:  57  partial loss: 0.069697544\n",
            "---> iteration:  58  partial loss: 0.0588267\n",
            "---> iteration:  59  partial loss: 0.12924747\n",
            "---> iteration:  60  partial loss: 0.13601921\n",
            "---> iteration:  61  partial loss: 0.029256338\n",
            "---> iteration:  62  partial loss: 0.09952911\n",
            "---> iteration:  63  partial loss: 0.120390974\n",
            "---> iteration:  64  partial loss: 0.05171362\n",
            "---> iteration:  65  partial loss: 0.10723834\n",
            "---> iteration:  66  partial loss: 0.049988534\n",
            "---> iteration:  67  partial loss: 0.08024692\n",
            "---> iteration:  68  partial loss: 0.16114959\n",
            "---> iteration:  69  partial loss: 0.10820346\n",
            "---> iteration:  70  partial loss: 0.13820606\n",
            "---> iteration:  71  partial loss: 0.08067074\n",
            "---> iteration:  72  partial loss: 0.08546372\n",
            "---> iteration:  73  partial loss: 0.09385776\n",
            "---> iteration:  74  partial loss: 0.085987136\n",
            "---> iteration:  75  partial loss: 0.05852076\n",
            "---> iteration:  76  partial loss: 0.046798732\n",
            "---> iteration:  77  partial loss: 0.03592816\n",
            "---> iteration:  78  partial loss: 0.06943221\n",
            "---> iteration:  79  partial loss: 0.038461175\n",
            "---> iteration:  80  partial loss: 0.08671767\n",
            "---> iteration:  81  partial loss: 0.23550919\n",
            "---> iteration:  82  partial loss: 0.03976202\n",
            "---> iteration:  83  partial loss: 0.09562209\n",
            "---> iteration:  84  partial loss: 0.06422333\n",
            "---> iteration:  85  partial loss: 0.059586123\n",
            "---> iteration:  86  partial loss: 0.041826077\n",
            "---> iteration:  87  partial loss: 0.09298137\n",
            "---> iteration:  88  partial loss: 0.075661376\n",
            "---> iteration:  89  partial loss: 0.06504357\n",
            "---> iteration:  90  partial loss: 0.083459385\n",
            "---> iteration:  91  partial loss: 0.15312992\n",
            "---> iteration:  92  partial loss: 0.080172196\n",
            "---> iteration:  93  partial loss: 0.04559193\n",
            "---> iteration:  94  partial loss: 0.13650343\n",
            "---> iteration:  95  partial loss: 0.03716373\n",
            "---> iteration:  96  partial loss: 0.04539811\n",
            "---> iteration:  97  partial loss: 0.116659485\n",
            "---> iteration:  98  partial loss: 0.1786236\n",
            "---> iteration:  99  partial loss: 0.10668715\n",
            "---> iteration:  100  partial loss: 0.10662329\n",
            "---> iteration:  101  partial loss: 0.12613927\n",
            "---> iteration:  102  partial loss: 0.10317978\n",
            "---> iteration:  103  partial loss: 0.096921965\n",
            "---> iteration:  104  partial loss: 0.086560555\n",
            "---> iteration:  105  partial loss: 0.05499963\n",
            "---> iteration:  106  partial loss: 0.1495914\n",
            "---> iteration:  107  partial loss: 0.052930005\n",
            "---> iteration:  108  partial loss: 0.09311763\n",
            "---> iteration:  109  partial loss: 0.06309614\n",
            "---> iteration:  110  partial loss: 0.034326218\n",
            "---> iteration:  111  partial loss: 0.09506982\n",
            "---> iteration:  112  partial loss: 0.054580245\n",
            "---> iteration:  113  partial loss: 0.049130324\n",
            "---> iteration:  114  partial loss: 0.10322887\n",
            "---> iteration:  115  partial loss: 0.1174684\n",
            "---> iteration:  116  partial loss: 0.20305176\n",
            "---> iteration:  117  partial loss: 0.047000144\n",
            "---> iteration:  118  partial loss: 0.07717393\n",
            "---> iteration:  119  partial loss: 0.06766663\n",
            "---> iteration:  120  partial loss: 0.073636584\n",
            "---> iteration:  121  partial loss: 0.11969295\n",
            "---> iteration:  122  partial loss: 0.063659646\n",
            "---> iteration:  123  partial loss: 0.09329329\n",
            "---> iteration:  124  partial loss: 0.1692244\n",
            "---> iteration:  125  partial loss: 0.1231512\n",
            "---> iteration:  126  partial loss: 0.1347734\n",
            "---> iteration:  127  partial loss: 0.069623716\n",
            "---> iteration:  128  partial loss: 0.04825173\n",
            "---> iteration:  129  partial loss: 0.03230575\n",
            "---> iteration:  130  partial loss: 0.085283384\n",
            "---> iteration:  131  partial loss: 0.051420063\n",
            "---> iteration:  132  partial loss: 0.16091153\n",
            "---> iteration:  133  partial loss: 0.04329119\n",
            "---> iteration:  134  partial loss: 0.17690171\n",
            "---> iteration:  135  partial loss: 0.11193197\n",
            "---> iteration:  136  partial loss: 0.060726203\n",
            "---> iteration:  137  partial loss: 0.04005136\n",
            "---> iteration:  138  partial loss: 0.18910898\n",
            "---> iteration:  139  partial loss: 0.04651592\n",
            "---> iteration:  140  partial loss: 0.101159774\n",
            "---> iteration:  141  partial loss: 0.07560973\n",
            "---> iteration:  142  partial loss: 0.082811676\n",
            "---> iteration:  143  partial loss: 0.07714533\n",
            "---> iteration:  144  partial loss: 0.073891714\n",
            "---> iteration:  145  partial loss: 0.07187081\n",
            "---> iteration:  146  partial loss: 0.04192226\n",
            "---> iteration:  147  partial loss: 0.059209973\n",
            "---> iteration:  148  partial loss: 0.07414867\n",
            "---> iteration:  149  partial loss: 0.14815548\n",
            "---> iteration:  150  partial loss: 0.071537144\n",
            "---> iteration:  151  partial loss: 0.07166105\n",
            "---> iteration:  152  partial loss: 0.1023627\n",
            "---> iteration:  153  partial loss: 0.058885507\n",
            "---> iteration:  154  partial loss: 0.052944288\n",
            "---> iteration:  155  partial loss: 0.039602783\n",
            "---> iteration:  156  partial loss: 0.064662255\n",
            "---> iteration:  157  partial loss: 0.1065577\n",
            "---> iteration:  158  partial loss: 0.08370217\n",
            "---> iteration:  159  partial loss: 0.035495333\n",
            "---> iteration:  160  partial loss: 0.09541379\n",
            "---> iteration:  161  partial loss: 0.09727022\n",
            "---> iteration:  162  partial loss: 0.06272838\n",
            "---> iteration:  163  partial loss: 0.23566051\n",
            "---> iteration:  164  partial loss: 0.112405606\n",
            "---> iteration:  165  partial loss: 0.10427225\n",
            "---> iteration:  166  partial loss: 0.07652003\n",
            "---> iteration:  167  partial loss: 0.08157982\n",
            "---> iteration:  168  partial loss: 0.08158067\n",
            "---> iteration:  169  partial loss: 0.041853722\n",
            "---> iteration:  170  partial loss: 0.08691389\n",
            "---> iteration:  171  partial loss: 0.08082063\n",
            "---> iteration:  172  partial loss: 0.052154467\n",
            "---> iteration:  173  partial loss: 0.17875148\n",
            "---> iteration:  174  partial loss: 0.14114855\n",
            "---> iteration:  175  partial loss: 0.05938975\n",
            "---> iteration:  176  partial loss: 0.061988644\n",
            "---> iteration:  177  partial loss: 0.079964645\n",
            "---> iteration:  178  partial loss: 0.044976924\n",
            "---> iteration:  179  partial loss: 0.029727433\n",
            "---> iteration:  180  partial loss: 0.041022334\n",
            "---> iteration:  181  partial loss: 0.10491688\n",
            "---> iteration:  182  partial loss: 0.101994745\n",
            "---> iteration:  183  partial loss: 0.033987034\n",
            "---> iteration:  184  partial loss: 0.03532586\n",
            "---> iteration:  185  partial loss: 0.05155584\n",
            "---> iteration:  186  partial loss: 0.08378712\n",
            "---> iteration:  187  partial loss: 0.055995718\n",
            "---> iteration:  188  partial loss: 0.042525318\n",
            "---> iteration:  189  partial loss: 0.095511116\n",
            "---> iteration:  190  partial loss: 0.050218016\n",
            "---> iteration:  191  partial loss: 0.036268275\n",
            "---> iteration:  192  partial loss: 0.08134054\n",
            "---> iteration:  193  partial loss: 0.083977714\n",
            "---> iteration:  194  partial loss: 0.054022565\n",
            "---> iteration:  195  partial loss: 0.07120522\n",
            "---> iteration:  196  partial loss: 0.09086554\n",
            "---> iteration:  197  partial loss: 0.069370076\n",
            "---> iteration:  198  partial loss: 0.08206709\n",
            "---> iteration:  199  partial loss: 0.04422158\n",
            "---> iteration:  200  partial loss: 0.053304512\n",
            "---> iteration:  201  partial loss: 0.06970874\n",
            "---> iteration:  202  partial loss: 0.07541411\n",
            "---> iteration:  203  partial loss: 0.114541106\n",
            "---> iteration:  204  partial loss: 0.05988657\n",
            "---> iteration:  205  partial loss: 0.14643829\n",
            "---> iteration:  206  partial loss: 0.07055061\n",
            "---> iteration:  207  partial loss: 0.087336846\n",
            "---> iteration:  208  partial loss: 0.09056248\n",
            "---> iteration:  209  partial loss: 0.09159986\n",
            "---> iteration:  210  partial loss: 0.051465534\n",
            "---> iteration:  211  partial loss: 0.06679623\n",
            "---> iteration:  212  partial loss: 0.11719318\n",
            "---> iteration:  213  partial loss: 0.09653432\n",
            "---> iteration:  214  partial loss: 0.08816784\n",
            "---> iteration:  215  partial loss: 0.07717678\n",
            "---> iteration:  216  partial loss: 0.09319\n",
            "---> iteration:  217  partial loss: 0.07371891\n",
            "---> iteration:  218  partial loss: 0.04962407\n",
            "---> iteration:  219  partial loss: 0.032916367\n",
            "---> iteration:  220  partial loss: 0.043360904\n",
            "---> iteration:  221  partial loss: 0.06548108\n",
            "---> iteration:  222  partial loss: 0.07708579\n",
            "---> iteration:  223  partial loss: 0.09023895\n",
            "---> iteration:  224  partial loss: 0.12543438\n",
            "---> iteration:  225  partial loss: 0.07948043\n",
            "---> iteration:  226  partial loss: 0.044984106\n",
            "---> iteration:  227  partial loss: 0.10966658\n",
            "---> iteration:  228  partial loss: 0.19106786\n",
            "---> iteration:  229  partial loss: 0.115363754\n",
            "---> iteration:  230  partial loss: 0.11611198\n",
            "---> iteration:  231  partial loss: 0.062431134\n",
            "---> iteration:  232  partial loss: 0.13762535\n",
            "---> iteration:  233  partial loss: 0.034631845\n",
            "---> iteration:  234  partial loss: 0.07065283\n",
            "---> iteration:  235  partial loss: 0.21719205\n",
            "---> iteration:  236  partial loss: 0.0438221\n",
            "---> iteration:  237  partial loss: 0.06740835\n",
            "---> iteration:  238  partial loss: 0.13190778\n",
            "---> iteration:  239  partial loss: 0.08636189\n",
            "---> iteration:  240  partial loss: 0.05261596\n",
            "---> iteration:  241  partial loss: 0.078798294\n",
            "---> iteration:  242  partial loss: 0.16971308\n",
            "---> iteration:  243  partial loss: 0.031016229\n",
            "---> iteration:  244  partial loss: 0.073648974\n",
            "---> iteration:  245  partial loss: 0.05702789\n",
            "---> iteration:  246  partial loss: 0.07204563\n",
            "---> iteration:  247  partial loss: 0.07452643\n",
            "---> iteration:  248  partial loss: 0.06261171\n",
            "---> iteration:  249  partial loss: 0.14947355\n",
            "---> iteration:  250  partial loss: 0.08085426\n",
            "---> iteration:  251  partial loss: 0.185836\n",
            "---> iteration:  252  partial loss: 0.12531768\n",
            "---> iteration:  253  partial loss: 0.061479874\n",
            "---> iteration:  254  partial loss: 0.035896968\n",
            "---> iteration:  255  partial loss: 0.0842461\n",
            "---> iteration:  256  partial loss: 0.09409148\n",
            "---> iteration:  257  partial loss: 0.07487875\n",
            "---> iteration:  258  partial loss: 0.055234738\n",
            "---> iteration:  259  partial loss: 0.05391711\n",
            "---> iteration:  260  partial loss: 0.042693276\n",
            "---> iteration:  261  partial loss: 0.051616807\n",
            "---> iteration:  262  partial loss: 0.11925689\n",
            "---> iteration:  263  partial loss: 0.04869442\n",
            "---> iteration:  264  partial loss: 0.044082925\n",
            "---> iteration:  265  partial loss: 0.04358259\n",
            "---> iteration:  266  partial loss: 0.034059186\n",
            "---> iteration:  267  partial loss: 0.038917594\n",
            "---> iteration:  268  partial loss: 0.03080289\n",
            "---> iteration:  269  partial loss: 0.09755343\n",
            "---> iteration:  270  partial loss: 0.026816461\n",
            "---> iteration:  271  partial loss: 0.08093129\n",
            "---> iteration:  272  partial loss: 0.12246602\n",
            "---> iteration:  273  partial loss: 0.043487374\n",
            "---> iteration:  274  partial loss: 0.07176144\n",
            "---> iteration:  275  partial loss: 0.1077021\n",
            "---> iteration:  276  partial loss: 0.106529966\n",
            "---> iteration:  277  partial loss: 0.084697254\n",
            "---> iteration:  278  partial loss: 0.07360227\n",
            "---> iteration:  279  partial loss: 0.09413912\n",
            "---> iteration:  280  partial loss: 0.04074641\n",
            "---> iteration:  281  partial loss: 0.05431911\n",
            "---> iteration:  282  partial loss: 0.082616724\n",
            "---> iteration:  283  partial loss: 0.084354356\n",
            "---> iteration:  284  partial loss: 0.20764889\n",
            "---> iteration:  285  partial loss: 0.055851832\n",
            "---> iteration:  286  partial loss: 0.07741509\n",
            "---> iteration:  287  partial loss: 0.08590405\n",
            "---> iteration:  288  partial loss: 0.09176585\n",
            "---> iteration:  289  partial loss: 0.06965335\n",
            "------------------\n",
            "epoch:  10  of  20 training loss:  0.08638471780041922\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.102282226\n",
            "---> iteration:  2  partial loss: 0.06140824\n",
            "---> iteration:  3  partial loss: 0.041657966\n",
            "---> iteration:  4  partial loss: 0.1659666\n",
            "---> iteration:  5  partial loss: 0.087287255\n",
            "---> iteration:  6  partial loss: 0.058074072\n",
            "---> iteration:  7  partial loss: 0.08281526\n",
            "---> iteration:  8  partial loss: 0.07035326\n",
            "---> iteration:  9  partial loss: 0.12901552\n",
            "---> iteration:  10  partial loss: 0.055100325\n",
            "---> iteration:  11  partial loss: 0.07473634\n",
            "---> iteration:  12  partial loss: 0.114855014\n",
            "---> iteration:  13  partial loss: 0.09174766\n",
            "---> iteration:  14  partial loss: 0.053401746\n",
            "---> iteration:  15  partial loss: 0.059056524\n",
            "---> iteration:  16  partial loss: 0.069587186\n",
            "---> iteration:  17  partial loss: 0.05125353\n",
            "---> iteration:  18  partial loss: 0.07136661\n",
            "---> iteration:  19  partial loss: 0.10997115\n",
            "---> iteration:  20  partial loss: 0.06884379\n",
            "---> iteration:  21  partial loss: 0.049874045\n",
            "---> iteration:  22  partial loss: 0.049144153\n",
            "---> iteration:  23  partial loss: 0.08069138\n",
            "---> iteration:  24  partial loss: 0.076446354\n",
            "---> iteration:  25  partial loss: 0.03846136\n",
            "---> iteration:  26  partial loss: 0.085318975\n",
            "---> iteration:  27  partial loss: 0.06411544\n",
            "---> iteration:  28  partial loss: 0.038166318\n",
            "---> iteration:  29  partial loss: 0.027681878\n",
            "---> iteration:  30  partial loss: 0.10217785\n",
            "---> iteration:  31  partial loss: 0.027468055\n",
            "---> iteration:  32  partial loss: 0.10601269\n",
            "---> iteration:  33  partial loss: 0.06631866\n",
            "---> iteration:  34  partial loss: 0.07888875\n",
            "---> iteration:  35  partial loss: 0.052459326\n",
            "---> iteration:  36  partial loss: 0.08474991\n",
            "---> iteration:  37  partial loss: 0.093686305\n",
            "---> iteration:  38  partial loss: 0.113208815\n",
            "---> iteration:  39  partial loss: 0.053368308\n",
            "---> iteration:  40  partial loss: 0.051392354\n",
            "---> iteration:  41  partial loss: 0.119587965\n",
            "---> iteration:  42  partial loss: 0.036703262\n",
            "---> iteration:  43  partial loss: 0.069042504\n",
            "---> iteration:  44  partial loss: 0.06663065\n",
            "---> iteration:  45  partial loss: 0.054796416\n",
            "---> iteration:  46  partial loss: 0.07060652\n",
            "---> iteration:  47  partial loss: 0.03138991\n",
            "---> iteration:  48  partial loss: 0.06186294\n",
            "---> iteration:  49  partial loss: 0.098016016\n",
            "---> iteration:  50  partial loss: 0.04409801\n",
            "---> iteration:  51  partial loss: 0.0858981\n",
            "---> iteration:  52  partial loss: 0.06470324\n",
            "---> iteration:  53  partial loss: 0.1067132\n",
            "---> iteration:  54  partial loss: 0.09653874\n",
            "---> iteration:  55  partial loss: 0.048062854\n",
            "---> iteration:  56  partial loss: 0.06396285\n",
            "---> iteration:  57  partial loss: 0.05779638\n",
            "---> iteration:  58  partial loss: 0.05034781\n",
            "---> iteration:  59  partial loss: 0.09167949\n",
            "---> iteration:  60  partial loss: 0.084877335\n",
            "---> iteration:  61  partial loss: 0.14239644\n",
            "---> iteration:  62  partial loss: 0.19311468\n",
            "---> iteration:  63  partial loss: 0.04717601\n",
            "---> iteration:  64  partial loss: 0.08809583\n",
            "---> iteration:  65  partial loss: 0.06312091\n",
            "---> iteration:  66  partial loss: 0.057737563\n",
            "---> iteration:  67  partial loss: 0.047189675\n",
            "---> iteration:  68  partial loss: 0.073171444\n",
            "---> iteration:  69  partial loss: 0.19934586\n",
            "---> iteration:  70  partial loss: 0.06838231\n",
            "---> iteration:  71  partial loss: 0.053184837\n",
            "---> iteration:  72  partial loss: 0.08365525\n",
            "---> iteration:  73  partial loss: 0.07953382\n",
            "---> iteration:  74  partial loss: 0.13522528\n",
            "---> iteration:  75  partial loss: 0.21179189\n",
            "---> iteration:  76  partial loss: 0.08204426\n",
            "---> iteration:  77  partial loss: 0.058943033\n",
            "---> iteration:  78  partial loss: 0.15120679\n",
            "---> iteration:  79  partial loss: 0.10856684\n",
            "---> iteration:  80  partial loss: 0.13830362\n",
            "---> iteration:  81  partial loss: 0.11207979\n",
            "---> iteration:  82  partial loss: 0.07612851\n",
            "---> iteration:  83  partial loss: 0.1306095\n",
            "---> iteration:  84  partial loss: 0.04425056\n",
            "---> iteration:  85  partial loss: 0.119896695\n",
            "---> iteration:  86  partial loss: 0.10870791\n",
            "---> iteration:  87  partial loss: 0.10278454\n",
            "---> iteration:  88  partial loss: 0.08013155\n",
            "---> iteration:  89  partial loss: 0.06956879\n",
            "---> iteration:  90  partial loss: 0.06749966\n",
            "---> iteration:  91  partial loss: 0.11649051\n",
            "---> iteration:  92  partial loss: 0.082852915\n",
            "---> iteration:  93  partial loss: 0.03271875\n",
            "---> iteration:  94  partial loss: 0.16913988\n",
            "---> iteration:  95  partial loss: 0.10464982\n",
            "---> iteration:  96  partial loss: 0.09370613\n",
            "---> iteration:  97  partial loss: 0.05224742\n",
            "---> iteration:  98  partial loss: 0.036724154\n",
            "---> iteration:  99  partial loss: 0.035651855\n",
            "---> iteration:  100  partial loss: 0.08080464\n",
            "---> iteration:  101  partial loss: 0.071537085\n",
            "---> iteration:  102  partial loss: 0.107474096\n",
            "---> iteration:  103  partial loss: 0.043664154\n",
            "---> iteration:  104  partial loss: 0.034041457\n",
            "---> iteration:  105  partial loss: 0.05765655\n",
            "---> iteration:  106  partial loss: 0.060745902\n",
            "---> iteration:  107  partial loss: 0.031014893\n",
            "---> iteration:  108  partial loss: 0.086695515\n",
            "---> iteration:  109  partial loss: 0.06316915\n",
            "---> iteration:  110  partial loss: 0.058616698\n",
            "---> iteration:  111  partial loss: 0.09401828\n",
            "---> iteration:  112  partial loss: 0.18901053\n",
            "---> iteration:  113  partial loss: 0.06911002\n",
            "---> iteration:  114  partial loss: 0.06307178\n",
            "---> iteration:  115  partial loss: 0.09340993\n",
            "---> iteration:  116  partial loss: 0.06459058\n",
            "---> iteration:  117  partial loss: 0.048944596\n",
            "---> iteration:  118  partial loss: 0.079551615\n",
            "---> iteration:  119  partial loss: 0.08415948\n",
            "---> iteration:  120  partial loss: 0.055355623\n",
            "---> iteration:  121  partial loss: 0.05093045\n",
            "---> iteration:  122  partial loss: 0.03486367\n",
            "---> iteration:  123  partial loss: 0.101526454\n",
            "---> iteration:  124  partial loss: 0.07991729\n",
            "---> iteration:  125  partial loss: 0.079083756\n",
            "---> iteration:  126  partial loss: 0.090687506\n",
            "---> iteration:  127  partial loss: 0.038770203\n",
            "---> iteration:  128  partial loss: 0.042143278\n",
            "---> iteration:  129  partial loss: 0.045112185\n",
            "---> iteration:  130  partial loss: 0.06544067\n",
            "---> iteration:  131  partial loss: 0.082077995\n",
            "---> iteration:  132  partial loss: 0.04029223\n",
            "---> iteration:  133  partial loss: 0.04566366\n",
            "---> iteration:  134  partial loss: 0.08409084\n",
            "---> iteration:  135  partial loss: 0.0819146\n",
            "---> iteration:  136  partial loss: 0.06088406\n",
            "---> iteration:  137  partial loss: 0.22206715\n",
            "---> iteration:  138  partial loss: 0.041888423\n",
            "---> iteration:  139  partial loss: 0.09898528\n",
            "---> iteration:  140  partial loss: 0.031098366\n",
            "---> iteration:  141  partial loss: 0.10221609\n",
            "---> iteration:  142  partial loss: 0.061296176\n",
            "---> iteration:  143  partial loss: 0.11066273\n",
            "---> iteration:  144  partial loss: 0.022558127\n",
            "---> iteration:  145  partial loss: 0.03254492\n",
            "---> iteration:  146  partial loss: 0.086852595\n",
            "---> iteration:  147  partial loss: 0.023529967\n",
            "---> iteration:  148  partial loss: 0.104929045\n",
            "---> iteration:  149  partial loss: 0.100490294\n",
            "---> iteration:  150  partial loss: 0.05777164\n",
            "---> iteration:  151  partial loss: 0.1910339\n",
            "---> iteration:  152  partial loss: 0.09349434\n",
            "---> iteration:  153  partial loss: 0.09757431\n",
            "---> iteration:  154  partial loss: 0.0584316\n",
            "---> iteration:  155  partial loss: 0.11420524\n",
            "---> iteration:  156  partial loss: 0.09059287\n",
            "---> iteration:  157  partial loss: 0.04168312\n",
            "---> iteration:  158  partial loss: 0.03666785\n",
            "---> iteration:  159  partial loss: 0.06940739\n",
            "---> iteration:  160  partial loss: 0.05195398\n",
            "---> iteration:  161  partial loss: 0.0430949\n",
            "---> iteration:  162  partial loss: 0.03390379\n",
            "---> iteration:  163  partial loss: 0.13506168\n",
            "---> iteration:  164  partial loss: 0.06980801\n",
            "---> iteration:  165  partial loss: 0.056341514\n",
            "---> iteration:  166  partial loss: 0.13501371\n",
            "---> iteration:  167  partial loss: 0.050832286\n",
            "---> iteration:  168  partial loss: 0.11035129\n",
            "---> iteration:  169  partial loss: 0.04501214\n",
            "---> iteration:  170  partial loss: 0.03530981\n",
            "---> iteration:  171  partial loss: 0.0405788\n",
            "---> iteration:  172  partial loss: 0.13903818\n",
            "---> iteration:  173  partial loss: 0.03845659\n",
            "---> iteration:  174  partial loss: 0.036949866\n",
            "---> iteration:  175  partial loss: 0.07330102\n",
            "---> iteration:  176  partial loss: 0.09568452\n",
            "---> iteration:  177  partial loss: 0.074241325\n",
            "---> iteration:  178  partial loss: 0.07955405\n",
            "---> iteration:  179  partial loss: 0.061380222\n",
            "---> iteration:  180  partial loss: 0.032372344\n",
            "---> iteration:  181  partial loss: 0.09776128\n",
            "---> iteration:  182  partial loss: 0.038358014\n",
            "---> iteration:  183  partial loss: 0.08812317\n",
            "---> iteration:  184  partial loss: 0.036115408\n",
            "---> iteration:  185  partial loss: 0.104319215\n",
            "---> iteration:  186  partial loss: 0.051262766\n",
            "---> iteration:  187  partial loss: 0.078693785\n",
            "---> iteration:  188  partial loss: 0.12489696\n",
            "---> iteration:  189  partial loss: 0.09436841\n",
            "---> iteration:  190  partial loss: 0.050819587\n",
            "---> iteration:  191  partial loss: 0.03563216\n",
            "---> iteration:  192  partial loss: 0.08619728\n",
            "---> iteration:  193  partial loss: 0.034523007\n",
            "---> iteration:  194  partial loss: 0.06887448\n",
            "---> iteration:  195  partial loss: 0.07635936\n",
            "---> iteration:  196  partial loss: 0.04768511\n",
            "---> iteration:  197  partial loss: 0.032931168\n",
            "---> iteration:  198  partial loss: 0.07026494\n",
            "---> iteration:  199  partial loss: 0.066093795\n",
            "---> iteration:  200  partial loss: 0.04944033\n",
            "---> iteration:  201  partial loss: 0.1078242\n",
            "---> iteration:  202  partial loss: 0.046513747\n",
            "---> iteration:  203  partial loss: 0.054656517\n",
            "---> iteration:  204  partial loss: 0.06344803\n",
            "---> iteration:  205  partial loss: 0.05575928\n",
            "---> iteration:  206  partial loss: 0.11545379\n",
            "---> iteration:  207  partial loss: 0.10237242\n",
            "---> iteration:  208  partial loss: 0.05126818\n",
            "---> iteration:  209  partial loss: 0.16031641\n",
            "---> iteration:  210  partial loss: 0.04031135\n",
            "---> iteration:  211  partial loss: 0.07073435\n",
            "---> iteration:  212  partial loss: 0.06290575\n",
            "---> iteration:  213  partial loss: 0.12689026\n",
            "---> iteration:  214  partial loss: 0.05996329\n",
            "---> iteration:  215  partial loss: 0.03350469\n",
            "---> iteration:  216  partial loss: 0.12999977\n",
            "---> iteration:  217  partial loss: 0.024473514\n",
            "---> iteration:  218  partial loss: 0.14912511\n",
            "---> iteration:  219  partial loss: 0.0926138\n",
            "---> iteration:  220  partial loss: 0.09731396\n",
            "---> iteration:  221  partial loss: 0.07889305\n",
            "---> iteration:  222  partial loss: 0.10970582\n",
            "---> iteration:  223  partial loss: 0.07830204\n",
            "---> iteration:  224  partial loss: 0.083984345\n",
            "---> iteration:  225  partial loss: 0.083303995\n",
            "---> iteration:  226  partial loss: 0.12649947\n",
            "---> iteration:  227  partial loss: 0.077668436\n",
            "---> iteration:  228  partial loss: 0.082607865\n",
            "---> iteration:  229  partial loss: 0.1457797\n",
            "---> iteration:  230  partial loss: 0.078451395\n",
            "---> iteration:  231  partial loss: 0.09401874\n",
            "---> iteration:  232  partial loss: 0.26743034\n",
            "---> iteration:  233  partial loss: 0.041164484\n",
            "---> iteration:  234  partial loss: 0.051924225\n",
            "---> iteration:  235  partial loss: 0.07091665\n",
            "---> iteration:  236  partial loss: 0.08724163\n",
            "---> iteration:  237  partial loss: 0.07454469\n",
            "---> iteration:  238  partial loss: 0.13186947\n",
            "---> iteration:  239  partial loss: 0.16677502\n",
            "---> iteration:  240  partial loss: 0.07881591\n",
            "---> iteration:  241  partial loss: 0.03330902\n",
            "---> iteration:  242  partial loss: 0.1380807\n",
            "---> iteration:  243  partial loss: 0.14732756\n",
            "---> iteration:  244  partial loss: 0.07294062\n",
            "---> iteration:  245  partial loss: 0.037393015\n",
            "---> iteration:  246  partial loss: 0.10149748\n",
            "---> iteration:  247  partial loss: 0.09021544\n",
            "---> iteration:  248  partial loss: 0.1013918\n",
            "---> iteration:  249  partial loss: 0.054387115\n",
            "---> iteration:  250  partial loss: 0.028648859\n",
            "---> iteration:  251  partial loss: 0.09478546\n",
            "---> iteration:  252  partial loss: 0.054932166\n",
            "---> iteration:  253  partial loss: 0.058785174\n",
            "---> iteration:  254  partial loss: 0.12161727\n",
            "---> iteration:  255  partial loss: 0.12848327\n",
            "---> iteration:  256  partial loss: 0.0714064\n",
            "---> iteration:  257  partial loss: 0.046340857\n",
            "---> iteration:  258  partial loss: 0.033225276\n",
            "---> iteration:  259  partial loss: 0.062232748\n",
            "---> iteration:  260  partial loss: 0.043749742\n",
            "---> iteration:  261  partial loss: 0.09208401\n",
            "---> iteration:  262  partial loss: 0.060393922\n",
            "---> iteration:  263  partial loss: 0.07920667\n",
            "---> iteration:  264  partial loss: 0.07156337\n",
            "---> iteration:  265  partial loss: 0.07394405\n",
            "---> iteration:  266  partial loss: 0.06656611\n",
            "---> iteration:  267  partial loss: 0.054499052\n",
            "---> iteration:  268  partial loss: 0.12148161\n",
            "---> iteration:  269  partial loss: 0.22681291\n",
            "---> iteration:  270  partial loss: 0.13271496\n",
            "---> iteration:  271  partial loss: 0.10957616\n",
            "---> iteration:  272  partial loss: 0.03536787\n",
            "---> iteration:  273  partial loss: 0.08447975\n",
            "---> iteration:  274  partial loss: 0.06564907\n",
            "---> iteration:  275  partial loss: 0.048350975\n",
            "---> iteration:  276  partial loss: 0.07384848\n",
            "---> iteration:  277  partial loss: 0.13627714\n",
            "---> iteration:  278  partial loss: 0.06290355\n",
            "---> iteration:  279  partial loss: 0.055047575\n",
            "---> iteration:  280  partial loss: 0.049657106\n",
            "---> iteration:  281  partial loss: 0.055341285\n",
            "---> iteration:  282  partial loss: 0.04436497\n",
            "---> iteration:  283  partial loss: 0.035352312\n",
            "---> iteration:  284  partial loss: 0.03418659\n",
            "---> iteration:  285  partial loss: 0.065928176\n",
            "---> iteration:  286  partial loss: 0.037146762\n",
            "---> iteration:  287  partial loss: 0.06659393\n",
            "---> iteration:  288  partial loss: 0.03673057\n",
            "---> iteration:  289  partial loss: 0.061635997\n",
            "------------------\n",
            "epoch:  11  of  20 training loss:  0.07825098389753214\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.089207605\n",
            "---> iteration:  2  partial loss: 0.09347392\n",
            "---> iteration:  3  partial loss: 0.029665552\n",
            "---> iteration:  4  partial loss: 0.0650581\n",
            "---> iteration:  5  partial loss: 0.07002008\n",
            "---> iteration:  6  partial loss: 0.04875\n",
            "---> iteration:  7  partial loss: 0.108741686\n",
            "---> iteration:  8  partial loss: 0.039807692\n",
            "---> iteration:  9  partial loss: 0.033375047\n",
            "---> iteration:  10  partial loss: 0.01767249\n",
            "---> iteration:  11  partial loss: 0.07589619\n",
            "---> iteration:  12  partial loss: 0.036685947\n",
            "---> iteration:  13  partial loss: 0.033629138\n",
            "---> iteration:  14  partial loss: 0.19768625\n",
            "---> iteration:  15  partial loss: 0.030720374\n",
            "---> iteration:  16  partial loss: 0.13141558\n",
            "---> iteration:  17  partial loss: 0.05408251\n",
            "---> iteration:  18  partial loss: 0.057809003\n",
            "---> iteration:  19  partial loss: 0.1343837\n",
            "---> iteration:  20  partial loss: 0.06770824\n",
            "---> iteration:  21  partial loss: 0.09357036\n",
            "---> iteration:  22  partial loss: 0.03867379\n",
            "---> iteration:  23  partial loss: 0.083573274\n",
            "---> iteration:  24  partial loss: 0.09856555\n",
            "---> iteration:  25  partial loss: 0.044297278\n",
            "---> iteration:  26  partial loss: 0.0749036\n",
            "---> iteration:  27  partial loss: 0.066072695\n",
            "---> iteration:  28  partial loss: 0.079597995\n",
            "---> iteration:  29  partial loss: 0.10070112\n",
            "---> iteration:  30  partial loss: 0.054031745\n",
            "---> iteration:  31  partial loss: 0.110355906\n",
            "---> iteration:  32  partial loss: 0.078483135\n",
            "---> iteration:  33  partial loss: 0.053104814\n",
            "---> iteration:  34  partial loss: 0.04520672\n",
            "---> iteration:  35  partial loss: 0.071652755\n",
            "---> iteration:  36  partial loss: 0.029137613\n",
            "---> iteration:  37  partial loss: 0.09073781\n",
            "---> iteration:  38  partial loss: 0.11124693\n",
            "---> iteration:  39  partial loss: 0.06482859\n",
            "---> iteration:  40  partial loss: 0.054196157\n",
            "---> iteration:  41  partial loss: 0.03354103\n",
            "---> iteration:  42  partial loss: 0.026518427\n",
            "---> iteration:  43  partial loss: 0.0701841\n",
            "---> iteration:  44  partial loss: 0.049016275\n",
            "---> iteration:  45  partial loss: 0.048865605\n",
            "---> iteration:  46  partial loss: 0.06649046\n",
            "---> iteration:  47  partial loss: 0.09528489\n",
            "---> iteration:  48  partial loss: 0.03939355\n",
            "---> iteration:  49  partial loss: 0.023958476\n",
            "---> iteration:  50  partial loss: 0.110414185\n",
            "---> iteration:  51  partial loss: 0.060879335\n",
            "---> iteration:  52  partial loss: 0.1513589\n",
            "---> iteration:  53  partial loss: 0.07297202\n",
            "---> iteration:  54  partial loss: 0.061122768\n",
            "---> iteration:  55  partial loss: 0.087528706\n",
            "---> iteration:  56  partial loss: 0.046648692\n",
            "---> iteration:  57  partial loss: 0.07956848\n",
            "---> iteration:  58  partial loss: 0.057037026\n",
            "---> iteration:  59  partial loss: 0.07160139\n",
            "---> iteration:  60  partial loss: 0.053017393\n",
            "---> iteration:  61  partial loss: 0.12071253\n",
            "---> iteration:  62  partial loss: 0.03651842\n",
            "---> iteration:  63  partial loss: 0.08671635\n",
            "---> iteration:  64  partial loss: 0.04091107\n",
            "---> iteration:  65  partial loss: 0.039484475\n",
            "---> iteration:  66  partial loss: 0.059908953\n",
            "---> iteration:  67  partial loss: 0.0952815\n",
            "---> iteration:  68  partial loss: 0.073862255\n",
            "---> iteration:  69  partial loss: 0.08055653\n",
            "---> iteration:  70  partial loss: 0.07176508\n",
            "---> iteration:  71  partial loss: 0.033468828\n",
            "---> iteration:  72  partial loss: 0.055459633\n",
            "---> iteration:  73  partial loss: 0.025431713\n",
            "---> iteration:  74  partial loss: 0.025422128\n",
            "---> iteration:  75  partial loss: 0.05101494\n",
            "---> iteration:  76  partial loss: 0.034528565\n",
            "---> iteration:  77  partial loss: 0.041503523\n",
            "---> iteration:  78  partial loss: 0.03247995\n",
            "---> iteration:  79  partial loss: 0.037133195\n",
            "---> iteration:  80  partial loss: 0.055317827\n",
            "---> iteration:  81  partial loss: 0.0976298\n",
            "---> iteration:  82  partial loss: 0.034781285\n",
            "---> iteration:  83  partial loss: 0.10233082\n",
            "---> iteration:  84  partial loss: 0.08888403\n",
            "---> iteration:  85  partial loss: 0.07026343\n",
            "---> iteration:  86  partial loss: 0.040118925\n",
            "---> iteration:  87  partial loss: 0.049448185\n",
            "---> iteration:  88  partial loss: 0.056354005\n",
            "---> iteration:  89  partial loss: 0.099166274\n",
            "---> iteration:  90  partial loss: 0.035399653\n",
            "---> iteration:  91  partial loss: 0.08842563\n",
            "---> iteration:  92  partial loss: 0.04762035\n",
            "---> iteration:  93  partial loss: 0.088268526\n",
            "---> iteration:  94  partial loss: 0.06704071\n",
            "---> iteration:  95  partial loss: 0.08010413\n",
            "---> iteration:  96  partial loss: 0.07197917\n",
            "---> iteration:  97  partial loss: 0.20615879\n",
            "---> iteration:  98  partial loss: 0.06951931\n",
            "---> iteration:  99  partial loss: 0.11564674\n",
            "---> iteration:  100  partial loss: 0.03982908\n",
            "---> iteration:  101  partial loss: 0.06324238\n",
            "---> iteration:  102  partial loss: 0.05721452\n",
            "---> iteration:  103  partial loss: 0.062245242\n",
            "---> iteration:  104  partial loss: 0.032811947\n",
            "---> iteration:  105  partial loss: 0.075578585\n",
            "---> iteration:  106  partial loss: 0.044375293\n",
            "---> iteration:  107  partial loss: 0.04547934\n",
            "---> iteration:  108  partial loss: 0.1010185\n",
            "---> iteration:  109  partial loss: 0.100561395\n",
            "---> iteration:  110  partial loss: 0.05718892\n",
            "---> iteration:  111  partial loss: 0.07650892\n",
            "---> iteration:  112  partial loss: 0.032100387\n",
            "---> iteration:  113  partial loss: 0.050192416\n",
            "---> iteration:  114  partial loss: 0.030676698\n",
            "---> iteration:  115  partial loss: 0.020306539\n",
            "---> iteration:  116  partial loss: 0.07415844\n",
            "---> iteration:  117  partial loss: 0.05733127\n",
            "---> iteration:  118  partial loss: 0.035655163\n",
            "---> iteration:  119  partial loss: 0.08087402\n",
            "---> iteration:  120  partial loss: 0.040531814\n",
            "---> iteration:  121  partial loss: 0.039294366\n",
            "---> iteration:  122  partial loss: 0.05065582\n",
            "---> iteration:  123  partial loss: 0.09670707\n",
            "---> iteration:  124  partial loss: 0.066591404\n",
            "---> iteration:  125  partial loss: 0.04366328\n",
            "---> iteration:  126  partial loss: 0.022733383\n",
            "---> iteration:  127  partial loss: 0.04112618\n",
            "---> iteration:  128  partial loss: 0.07721953\n",
            "---> iteration:  129  partial loss: 0.07543159\n",
            "---> iteration:  130  partial loss: 0.0743928\n",
            "---> iteration:  131  partial loss: 0.058959298\n",
            "---> iteration:  132  partial loss: 0.051662456\n",
            "---> iteration:  133  partial loss: 0.123979524\n",
            "---> iteration:  134  partial loss: 0.03731726\n",
            "---> iteration:  135  partial loss: 0.028052613\n",
            "---> iteration:  136  partial loss: 0.09297392\n",
            "---> iteration:  137  partial loss: 0.054327216\n",
            "---> iteration:  138  partial loss: 0.07439132\n",
            "---> iteration:  139  partial loss: 0.053891987\n",
            "---> iteration:  140  partial loss: 0.06920288\n",
            "---> iteration:  141  partial loss: 0.06111666\n",
            "---> iteration:  142  partial loss: 0.075746745\n",
            "---> iteration:  143  partial loss: 0.05845957\n",
            "---> iteration:  144  partial loss: 0.024881426\n",
            "---> iteration:  145  partial loss: 0.030229855\n",
            "---> iteration:  146  partial loss: 0.06717015\n",
            "---> iteration:  147  partial loss: 0.05796951\n",
            "---> iteration:  148  partial loss: 0.04245176\n",
            "---> iteration:  149  partial loss: 0.043767612\n",
            "---> iteration:  150  partial loss: 0.15031296\n",
            "---> iteration:  151  partial loss: 0.05984315\n",
            "---> iteration:  152  partial loss: 0.04516753\n",
            "---> iteration:  153  partial loss: 0.032222547\n",
            "---> iteration:  154  partial loss: 0.08254111\n",
            "---> iteration:  155  partial loss: 0.060285416\n",
            "---> iteration:  156  partial loss: 0.13697109\n",
            "---> iteration:  157  partial loss: 0.07608433\n",
            "---> iteration:  158  partial loss: 0.028981993\n",
            "---> iteration:  159  partial loss: 0.08491099\n",
            "---> iteration:  160  partial loss: 0.066529594\n",
            "---> iteration:  161  partial loss: 0.042381734\n",
            "---> iteration:  162  partial loss: 0.06308628\n",
            "---> iteration:  163  partial loss: 0.070765674\n",
            "---> iteration:  164  partial loss: 0.07120517\n",
            "---> iteration:  165  partial loss: 0.02751214\n",
            "---> iteration:  166  partial loss: 0.047025647\n",
            "---> iteration:  167  partial loss: 0.029965363\n",
            "---> iteration:  168  partial loss: 0.12770104\n",
            "---> iteration:  169  partial loss: 0.095175914\n",
            "---> iteration:  170  partial loss: 0.09625871\n",
            "---> iteration:  171  partial loss: 0.09176926\n",
            "---> iteration:  172  partial loss: 0.0499117\n",
            "---> iteration:  173  partial loss: 0.08599071\n",
            "---> iteration:  174  partial loss: 0.08424642\n",
            "---> iteration:  175  partial loss: 0.105119\n",
            "---> iteration:  176  partial loss: 0.08320293\n",
            "---> iteration:  177  partial loss: 0.14320736\n",
            "---> iteration:  178  partial loss: 0.027385648\n",
            "---> iteration:  179  partial loss: 0.056296136\n",
            "---> iteration:  180  partial loss: 0.03746144\n",
            "---> iteration:  181  partial loss: 0.029799933\n",
            "---> iteration:  182  partial loss: 0.14637515\n",
            "---> iteration:  183  partial loss: 0.08919451\n",
            "---> iteration:  184  partial loss: 0.16452906\n",
            "---> iteration:  185  partial loss: 0.029641008\n",
            "---> iteration:  186  partial loss: 0.04124451\n",
            "---> iteration:  187  partial loss: 0.040230174\n",
            "---> iteration:  188  partial loss: 0.06290144\n",
            "---> iteration:  189  partial loss: 0.068618044\n",
            "---> iteration:  190  partial loss: 0.031566203\n",
            "---> iteration:  191  partial loss: 0.03536822\n",
            "---> iteration:  192  partial loss: 0.031623546\n",
            "---> iteration:  193  partial loss: 0.06713777\n",
            "---> iteration:  194  partial loss: 0.07091399\n",
            "---> iteration:  195  partial loss: 0.066407025\n",
            "---> iteration:  196  partial loss: 0.031007737\n",
            "---> iteration:  197  partial loss: 0.07886322\n",
            "---> iteration:  198  partial loss: 0.033498123\n",
            "---> iteration:  199  partial loss: 0.06146363\n",
            "---> iteration:  200  partial loss: 0.07734996\n",
            "---> iteration:  201  partial loss: 0.027753549\n",
            "---> iteration:  202  partial loss: 0.06520441\n",
            "---> iteration:  203  partial loss: 0.026291773\n",
            "---> iteration:  204  partial loss: 0.03012309\n",
            "---> iteration:  205  partial loss: 0.11316994\n",
            "---> iteration:  206  partial loss: 0.04647736\n",
            "---> iteration:  207  partial loss: 0.052923657\n",
            "---> iteration:  208  partial loss: 0.06609271\n",
            "---> iteration:  209  partial loss: 0.04960587\n",
            "---> iteration:  210  partial loss: 0.086501956\n",
            "---> iteration:  211  partial loss: 0.07164317\n",
            "---> iteration:  212  partial loss: 0.0506314\n",
            "---> iteration:  213  partial loss: 0.10901408\n",
            "---> iteration:  214  partial loss: 0.12180786\n",
            "---> iteration:  215  partial loss: 0.10023178\n",
            "---> iteration:  216  partial loss: 0.08281002\n",
            "---> iteration:  217  partial loss: 0.110972814\n",
            "---> iteration:  218  partial loss: 0.08421581\n",
            "---> iteration:  219  partial loss: 0.0717619\n",
            "---> iteration:  220  partial loss: 0.08627217\n",
            "---> iteration:  221  partial loss: 0.072437935\n",
            "---> iteration:  222  partial loss: 0.12278723\n",
            "---> iteration:  223  partial loss: 0.05686938\n",
            "---> iteration:  224  partial loss: 0.05478131\n",
            "---> iteration:  225  partial loss: 0.06731225\n",
            "---> iteration:  226  partial loss: 0.03361019\n",
            "---> iteration:  227  partial loss: 0.059381135\n",
            "---> iteration:  228  partial loss: 0.206605\n",
            "---> iteration:  229  partial loss: 0.06516576\n",
            "---> iteration:  230  partial loss: 0.11951444\n",
            "---> iteration:  231  partial loss: 0.05572481\n",
            "---> iteration:  232  partial loss: 0.06822079\n",
            "---> iteration:  233  partial loss: 0.039799687\n",
            "---> iteration:  234  partial loss: 0.041511595\n",
            "---> iteration:  235  partial loss: 0.087685\n",
            "---> iteration:  236  partial loss: 0.043930855\n",
            "---> iteration:  237  partial loss: 0.13064699\n",
            "---> iteration:  238  partial loss: 0.052104462\n",
            "---> iteration:  239  partial loss: 0.04979973\n",
            "---> iteration:  240  partial loss: 0.049970392\n",
            "---> iteration:  241  partial loss: 0.03125412\n",
            "---> iteration:  242  partial loss: 0.052267324\n",
            "---> iteration:  243  partial loss: 0.07036997\n",
            "---> iteration:  244  partial loss: 0.090949036\n",
            "---> iteration:  245  partial loss: 0.060334723\n",
            "---> iteration:  246  partial loss: 0.060146097\n",
            "---> iteration:  247  partial loss: 0.11079918\n",
            "---> iteration:  248  partial loss: 0.11080655\n",
            "---> iteration:  249  partial loss: 0.070544876\n",
            "---> iteration:  250  partial loss: 0.039527643\n",
            "---> iteration:  251  partial loss: 0.030333117\n",
            "---> iteration:  252  partial loss: 0.05886888\n",
            "---> iteration:  253  partial loss: 0.043476734\n",
            "---> iteration:  254  partial loss: 0.06833613\n",
            "---> iteration:  255  partial loss: 0.10829417\n",
            "---> iteration:  256  partial loss: 0.045531727\n",
            "---> iteration:  257  partial loss: 0.026360821\n",
            "---> iteration:  258  partial loss: 0.08644333\n",
            "---> iteration:  259  partial loss: 0.04215402\n",
            "---> iteration:  260  partial loss: 0.059063096\n",
            "---> iteration:  261  partial loss: 0.044795725\n",
            "---> iteration:  262  partial loss: 0.066575155\n",
            "---> iteration:  263  partial loss: 0.04248246\n",
            "---> iteration:  264  partial loss: 0.08782598\n",
            "---> iteration:  265  partial loss: 0.047279708\n",
            "---> iteration:  266  partial loss: 0.084334575\n",
            "---> iteration:  267  partial loss: 0.0829837\n",
            "---> iteration:  268  partial loss: 0.075548135\n",
            "---> iteration:  269  partial loss: 0.06583138\n",
            "---> iteration:  270  partial loss: 0.061333295\n",
            "---> iteration:  271  partial loss: 0.07675113\n",
            "---> iteration:  272  partial loss: 0.0423445\n",
            "---> iteration:  273  partial loss: 0.021950116\n",
            "---> iteration:  274  partial loss: 0.09253775\n",
            "---> iteration:  275  partial loss: 0.034540907\n",
            "---> iteration:  276  partial loss: 0.083459854\n",
            "---> iteration:  277  partial loss: 0.061466742\n",
            "---> iteration:  278  partial loss: 0.030206108\n",
            "---> iteration:  279  partial loss: 0.07741585\n",
            "---> iteration:  280  partial loss: 0.08026142\n",
            "---> iteration:  281  partial loss: 0.09547939\n",
            "---> iteration:  282  partial loss: 0.091922455\n",
            "---> iteration:  283  partial loss: 0.082287446\n",
            "---> iteration:  284  partial loss: 0.05499328\n",
            "---> iteration:  285  partial loss: 0.04334009\n",
            "---> iteration:  286  partial loss: 0.03852758\n",
            "---> iteration:  287  partial loss: 0.14858778\n",
            "---> iteration:  288  partial loss: 0.068802565\n",
            "---> iteration:  289  partial loss: 0.035191987\n",
            "------------------\n",
            "epoch:  12  of  20 training loss:  0.0667007923139111\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.06777345\n",
            "---> iteration:  2  partial loss: 0.061875857\n",
            "---> iteration:  3  partial loss: 0.12389243\n",
            "---> iteration:  4  partial loss: 0.10693633\n",
            "---> iteration:  5  partial loss: 0.026543643\n",
            "---> iteration:  6  partial loss: 0.052407287\n",
            "---> iteration:  7  partial loss: 0.04446809\n",
            "---> iteration:  8  partial loss: 0.057744555\n",
            "---> iteration:  9  partial loss: 0.064005375\n",
            "---> iteration:  10  partial loss: 0.07426023\n",
            "---> iteration:  11  partial loss: 0.040401474\n",
            "---> iteration:  12  partial loss: 0.08232112\n",
            "---> iteration:  13  partial loss: 0.06610709\n",
            "---> iteration:  14  partial loss: 0.09980953\n",
            "---> iteration:  15  partial loss: 0.046615705\n",
            "---> iteration:  16  partial loss: 0.03831092\n",
            "---> iteration:  17  partial loss: 0.053722367\n",
            "---> iteration:  18  partial loss: 0.06989744\n",
            "---> iteration:  19  partial loss: 0.083414376\n",
            "---> iteration:  20  partial loss: 0.0985067\n",
            "---> iteration:  21  partial loss: 0.023639297\n",
            "---> iteration:  22  partial loss: 0.030225197\n",
            "---> iteration:  23  partial loss: 0.05425143\n",
            "---> iteration:  24  partial loss: 0.0626301\n",
            "---> iteration:  25  partial loss: 0.03868885\n",
            "---> iteration:  26  partial loss: 0.053906135\n",
            "---> iteration:  27  partial loss: 0.0422007\n",
            "---> iteration:  28  partial loss: 0.06597355\n",
            "---> iteration:  29  partial loss: 0.02367888\n",
            "---> iteration:  30  partial loss: 0.07133767\n",
            "---> iteration:  31  partial loss: 0.047597658\n",
            "---> iteration:  32  partial loss: 0.080114916\n",
            "---> iteration:  33  partial loss: 0.06649341\n",
            "---> iteration:  34  partial loss: 0.07646965\n",
            "---> iteration:  35  partial loss: 0.06344294\n",
            "---> iteration:  36  partial loss: 0.017465025\n",
            "---> iteration:  37  partial loss: 0.0698012\n",
            "---> iteration:  38  partial loss: 0.07130253\n",
            "---> iteration:  39  partial loss: 0.078999646\n",
            "---> iteration:  40  partial loss: 0.067879215\n",
            "---> iteration:  41  partial loss: 0.08267581\n",
            "---> iteration:  42  partial loss: 0.058158483\n",
            "---> iteration:  43  partial loss: 0.05596586\n",
            "---> iteration:  44  partial loss: 0.046915043\n",
            "---> iteration:  45  partial loss: 0.07129938\n",
            "---> iteration:  46  partial loss: 0.037747283\n",
            "---> iteration:  47  partial loss: 0.04120651\n",
            "---> iteration:  48  partial loss: 0.05000625\n",
            "---> iteration:  49  partial loss: 0.049124274\n",
            "---> iteration:  50  partial loss: 0.016497856\n",
            "---> iteration:  51  partial loss: 0.05924428\n",
            "---> iteration:  52  partial loss: 0.049670134\n",
            "---> iteration:  53  partial loss: 0.06431812\n",
            "---> iteration:  54  partial loss: 0.078135625\n",
            "---> iteration:  55  partial loss: 0.035541184\n",
            "---> iteration:  56  partial loss: 0.053572603\n",
            "---> iteration:  57  partial loss: 0.061385993\n",
            "---> iteration:  58  partial loss: 0.024685632\n",
            "---> iteration:  59  partial loss: 0.042827465\n",
            "---> iteration:  60  partial loss: 0.05220166\n",
            "---> iteration:  61  partial loss: 0.0672976\n",
            "---> iteration:  62  partial loss: 0.12750353\n",
            "---> iteration:  63  partial loss: 0.058060467\n",
            "---> iteration:  64  partial loss: 0.09161457\n",
            "---> iteration:  65  partial loss: 0.089505516\n",
            "---> iteration:  66  partial loss: 0.041562784\n",
            "---> iteration:  67  partial loss: 0.027664995\n",
            "---> iteration:  68  partial loss: 0.04994513\n",
            "---> iteration:  69  partial loss: 0.05549913\n",
            "---> iteration:  70  partial loss: 0.08239013\n",
            "---> iteration:  71  partial loss: 0.02842411\n",
            "---> iteration:  72  partial loss: 0.07490393\n",
            "---> iteration:  73  partial loss: 0.079426154\n",
            "---> iteration:  74  partial loss: 0.047320217\n",
            "---> iteration:  75  partial loss: 0.03246489\n",
            "---> iteration:  76  partial loss: 0.037123613\n",
            "---> iteration:  77  partial loss: 0.117467284\n",
            "---> iteration:  78  partial loss: 0.024470838\n",
            "---> iteration:  79  partial loss: 0.03643624\n",
            "---> iteration:  80  partial loss: 0.09226697\n",
            "---> iteration:  81  partial loss: 0.064308286\n",
            "---> iteration:  82  partial loss: 0.07456887\n",
            "---> iteration:  83  partial loss: 0.058452014\n",
            "---> iteration:  84  partial loss: 0.09526912\n",
            "---> iteration:  85  partial loss: 0.049714692\n",
            "---> iteration:  86  partial loss: 0.032455917\n",
            "---> iteration:  87  partial loss: 0.08196558\n",
            "---> iteration:  88  partial loss: 0.09459139\n",
            "---> iteration:  89  partial loss: 0.055354007\n",
            "---> iteration:  90  partial loss: 0.048213407\n",
            "---> iteration:  91  partial loss: 0.068156324\n",
            "---> iteration:  92  partial loss: 0.032225884\n",
            "---> iteration:  93  partial loss: 0.03258871\n",
            "---> iteration:  94  partial loss: 0.10199708\n",
            "---> iteration:  95  partial loss: 0.0860123\n",
            "---> iteration:  96  partial loss: 0.08950999\n",
            "---> iteration:  97  partial loss: 0.10603722\n",
            "---> iteration:  98  partial loss: 0.121629305\n",
            "---> iteration:  99  partial loss: 0.030873012\n",
            "---> iteration:  100  partial loss: 0.081432424\n",
            "---> iteration:  101  partial loss: 0.12636404\n",
            "---> iteration:  102  partial loss: 0.09703776\n",
            "---> iteration:  103  partial loss: 0.026500162\n",
            "---> iteration:  104  partial loss: 0.08659149\n",
            "---> iteration:  105  partial loss: 0.16577987\n",
            "---> iteration:  106  partial loss: 0.042459317\n",
            "---> iteration:  107  partial loss: 0.071018875\n",
            "---> iteration:  108  partial loss: 0.052465364\n",
            "---> iteration:  109  partial loss: 0.032226067\n",
            "---> iteration:  110  partial loss: 0.07215064\n",
            "---> iteration:  111  partial loss: 0.029986747\n",
            "---> iteration:  112  partial loss: 0.070022255\n",
            "---> iteration:  113  partial loss: 0.054717127\n",
            "---> iteration:  114  partial loss: 0.029514058\n",
            "---> iteration:  115  partial loss: 0.12649204\n",
            "---> iteration:  116  partial loss: 0.07654862\n",
            "---> iteration:  117  partial loss: 0.048230533\n",
            "---> iteration:  118  partial loss: 0.09314358\n",
            "---> iteration:  119  partial loss: 0.05167038\n",
            "---> iteration:  120  partial loss: 0.08386516\n",
            "---> iteration:  121  partial loss: 0.031046692\n",
            "---> iteration:  122  partial loss: 0.1222494\n",
            "---> iteration:  123  partial loss: 0.060509723\n",
            "---> iteration:  124  partial loss: 0.042497855\n",
            "---> iteration:  125  partial loss: 0.045118168\n",
            "---> iteration:  126  partial loss: 0.053731106\n",
            "---> iteration:  127  partial loss: 0.041444957\n",
            "---> iteration:  128  partial loss: 0.034467556\n",
            "---> iteration:  129  partial loss: 0.080100164\n",
            "---> iteration:  130  partial loss: 0.032776516\n",
            "---> iteration:  131  partial loss: 0.11440204\n",
            "---> iteration:  132  partial loss: 0.03434976\n",
            "---> iteration:  133  partial loss: 0.020612659\n",
            "---> iteration:  134  partial loss: 0.034018394\n",
            "---> iteration:  135  partial loss: 0.10073941\n",
            "---> iteration:  136  partial loss: 0.05796102\n",
            "---> iteration:  137  partial loss: 0.12832038\n",
            "---> iteration:  138  partial loss: 0.090895645\n",
            "---> iteration:  139  partial loss: 0.025665198\n",
            "---> iteration:  140  partial loss: 0.038756587\n",
            "---> iteration:  141  partial loss: 0.05514346\n",
            "---> iteration:  142  partial loss: 0.06504638\n",
            "---> iteration:  143  partial loss: 0.038002513\n",
            "---> iteration:  144  partial loss: 0.32351667\n",
            "---> iteration:  145  partial loss: 0.08806285\n",
            "---> iteration:  146  partial loss: 0.12957674\n",
            "---> iteration:  147  partial loss: 0.075411364\n",
            "---> iteration:  148  partial loss: 0.100602634\n",
            "---> iteration:  149  partial loss: 0.07064012\n",
            "---> iteration:  150  partial loss: 0.11776798\n",
            "---> iteration:  151  partial loss: 0.043729287\n",
            "---> iteration:  152  partial loss: 0.066547096\n",
            "---> iteration:  153  partial loss: 0.065443926\n",
            "---> iteration:  154  partial loss: 0.11211815\n",
            "---> iteration:  155  partial loss: 0.059584722\n",
            "---> iteration:  156  partial loss: 0.02880916\n",
            "---> iteration:  157  partial loss: 0.03695799\n",
            "---> iteration:  158  partial loss: 0.10989471\n",
            "---> iteration:  159  partial loss: 0.03355276\n",
            "---> iteration:  160  partial loss: 0.028617514\n",
            "---> iteration:  161  partial loss: 0.15328956\n",
            "---> iteration:  162  partial loss: 0.07307752\n",
            "---> iteration:  163  partial loss: 0.057470497\n",
            "---> iteration:  164  partial loss: 0.027032414\n",
            "---> iteration:  165  partial loss: 0.035904367\n",
            "---> iteration:  166  partial loss: 0.09725478\n",
            "---> iteration:  167  partial loss: 0.1300617\n",
            "---> iteration:  168  partial loss: 0.0320343\n",
            "---> iteration:  169  partial loss: 0.040965352\n",
            "---> iteration:  170  partial loss: 0.07969901\n",
            "---> iteration:  171  partial loss: 0.056565333\n",
            "---> iteration:  172  partial loss: 0.055781927\n",
            "---> iteration:  173  partial loss: 0.0395171\n",
            "---> iteration:  174  partial loss: 0.05593832\n",
            "---> iteration:  175  partial loss: 0.11428557\n",
            "---> iteration:  176  partial loss: 0.034153678\n",
            "---> iteration:  177  partial loss: 0.07696781\n",
            "---> iteration:  178  partial loss: 0.04272739\n",
            "---> iteration:  179  partial loss: 0.07388217\n",
            "---> iteration:  180  partial loss: 0.031075573\n",
            "---> iteration:  181  partial loss: 0.051957842\n",
            "---> iteration:  182  partial loss: 0.07802549\n",
            "---> iteration:  183  partial loss: 0.13460188\n",
            "---> iteration:  184  partial loss: 0.06544833\n",
            "---> iteration:  185  partial loss: 0.0303431\n",
            "---> iteration:  186  partial loss: 0.03126118\n",
            "---> iteration:  187  partial loss: 0.03994767\n",
            "---> iteration:  188  partial loss: 0.050885126\n",
            "---> iteration:  189  partial loss: 0.29932708\n",
            "---> iteration:  190  partial loss: 0.052258864\n",
            "---> iteration:  191  partial loss: 0.07993064\n",
            "---> iteration:  192  partial loss: 0.23467831\n",
            "---> iteration:  193  partial loss: 0.048846204\n",
            "---> iteration:  194  partial loss: 0.094747044\n",
            "---> iteration:  195  partial loss: 0.070905805\n",
            "---> iteration:  196  partial loss: 0.09312697\n",
            "---> iteration:  197  partial loss: 0.04195565\n",
            "---> iteration:  198  partial loss: 0.11250371\n",
            "---> iteration:  199  partial loss: 0.07794818\n",
            "---> iteration:  200  partial loss: 0.037133317\n",
            "---> iteration:  201  partial loss: 0.111934856\n",
            "---> iteration:  202  partial loss: 0.10121162\n",
            "---> iteration:  203  partial loss: 0.12680595\n",
            "---> iteration:  204  partial loss: 0.08615995\n",
            "---> iteration:  205  partial loss: 0.14095274\n",
            "---> iteration:  206  partial loss: 0.045703873\n",
            "---> iteration:  207  partial loss: 0.1590217\n",
            "---> iteration:  208  partial loss: 0.053055573\n",
            "---> iteration:  209  partial loss: 0.08569888\n",
            "---> iteration:  210  partial loss: 0.062013805\n",
            "---> iteration:  211  partial loss: 0.09269446\n",
            "---> iteration:  212  partial loss: 0.14472264\n",
            "---> iteration:  213  partial loss: 0.039827533\n",
            "---> iteration:  214  partial loss: 0.13048027\n",
            "---> iteration:  215  partial loss: 0.03247566\n",
            "---> iteration:  216  partial loss: 0.03835843\n",
            "---> iteration:  217  partial loss: 0.08613472\n",
            "---> iteration:  218  partial loss: 0.056441233\n",
            "---> iteration:  219  partial loss: 0.17320739\n",
            "---> iteration:  220  partial loss: 0.07779875\n",
            "---> iteration:  221  partial loss: 0.04450053\n",
            "---> iteration:  222  partial loss: 0.050425433\n",
            "---> iteration:  223  partial loss: 0.03156643\n",
            "---> iteration:  224  partial loss: 0.026564797\n",
            "---> iteration:  225  partial loss: 0.08854944\n",
            "---> iteration:  226  partial loss: 0.10002395\n",
            "---> iteration:  227  partial loss: 0.093091816\n",
            "---> iteration:  228  partial loss: 0.06885784\n",
            "---> iteration:  229  partial loss: 0.07208079\n",
            "---> iteration:  230  partial loss: 0.035814308\n",
            "---> iteration:  231  partial loss: 0.062039077\n",
            "---> iteration:  232  partial loss: 0.046367995\n",
            "---> iteration:  233  partial loss: 0.21644944\n",
            "---> iteration:  234  partial loss: 0.11739508\n",
            "---> iteration:  235  partial loss: 0.09214074\n",
            "---> iteration:  236  partial loss: 0.029276662\n",
            "---> iteration:  237  partial loss: 0.10881557\n",
            "---> iteration:  238  partial loss: 0.050750706\n",
            "---> iteration:  239  partial loss: 0.050109364\n",
            "---> iteration:  240  partial loss: 0.030285364\n",
            "---> iteration:  241  partial loss: 0.07266152\n",
            "---> iteration:  242  partial loss: 0.049881656\n",
            "---> iteration:  243  partial loss: 0.050160836\n",
            "---> iteration:  244  partial loss: 0.08538873\n",
            "---> iteration:  245  partial loss: 0.06732608\n",
            "---> iteration:  246  partial loss: 0.03475934\n",
            "---> iteration:  247  partial loss: 0.06335859\n",
            "---> iteration:  248  partial loss: 0.06776609\n",
            "---> iteration:  249  partial loss: 0.07271815\n",
            "---> iteration:  250  partial loss: 0.039133105\n",
            "---> iteration:  251  partial loss: 0.092871584\n",
            "---> iteration:  252  partial loss: 0.06737247\n",
            "---> iteration:  253  partial loss: 0.026342373\n",
            "---> iteration:  254  partial loss: 0.055628527\n",
            "---> iteration:  255  partial loss: 0.06359677\n",
            "---> iteration:  256  partial loss: 0.037643798\n",
            "---> iteration:  257  partial loss: 0.048428662\n",
            "---> iteration:  258  partial loss: 0.15068793\n",
            "---> iteration:  259  partial loss: 0.04947129\n",
            "---> iteration:  260  partial loss: 0.049583346\n",
            "---> iteration:  261  partial loss: 0.031739485\n",
            "---> iteration:  262  partial loss: 0.08556653\n",
            "---> iteration:  263  partial loss: 0.037496816\n",
            "---> iteration:  264  partial loss: 0.04506022\n",
            "---> iteration:  265  partial loss: 0.035200242\n",
            "---> iteration:  266  partial loss: 0.027236652\n",
            "---> iteration:  267  partial loss: 0.05248306\n",
            "---> iteration:  268  partial loss: 0.08972738\n",
            "---> iteration:  269  partial loss: 0.06553267\n",
            "---> iteration:  270  partial loss: 0.07105649\n",
            "---> iteration:  271  partial loss: 0.040818814\n",
            "---> iteration:  272  partial loss: 0.050137762\n",
            "---> iteration:  273  partial loss: 0.07021202\n",
            "---> iteration:  274  partial loss: 0.23221193\n",
            "---> iteration:  275  partial loss: 0.03181711\n",
            "---> iteration:  276  partial loss: 0.052936204\n",
            "---> iteration:  277  partial loss: 0.028697824\n",
            "---> iteration:  278  partial loss: 0.07802818\n",
            "---> iteration:  279  partial loss: 0.020262111\n",
            "---> iteration:  280  partial loss: 0.100381106\n",
            "---> iteration:  281  partial loss: 0.08947929\n",
            "---> iteration:  282  partial loss: 0.028875628\n",
            "---> iteration:  283  partial loss: 0.031733338\n",
            "---> iteration:  284  partial loss: 0.035902645\n",
            "---> iteration:  285  partial loss: 0.049543522\n",
            "---> iteration:  286  partial loss: 0.08322522\n",
            "---> iteration:  287  partial loss: 0.061477758\n",
            "---> iteration:  288  partial loss: 0.045957692\n",
            "---> iteration:  289  partial loss: 0.09005599\n",
            "------------------\n",
            "epoch:  13  of  20 training loss:  0.06830250870139953\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.024961598\n",
            "---> iteration:  2  partial loss: 0.043557502\n",
            "---> iteration:  3  partial loss: 0.07707558\n",
            "---> iteration:  4  partial loss: 0.06163981\n",
            "---> iteration:  5  partial loss: 0.03438514\n",
            "---> iteration:  6  partial loss: 0.06760574\n",
            "---> iteration:  7  partial loss: 0.031219043\n",
            "---> iteration:  8  partial loss: 0.036488816\n",
            "---> iteration:  9  partial loss: 0.04737495\n",
            "---> iteration:  10  partial loss: 0.095948264\n",
            "---> iteration:  11  partial loss: 0.059898335\n",
            "---> iteration:  12  partial loss: 0.031433214\n",
            "---> iteration:  13  partial loss: 0.092178516\n",
            "---> iteration:  14  partial loss: 0.049029548\n",
            "---> iteration:  15  partial loss: 0.016392648\n",
            "---> iteration:  16  partial loss: 0.029926546\n",
            "---> iteration:  17  partial loss: 0.04683369\n",
            "---> iteration:  18  partial loss: 0.043151375\n",
            "---> iteration:  19  partial loss: 0.046662178\n",
            "---> iteration:  20  partial loss: 0.030216416\n",
            "---> iteration:  21  partial loss: 0.0356098\n",
            "---> iteration:  22  partial loss: 0.028932396\n",
            "---> iteration:  23  partial loss: 0.0330871\n",
            "---> iteration:  24  partial loss: 0.06804802\n",
            "---> iteration:  25  partial loss: 0.037671864\n",
            "---> iteration:  26  partial loss: 0.055095706\n",
            "---> iteration:  27  partial loss: 0.058116414\n",
            "---> iteration:  28  partial loss: 0.10992273\n",
            "---> iteration:  29  partial loss: 0.038278088\n",
            "---> iteration:  30  partial loss: 0.079190336\n",
            "---> iteration:  31  partial loss: 0.040472053\n",
            "---> iteration:  32  partial loss: 0.097071916\n",
            "---> iteration:  33  partial loss: 0.0759392\n",
            "---> iteration:  34  partial loss: 0.07501548\n",
            "---> iteration:  35  partial loss: 0.069565214\n",
            "---> iteration:  36  partial loss: 0.031169673\n",
            "---> iteration:  37  partial loss: 0.058628444\n",
            "---> iteration:  38  partial loss: 0.024261763\n",
            "---> iteration:  39  partial loss: 0.033074334\n",
            "---> iteration:  40  partial loss: 0.058154233\n",
            "---> iteration:  41  partial loss: 0.07622874\n",
            "---> iteration:  42  partial loss: 0.06383269\n",
            "---> iteration:  43  partial loss: 0.05163844\n",
            "---> iteration:  44  partial loss: 0.09525623\n",
            "---> iteration:  45  partial loss: 0.119964354\n",
            "---> iteration:  46  partial loss: 0.026119879\n",
            "---> iteration:  47  partial loss: 0.1427053\n",
            "---> iteration:  48  partial loss: 0.12112066\n",
            "---> iteration:  49  partial loss: 0.06603188\n",
            "---> iteration:  50  partial loss: 0.04637741\n",
            "---> iteration:  51  partial loss: 0.030461561\n",
            "---> iteration:  52  partial loss: 0.043534543\n",
            "---> iteration:  53  partial loss: 0.030772315\n",
            "---> iteration:  54  partial loss: 0.01941491\n",
            "---> iteration:  55  partial loss: 0.024892887\n",
            "---> iteration:  56  partial loss: 0.03776879\n",
            "---> iteration:  57  partial loss: 0.043808594\n",
            "---> iteration:  58  partial loss: 0.039558757\n",
            "---> iteration:  59  partial loss: 0.12351854\n",
            "---> iteration:  60  partial loss: 0.06607394\n",
            "---> iteration:  61  partial loss: 0.100694805\n",
            "---> iteration:  62  partial loss: 0.026473135\n",
            "---> iteration:  63  partial loss: 0.018803053\n",
            "---> iteration:  64  partial loss: 0.055871714\n",
            "---> iteration:  65  partial loss: 0.046587277\n",
            "---> iteration:  66  partial loss: 0.06817579\n",
            "---> iteration:  67  partial loss: 0.075485736\n",
            "---> iteration:  68  partial loss: 0.050043594\n",
            "---> iteration:  69  partial loss: 0.051164724\n",
            "---> iteration:  70  partial loss: 0.018903883\n",
            "---> iteration:  71  partial loss: 0.080142446\n",
            "---> iteration:  72  partial loss: 0.05628744\n",
            "---> iteration:  73  partial loss: 0.03373549\n",
            "---> iteration:  74  partial loss: 0.060144715\n",
            "---> iteration:  75  partial loss: 0.08482551\n",
            "---> iteration:  76  partial loss: 0.07444668\n",
            "---> iteration:  77  partial loss: 0.04354094\n",
            "---> iteration:  78  partial loss: 0.04754912\n",
            "---> iteration:  79  partial loss: 0.030819707\n",
            "---> iteration:  80  partial loss: 0.11189373\n",
            "---> iteration:  81  partial loss: 0.07589198\n",
            "---> iteration:  82  partial loss: 0.033894956\n",
            "---> iteration:  83  partial loss: 0.02846748\n",
            "---> iteration:  84  partial loss: 0.06556152\n",
            "---> iteration:  85  partial loss: 0.03956308\n",
            "---> iteration:  86  partial loss: 0.04630172\n",
            "---> iteration:  87  partial loss: 0.030152485\n",
            "---> iteration:  88  partial loss: 0.08260097\n",
            "---> iteration:  89  partial loss: 0.0262326\n",
            "---> iteration:  90  partial loss: 0.029728703\n",
            "---> iteration:  91  partial loss: 0.0698315\n",
            "---> iteration:  92  partial loss: 0.056295596\n",
            "---> iteration:  93  partial loss: 0.06499523\n",
            "---> iteration:  94  partial loss: 0.046459302\n",
            "---> iteration:  95  partial loss: 0.038931523\n",
            "---> iteration:  96  partial loss: 0.042922027\n",
            "---> iteration:  97  partial loss: 0.06724206\n",
            "---> iteration:  98  partial loss: 0.035133585\n",
            "---> iteration:  99  partial loss: 0.051067576\n",
            "---> iteration:  100  partial loss: 0.026707463\n",
            "---> iteration:  101  partial loss: 0.03328404\n",
            "---> iteration:  102  partial loss: 0.047192372\n",
            "---> iteration:  103  partial loss: 0.046228725\n",
            "---> iteration:  104  partial loss: 0.035569333\n",
            "---> iteration:  105  partial loss: 0.063315816\n",
            "---> iteration:  106  partial loss: 0.04611975\n",
            "---> iteration:  107  partial loss: 0.022910131\n",
            "---> iteration:  108  partial loss: 0.048310824\n",
            "---> iteration:  109  partial loss: 0.041371968\n",
            "---> iteration:  110  partial loss: 0.04088714\n",
            "---> iteration:  111  partial loss: 0.02385346\n",
            "---> iteration:  112  partial loss: 0.062414285\n",
            "---> iteration:  113  partial loss: 0.08784414\n",
            "---> iteration:  114  partial loss: 0.03001692\n",
            "---> iteration:  115  partial loss: 0.05667313\n",
            "---> iteration:  116  partial loss: 0.036948603\n",
            "---> iteration:  117  partial loss: 0.02757228\n",
            "---> iteration:  118  partial loss: 0.051056597\n",
            "---> iteration:  119  partial loss: 0.04249611\n",
            "---> iteration:  120  partial loss: 0.02155217\n",
            "---> iteration:  121  partial loss: 0.05755081\n",
            "---> iteration:  122  partial loss: 0.03431894\n",
            "---> iteration:  123  partial loss: 0.022004994\n",
            "---> iteration:  124  partial loss: 0.04624415\n",
            "---> iteration:  125  partial loss: 0.024173604\n",
            "---> iteration:  126  partial loss: 0.04314325\n",
            "---> iteration:  127  partial loss: 0.049188234\n",
            "---> iteration:  128  partial loss: 0.047530238\n",
            "---> iteration:  129  partial loss: 0.06512941\n",
            "---> iteration:  130  partial loss: 0.04398845\n",
            "---> iteration:  131  partial loss: 0.026726134\n",
            "---> iteration:  132  partial loss: 0.027905928\n",
            "---> iteration:  133  partial loss: 0.033842023\n",
            "---> iteration:  134  partial loss: 0.057399783\n",
            "---> iteration:  135  partial loss: 0.078057885\n",
            "---> iteration:  136  partial loss: 0.105182655\n",
            "---> iteration:  137  partial loss: 0.01966571\n",
            "---> iteration:  138  partial loss: 0.04890977\n",
            "---> iteration:  139  partial loss: 0.09067349\n",
            "---> iteration:  140  partial loss: 0.0709023\n",
            "---> iteration:  141  partial loss: 0.09146548\n",
            "---> iteration:  142  partial loss: 0.08090842\n",
            "---> iteration:  143  partial loss: 0.07557307\n",
            "---> iteration:  144  partial loss: 0.17100385\n",
            "---> iteration:  145  partial loss: 0.06748782\n",
            "---> iteration:  146  partial loss: 0.08173358\n",
            "---> iteration:  147  partial loss: 0.06950981\n",
            "---> iteration:  148  partial loss: 0.10922254\n",
            "---> iteration:  149  partial loss: 0.08377329\n",
            "---> iteration:  150  partial loss: 0.058367506\n",
            "---> iteration:  151  partial loss: 0.03071355\n",
            "---> iteration:  152  partial loss: 0.063103326\n",
            "---> iteration:  153  partial loss: 0.069417834\n",
            "---> iteration:  154  partial loss: 0.10662852\n",
            "---> iteration:  155  partial loss: 0.04972517\n",
            "---> iteration:  156  partial loss: 0.033199508\n",
            "---> iteration:  157  partial loss: 0.029466126\n",
            "---> iteration:  158  partial loss: 0.04550882\n",
            "---> iteration:  159  partial loss: 0.1927781\n",
            "---> iteration:  160  partial loss: 0.072539985\n",
            "---> iteration:  161  partial loss: 0.07210581\n",
            "---> iteration:  162  partial loss: 0.05332894\n",
            "---> iteration:  163  partial loss: 0.07199516\n",
            "---> iteration:  164  partial loss: 0.107509784\n",
            "---> iteration:  165  partial loss: 0.072416\n",
            "---> iteration:  166  partial loss: 0.058847938\n",
            "---> iteration:  167  partial loss: 0.064770624\n",
            "---> iteration:  168  partial loss: 0.05690946\n",
            "---> iteration:  169  partial loss: 0.108090594\n",
            "---> iteration:  170  partial loss: 0.093246944\n",
            "---> iteration:  171  partial loss: 0.02356651\n",
            "---> iteration:  172  partial loss: 0.08072595\n",
            "---> iteration:  173  partial loss: 0.06295229\n",
            "---> iteration:  174  partial loss: 0.18985452\n",
            "---> iteration:  175  partial loss: 0.037927054\n",
            "---> iteration:  176  partial loss: 0.04642566\n",
            "---> iteration:  177  partial loss: 0.10538317\n",
            "---> iteration:  178  partial loss: 0.05347032\n",
            "---> iteration:  179  partial loss: 0.118630216\n",
            "---> iteration:  180  partial loss: 0.12173782\n",
            "---> iteration:  181  partial loss: 0.076093554\n",
            "---> iteration:  182  partial loss: 0.036926817\n",
            "---> iteration:  183  partial loss: 0.07190714\n",
            "---> iteration:  184  partial loss: 0.08370536\n",
            "---> iteration:  185  partial loss: 0.052247282\n",
            "---> iteration:  186  partial loss: 0.03792548\n",
            "---> iteration:  187  partial loss: 0.044459607\n",
            "---> iteration:  188  partial loss: 0.110850036\n",
            "---> iteration:  189  partial loss: 0.09026118\n",
            "---> iteration:  190  partial loss: 0.03314418\n",
            "---> iteration:  191  partial loss: 0.04266046\n",
            "---> iteration:  192  partial loss: 0.09321261\n",
            "---> iteration:  193  partial loss: 0.059043482\n",
            "---> iteration:  194  partial loss: 0.071102895\n",
            "---> iteration:  195  partial loss: 0.037925247\n",
            "---> iteration:  196  partial loss: 0.20196326\n",
            "---> iteration:  197  partial loss: 0.07083692\n",
            "---> iteration:  198  partial loss: 0.02324995\n",
            "---> iteration:  199  partial loss: 0.058558065\n",
            "---> iteration:  200  partial loss: 0.051116027\n",
            "---> iteration:  201  partial loss: 0.21176285\n",
            "---> iteration:  202  partial loss: 0.29727265\n",
            "---> iteration:  203  partial loss: 0.035201345\n",
            "---> iteration:  204  partial loss: 0.054331884\n",
            "---> iteration:  205  partial loss: 0.052146796\n",
            "---> iteration:  206  partial loss: 0.06894582\n",
            "---> iteration:  207  partial loss: 0.15232572\n",
            "---> iteration:  208  partial loss: 0.11122505\n",
            "---> iteration:  209  partial loss: 0.3055565\n",
            "---> iteration:  210  partial loss: 0.07822815\n",
            "---> iteration:  211  partial loss: 0.04378776\n",
            "---> iteration:  212  partial loss: 0.041693307\n",
            "---> iteration:  213  partial loss: 0.096640185\n",
            "---> iteration:  214  partial loss: 0.108937465\n",
            "---> iteration:  215  partial loss: 0.07535492\n",
            "---> iteration:  216  partial loss: 0.04079958\n",
            "---> iteration:  217  partial loss: 0.03763339\n",
            "---> iteration:  218  partial loss: 0.05949955\n",
            "---> iteration:  219  partial loss: 0.08961103\n",
            "---> iteration:  220  partial loss: 0.06448452\n",
            "---> iteration:  221  partial loss: 0.32118317\n",
            "---> iteration:  222  partial loss: 0.090266734\n",
            "---> iteration:  223  partial loss: 0.1922865\n",
            "---> iteration:  224  partial loss: 0.07213227\n",
            "---> iteration:  225  partial loss: 0.14287739\n",
            "---> iteration:  226  partial loss: 0.3812089\n",
            "---> iteration:  227  partial loss: 0.06765212\n",
            "---> iteration:  228  partial loss: 0.081719436\n",
            "---> iteration:  229  partial loss: 0.04703563\n",
            "---> iteration:  230  partial loss: 0.12140272\n",
            "---> iteration:  231  partial loss: 0.049635738\n",
            "---> iteration:  232  partial loss: 0.15532605\n",
            "---> iteration:  233  partial loss: 0.12839769\n",
            "---> iteration:  234  partial loss: 0.11335618\n",
            "---> iteration:  235  partial loss: 0.03988615\n",
            "---> iteration:  236  partial loss: 0.08550935\n",
            "---> iteration:  237  partial loss: 0.09606247\n",
            "---> iteration:  238  partial loss: 0.118293285\n",
            "---> iteration:  239  partial loss: 0.12968384\n",
            "---> iteration:  240  partial loss: 0.03978585\n",
            "---> iteration:  241  partial loss: 0.04816168\n",
            "---> iteration:  242  partial loss: 0.16677971\n",
            "---> iteration:  243  partial loss: 0.037541058\n",
            "---> iteration:  244  partial loss: 0.067577615\n",
            "---> iteration:  245  partial loss: 0.076846756\n",
            "---> iteration:  246  partial loss: 0.04454083\n",
            "---> iteration:  247  partial loss: 0.12037786\n",
            "---> iteration:  248  partial loss: 0.0778573\n",
            "---> iteration:  249  partial loss: 0.06485517\n",
            "---> iteration:  250  partial loss: 0.07234968\n",
            "---> iteration:  251  partial loss: 0.072286725\n",
            "---> iteration:  252  partial loss: 0.056708194\n",
            "---> iteration:  253  partial loss: 0.061175443\n",
            "---> iteration:  254  partial loss: 0.05734757\n",
            "---> iteration:  255  partial loss: 0.123524256\n",
            "---> iteration:  256  partial loss: 0.11262991\n",
            "---> iteration:  257  partial loss: 0.0325646\n",
            "---> iteration:  258  partial loss: 0.17004053\n",
            "---> iteration:  259  partial loss: 0.09394525\n",
            "---> iteration:  260  partial loss: 0.024126625\n",
            "---> iteration:  261  partial loss: 0.07291593\n",
            "---> iteration:  262  partial loss: 0.09162632\n",
            "---> iteration:  263  partial loss: 0.105222836\n",
            "---> iteration:  264  partial loss: 0.03574288\n",
            "---> iteration:  265  partial loss: 0.044987414\n",
            "---> iteration:  266  partial loss: 0.04046388\n",
            "---> iteration:  267  partial loss: 0.072997876\n",
            "---> iteration:  268  partial loss: 0.08589735\n",
            "---> iteration:  269  partial loss: 0.045857985\n",
            "---> iteration:  270  partial loss: 0.026533158\n",
            "---> iteration:  271  partial loss: 0.07256556\n",
            "---> iteration:  272  partial loss: 0.14134632\n",
            "---> iteration:  273  partial loss: 0.20814379\n",
            "---> iteration:  274  partial loss: 0.064689055\n",
            "---> iteration:  275  partial loss: 0.045491472\n",
            "---> iteration:  276  partial loss: 0.11723508\n",
            "---> iteration:  277  partial loss: 0.07870262\n",
            "---> iteration:  278  partial loss: 0.04858062\n",
            "---> iteration:  279  partial loss: 0.05250775\n",
            "---> iteration:  280  partial loss: 0.075182416\n",
            "---> iteration:  281  partial loss: 0.022155218\n",
            "---> iteration:  282  partial loss: 0.03892985\n",
            "---> iteration:  283  partial loss: 0.060744975\n",
            "---> iteration:  284  partial loss: 0.13400218\n",
            "---> iteration:  285  partial loss: 0.07106468\n",
            "---> iteration:  286  partial loss: 0.057173476\n",
            "---> iteration:  287  partial loss: 0.139665\n",
            "---> iteration:  288  partial loss: 0.037537113\n",
            "---> iteration:  289  partial loss: 0.09762945\n",
            "------------------\n",
            "epoch:  14  of  20 training loss:  0.069513045322266\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.0765685\n",
            "---> iteration:  2  partial loss: 0.05495455\n",
            "---> iteration:  3  partial loss: 0.08740459\n",
            "---> iteration:  4  partial loss: 0.060932256\n",
            "---> iteration:  5  partial loss: 0.034551535\n",
            "---> iteration:  6  partial loss: 0.057962112\n",
            "---> iteration:  7  partial loss: 0.040963415\n",
            "---> iteration:  8  partial loss: 0.05268501\n",
            "---> iteration:  9  partial loss: 0.15084757\n",
            "---> iteration:  10  partial loss: 0.03643997\n",
            "---> iteration:  11  partial loss: 0.11379392\n",
            "---> iteration:  12  partial loss: 0.04366543\n",
            "---> iteration:  13  partial loss: 0.075035125\n",
            "---> iteration:  14  partial loss: 0.09082472\n",
            "---> iteration:  15  partial loss: 0.062353726\n",
            "---> iteration:  16  partial loss: 0.04529972\n",
            "---> iteration:  17  partial loss: 0.029765043\n",
            "---> iteration:  18  partial loss: 0.056756973\n",
            "---> iteration:  19  partial loss: 0.06551492\n",
            "---> iteration:  20  partial loss: 0.046092108\n",
            "---> iteration:  21  partial loss: 0.038844723\n",
            "---> iteration:  22  partial loss: 0.093299836\n",
            "---> iteration:  23  partial loss: 0.027631853\n",
            "---> iteration:  24  partial loss: 0.07067258\n",
            "---> iteration:  25  partial loss: 0.08853651\n",
            "---> iteration:  26  partial loss: 0.039694384\n",
            "---> iteration:  27  partial loss: 0.03651091\n",
            "---> iteration:  28  partial loss: 0.11350818\n",
            "---> iteration:  29  partial loss: 0.14900443\n",
            "---> iteration:  30  partial loss: 0.04753443\n",
            "---> iteration:  31  partial loss: 0.037359096\n",
            "---> iteration:  32  partial loss: 0.08469216\n",
            "---> iteration:  33  partial loss: 0.031537257\n",
            "---> iteration:  34  partial loss: 0.06188468\n",
            "---> iteration:  35  partial loss: 0.054528955\n",
            "---> iteration:  36  partial loss: 0.051539995\n",
            "---> iteration:  37  partial loss: 0.08383314\n",
            "---> iteration:  38  partial loss: 0.023222843\n",
            "---> iteration:  39  partial loss: 0.04019308\n",
            "---> iteration:  40  partial loss: 0.030550225\n",
            "---> iteration:  41  partial loss: 0.07939771\n",
            "---> iteration:  42  partial loss: 0.03536085\n",
            "---> iteration:  43  partial loss: 0.08899156\n",
            "---> iteration:  44  partial loss: 0.02812651\n",
            "---> iteration:  45  partial loss: 0.086608164\n",
            "---> iteration:  46  partial loss: 0.020262089\n",
            "---> iteration:  47  partial loss: 0.039399866\n",
            "---> iteration:  48  partial loss: 0.06989695\n",
            "---> iteration:  49  partial loss: 0.08822097\n",
            "---> iteration:  50  partial loss: 0.04092301\n",
            "---> iteration:  51  partial loss: 0.029078504\n",
            "---> iteration:  52  partial loss: 0.036480155\n",
            "---> iteration:  53  partial loss: 0.030247787\n",
            "---> iteration:  54  partial loss: 0.11131884\n",
            "---> iteration:  55  partial loss: 0.03953674\n",
            "---> iteration:  56  partial loss: 0.07962369\n",
            "---> iteration:  57  partial loss: 0.02421251\n",
            "---> iteration:  58  partial loss: 0.06420307\n",
            "---> iteration:  59  partial loss: 0.05575641\n",
            "---> iteration:  60  partial loss: 0.051940005\n",
            "---> iteration:  61  partial loss: 0.05027134\n",
            "---> iteration:  62  partial loss: 0.03486101\n",
            "---> iteration:  63  partial loss: 0.020225218\n",
            "---> iteration:  64  partial loss: 0.10392535\n",
            "---> iteration:  65  partial loss: 0.103808954\n",
            "---> iteration:  66  partial loss: 0.045244742\n",
            "---> iteration:  67  partial loss: 0.07439831\n",
            "---> iteration:  68  partial loss: 0.05866108\n",
            "---> iteration:  69  partial loss: 0.03347743\n",
            "---> iteration:  70  partial loss: 0.14592904\n",
            "---> iteration:  71  partial loss: 0.041023433\n",
            "---> iteration:  72  partial loss: 0.045339245\n",
            "---> iteration:  73  partial loss: 0.028719213\n",
            "---> iteration:  74  partial loss: 0.047215566\n",
            "---> iteration:  75  partial loss: 0.044280175\n",
            "---> iteration:  76  partial loss: 0.02903105\n",
            "---> iteration:  77  partial loss: 0.06466613\n",
            "---> iteration:  78  partial loss: 0.017061634\n",
            "---> iteration:  79  partial loss: 0.06866363\n",
            "---> iteration:  80  partial loss: 0.06526064\n",
            "---> iteration:  81  partial loss: 0.038943637\n",
            "---> iteration:  82  partial loss: 0.047352012\n",
            "---> iteration:  83  partial loss: 0.05616642\n",
            "---> iteration:  84  partial loss: 0.07147616\n",
            "---> iteration:  85  partial loss: 0.047685776\n",
            "---> iteration:  86  partial loss: 0.023363303\n",
            "---> iteration:  87  partial loss: 0.026115926\n",
            "---> iteration:  88  partial loss: 0.07427376\n",
            "---> iteration:  89  partial loss: 0.06753427\n",
            "---> iteration:  90  partial loss: 0.065369435\n",
            "---> iteration:  91  partial loss: 0.031190967\n",
            "---> iteration:  92  partial loss: 0.028141767\n",
            "---> iteration:  93  partial loss: 0.08663325\n",
            "---> iteration:  94  partial loss: 0.024670672\n",
            "---> iteration:  95  partial loss: 0.024715072\n",
            "---> iteration:  96  partial loss: 0.04939541\n",
            "---> iteration:  97  partial loss: 0.02705603\n",
            "---> iteration:  98  partial loss: 0.052763913\n",
            "---> iteration:  99  partial loss: 0.06106278\n",
            "---> iteration:  100  partial loss: 0.10794378\n",
            "---> iteration:  101  partial loss: 0.10468129\n",
            "---> iteration:  102  partial loss: 0.058135837\n",
            "---> iteration:  103  partial loss: 0.06258619\n",
            "---> iteration:  104  partial loss: 0.16798922\n",
            "---> iteration:  105  partial loss: 0.08232111\n",
            "---> iteration:  106  partial loss: 0.12594704\n",
            "---> iteration:  107  partial loss: 0.0612996\n",
            "---> iteration:  108  partial loss: 0.04673347\n",
            "---> iteration:  109  partial loss: 0.063001156\n",
            "---> iteration:  110  partial loss: 0.074258685\n",
            "---> iteration:  111  partial loss: 0.033454433\n",
            "---> iteration:  112  partial loss: 0.064999424\n",
            "---> iteration:  113  partial loss: 0.06719764\n",
            "---> iteration:  114  partial loss: 0.051920336\n",
            "---> iteration:  115  partial loss: 0.026615651\n",
            "---> iteration:  116  partial loss: 0.06737365\n",
            "---> iteration:  117  partial loss: 0.06669687\n",
            "---> iteration:  118  partial loss: 0.051006295\n",
            "---> iteration:  119  partial loss: 0.033760104\n",
            "---> iteration:  120  partial loss: 0.07290547\n",
            "---> iteration:  121  partial loss: 0.12973483\n",
            "---> iteration:  122  partial loss: 0.032428097\n",
            "---> iteration:  123  partial loss: 0.085569836\n",
            "---> iteration:  124  partial loss: 0.043581024\n",
            "---> iteration:  125  partial loss: 0.05979387\n",
            "---> iteration:  126  partial loss: 0.089349166\n",
            "---> iteration:  127  partial loss: 0.0543156\n",
            "---> iteration:  128  partial loss: 0.054587327\n",
            "---> iteration:  129  partial loss: 0.0798393\n",
            "---> iteration:  130  partial loss: 0.0508139\n",
            "---> iteration:  131  partial loss: 0.07375519\n",
            "---> iteration:  132  partial loss: 0.060159683\n",
            "---> iteration:  133  partial loss: 0.083966024\n",
            "---> iteration:  134  partial loss: 0.07145885\n",
            "---> iteration:  135  partial loss: 0.04055051\n",
            "---> iteration:  136  partial loss: 0.06308639\n",
            "---> iteration:  137  partial loss: 0.051801607\n",
            "---> iteration:  138  partial loss: 0.05265439\n",
            "---> iteration:  139  partial loss: 0.038565785\n",
            "---> iteration:  140  partial loss: 0.11068331\n",
            "---> iteration:  141  partial loss: 0.059609253\n",
            "---> iteration:  142  partial loss: 0.1570438\n",
            "---> iteration:  143  partial loss: 0.04100493\n",
            "---> iteration:  144  partial loss: 0.057975855\n",
            "---> iteration:  145  partial loss: 0.0522567\n",
            "---> iteration:  146  partial loss: 0.05641934\n",
            "---> iteration:  147  partial loss: 0.077989906\n",
            "---> iteration:  148  partial loss: 0.017708471\n",
            "---> iteration:  149  partial loss: 0.05819685\n",
            "---> iteration:  150  partial loss: 0.027137116\n",
            "---> iteration:  151  partial loss: 0.07604493\n",
            "---> iteration:  152  partial loss: 0.10214799\n",
            "---> iteration:  153  partial loss: 0.036242966\n",
            "---> iteration:  154  partial loss: 0.026605118\n",
            "---> iteration:  155  partial loss: 0.11413235\n",
            "---> iteration:  156  partial loss: 0.046635814\n",
            "---> iteration:  157  partial loss: 0.08735468\n",
            "---> iteration:  158  partial loss: 0.061743673\n",
            "---> iteration:  159  partial loss: 0.051748604\n",
            "---> iteration:  160  partial loss: 0.09749569\n",
            "---> iteration:  161  partial loss: 0.041956846\n",
            "---> iteration:  162  partial loss: 0.0688462\n",
            "---> iteration:  163  partial loss: 0.030945871\n",
            "---> iteration:  164  partial loss: 0.03578192\n",
            "---> iteration:  165  partial loss: 0.04680216\n",
            "---> iteration:  166  partial loss: 0.058488026\n",
            "---> iteration:  167  partial loss: 0.063865334\n",
            "---> iteration:  168  partial loss: 0.10391898\n",
            "---> iteration:  169  partial loss: 0.038204316\n",
            "---> iteration:  170  partial loss: 0.030307028\n",
            "---> iteration:  171  partial loss: 0.026413804\n",
            "---> iteration:  172  partial loss: 0.05987019\n",
            "---> iteration:  173  partial loss: 0.0792536\n",
            "---> iteration:  174  partial loss: 0.041715242\n",
            "---> iteration:  175  partial loss: 0.06567114\n",
            "---> iteration:  176  partial loss: 0.04374463\n",
            "---> iteration:  177  partial loss: 0.122427054\n",
            "---> iteration:  178  partial loss: 0.053902175\n",
            "---> iteration:  179  partial loss: 0.028041007\n",
            "---> iteration:  180  partial loss: 0.07784495\n",
            "---> iteration:  181  partial loss: 0.057849385\n",
            "---> iteration:  182  partial loss: 0.038336664\n",
            "---> iteration:  183  partial loss: 0.0655564\n",
            "---> iteration:  184  partial loss: 0.06933513\n",
            "---> iteration:  185  partial loss: 0.02259986\n",
            "---> iteration:  186  partial loss: 0.0649535\n",
            "---> iteration:  187  partial loss: 0.045224402\n",
            "---> iteration:  188  partial loss: 0.06788398\n",
            "---> iteration:  189  partial loss: 0.041361805\n",
            "---> iteration:  190  partial loss: 0.08807409\n",
            "---> iteration:  191  partial loss: 0.11093368\n",
            "---> iteration:  192  partial loss: 0.020146778\n",
            "---> iteration:  193  partial loss: 0.054992158\n",
            "---> iteration:  194  partial loss: 0.041671555\n",
            "---> iteration:  195  partial loss: 0.054346446\n",
            "---> iteration:  196  partial loss: 0.059802696\n",
            "---> iteration:  197  partial loss: 0.02472405\n",
            "---> iteration:  198  partial loss: 0.1015834\n",
            "---> iteration:  199  partial loss: 0.025804421\n",
            "---> iteration:  200  partial loss: 0.020771286\n",
            "---> iteration:  201  partial loss: 0.030311834\n",
            "---> iteration:  202  partial loss: 0.022494694\n",
            "---> iteration:  203  partial loss: 0.03499218\n",
            "---> iteration:  204  partial loss: 0.026644187\n",
            "---> iteration:  205  partial loss: 0.029421639\n",
            "---> iteration:  206  partial loss: 0.015611331\n",
            "---> iteration:  207  partial loss: 0.08765704\n",
            "---> iteration:  208  partial loss: 0.064331934\n",
            "---> iteration:  209  partial loss: 0.052258663\n",
            "---> iteration:  210  partial loss: 0.05099982\n",
            "---> iteration:  211  partial loss: 0.034716766\n",
            "---> iteration:  212  partial loss: 0.022141147\n",
            "---> iteration:  213  partial loss: 0.047305085\n",
            "---> iteration:  214  partial loss: 0.05350265\n",
            "---> iteration:  215  partial loss: 0.059038956\n",
            "---> iteration:  216  partial loss: 0.041313067\n",
            "---> iteration:  217  partial loss: 0.04576468\n",
            "---> iteration:  218  partial loss: 0.020708527\n",
            "---> iteration:  219  partial loss: 0.07698599\n",
            "---> iteration:  220  partial loss: 0.0733897\n",
            "---> iteration:  221  partial loss: 0.07405974\n",
            "---> iteration:  222  partial loss: 0.04140161\n",
            "---> iteration:  223  partial loss: 0.02723994\n",
            "---> iteration:  224  partial loss: 0.02799769\n",
            "---> iteration:  225  partial loss: 0.044956066\n",
            "---> iteration:  226  partial loss: 0.054738384\n",
            "---> iteration:  227  partial loss: 0.05802946\n",
            "---> iteration:  228  partial loss: 0.04442966\n",
            "---> iteration:  229  partial loss: 0.023824368\n",
            "---> iteration:  230  partial loss: 0.05031276\n",
            "---> iteration:  231  partial loss: 0.057231463\n",
            "---> iteration:  232  partial loss: 0.10169263\n",
            "---> iteration:  233  partial loss: 0.08137965\n",
            "---> iteration:  234  partial loss: 0.04111815\n",
            "---> iteration:  235  partial loss: 0.06607281\n",
            "---> iteration:  236  partial loss: 0.050333086\n",
            "---> iteration:  237  partial loss: 0.07244168\n",
            "---> iteration:  238  partial loss: 0.07111947\n",
            "---> iteration:  239  partial loss: 0.030194532\n",
            "---> iteration:  240  partial loss: 0.057120245\n",
            "---> iteration:  241  partial loss: 0.05950078\n",
            "---> iteration:  242  partial loss: 0.08503498\n",
            "---> iteration:  243  partial loss: 0.053505912\n",
            "---> iteration:  244  partial loss: 0.07643187\n",
            "---> iteration:  245  partial loss: 0.052925866\n",
            "---> iteration:  246  partial loss: 0.042994477\n",
            "---> iteration:  247  partial loss: 0.026896583\n",
            "---> iteration:  248  partial loss: 0.061221823\n",
            "---> iteration:  249  partial loss: 0.03587535\n",
            "---> iteration:  250  partial loss: 0.073169515\n",
            "---> iteration:  251  partial loss: 0.0991937\n",
            "---> iteration:  252  partial loss: 0.0350407\n",
            "---> iteration:  253  partial loss: 0.06454583\n",
            "---> iteration:  254  partial loss: 0.051407397\n",
            "---> iteration:  255  partial loss: 0.16494958\n",
            "---> iteration:  256  partial loss: 0.04261455\n",
            "---> iteration:  257  partial loss: 0.03022461\n",
            "---> iteration:  258  partial loss: 0.069959626\n",
            "---> iteration:  259  partial loss: 0.033697482\n",
            "---> iteration:  260  partial loss: 0.030221669\n",
            "---> iteration:  261  partial loss: 0.11058714\n",
            "---> iteration:  262  partial loss: 0.05669206\n",
            "---> iteration:  263  partial loss: 0.08191332\n",
            "---> iteration:  264  partial loss: 0.05189213\n",
            "---> iteration:  265  partial loss: 0.02479609\n",
            "---> iteration:  266  partial loss: 0.13639691\n",
            "---> iteration:  267  partial loss: 0.062295415\n",
            "---> iteration:  268  partial loss: 0.043472406\n",
            "---> iteration:  269  partial loss: 0.06072519\n",
            "---> iteration:  270  partial loss: 0.037884194\n",
            "---> iteration:  271  partial loss: 0.028337918\n",
            "---> iteration:  272  partial loss: 0.036044896\n",
            "---> iteration:  273  partial loss: 0.026463062\n",
            "---> iteration:  274  partial loss: 0.07483849\n",
            "---> iteration:  275  partial loss: 0.023040999\n",
            "---> iteration:  276  partial loss: 0.044081107\n",
            "---> iteration:  277  partial loss: 0.05080311\n",
            "---> iteration:  278  partial loss: 0.19215444\n",
            "---> iteration:  279  partial loss: 0.07033724\n",
            "---> iteration:  280  partial loss: 0.08160293\n",
            "---> iteration:  281  partial loss: 0.098520175\n",
            "---> iteration:  282  partial loss: 0.04529048\n",
            "---> iteration:  283  partial loss: 0.027278824\n",
            "---> iteration:  284  partial loss: 0.06408729\n",
            "---> iteration:  285  partial loss: 0.09400764\n",
            "---> iteration:  286  partial loss: 0.08991803\n",
            "---> iteration:  287  partial loss: 0.057696722\n",
            "---> iteration:  288  partial loss: 0.04407639\n",
            "---> iteration:  289  partial loss: 0.062625416\n",
            "------------------\n",
            "epoch:  15  of  20 training loss:  0.058692295287951675\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.035614293\n",
            "---> iteration:  2  partial loss: 0.017602833\n",
            "---> iteration:  3  partial loss: 0.020180011\n",
            "---> iteration:  4  partial loss: 0.04299102\n",
            "---> iteration:  5  partial loss: 0.10251015\n",
            "---> iteration:  6  partial loss: 0.061926957\n",
            "---> iteration:  7  partial loss: 0.08670662\n",
            "---> iteration:  8  partial loss: 0.039236605\n",
            "---> iteration:  9  partial loss: 0.06427243\n",
            "---> iteration:  10  partial loss: 0.040940363\n",
            "---> iteration:  11  partial loss: 0.031084796\n",
            "---> iteration:  12  partial loss: 0.03599123\n",
            "---> iteration:  13  partial loss: 0.08869606\n",
            "---> iteration:  14  partial loss: 0.027822161\n",
            "---> iteration:  15  partial loss: 0.04143173\n",
            "---> iteration:  16  partial loss: 0.06407165\n",
            "---> iteration:  17  partial loss: 0.046858616\n",
            "---> iteration:  18  partial loss: 0.05885341\n",
            "---> iteration:  19  partial loss: 0.045880202\n",
            "---> iteration:  20  partial loss: 0.020832637\n",
            "---> iteration:  21  partial loss: 0.021075226\n",
            "---> iteration:  22  partial loss: 0.11192234\n",
            "---> iteration:  23  partial loss: 0.039693046\n",
            "---> iteration:  24  partial loss: 0.028895998\n",
            "---> iteration:  25  partial loss: 0.119961806\n",
            "---> iteration:  26  partial loss: 0.02861908\n",
            "---> iteration:  27  partial loss: 0.048038594\n",
            "---> iteration:  28  partial loss: 0.05135106\n",
            "---> iteration:  29  partial loss: 0.060386784\n",
            "---> iteration:  30  partial loss: 0.09213365\n",
            "---> iteration:  31  partial loss: 0.026421972\n",
            "---> iteration:  32  partial loss: 0.09979284\n",
            "---> iteration:  33  partial loss: 0.0378001\n",
            "---> iteration:  34  partial loss: 0.047455005\n",
            "---> iteration:  35  partial loss: 0.021029986\n",
            "---> iteration:  36  partial loss: 0.07702992\n",
            "---> iteration:  37  partial loss: 0.060451232\n",
            "---> iteration:  38  partial loss: 0.033929307\n",
            "---> iteration:  39  partial loss: 0.0773096\n",
            "---> iteration:  40  partial loss: 0.026913177\n",
            "---> iteration:  41  partial loss: 0.0648045\n",
            "---> iteration:  42  partial loss: 0.05235646\n",
            "---> iteration:  43  partial loss: 0.05719693\n",
            "---> iteration:  44  partial loss: 0.020741416\n",
            "---> iteration:  45  partial loss: 0.05344318\n",
            "---> iteration:  46  partial loss: 0.0509838\n",
            "---> iteration:  47  partial loss: 0.045497477\n",
            "---> iteration:  48  partial loss: 0.029143862\n",
            "---> iteration:  49  partial loss: 0.03601727\n",
            "---> iteration:  50  partial loss: 0.028162435\n",
            "---> iteration:  51  partial loss: 0.020854063\n",
            "---> iteration:  52  partial loss: 0.027016396\n",
            "---> iteration:  53  partial loss: 0.06816681\n",
            "---> iteration:  54  partial loss: 0.05350272\n",
            "---> iteration:  55  partial loss: 0.03988686\n",
            "---> iteration:  56  partial loss: 0.043203156\n",
            "---> iteration:  57  partial loss: 0.05611851\n",
            "---> iteration:  58  partial loss: 0.029332263\n",
            "---> iteration:  59  partial loss: 0.029273028\n",
            "---> iteration:  60  partial loss: 0.036598556\n",
            "---> iteration:  61  partial loss: 0.0399288\n",
            "---> iteration:  62  partial loss: 0.050372906\n",
            "---> iteration:  63  partial loss: 0.022311943\n",
            "---> iteration:  64  partial loss: 0.060038842\n",
            "---> iteration:  65  partial loss: 0.056829173\n",
            "---> iteration:  66  partial loss: 0.02877237\n",
            "---> iteration:  67  partial loss: 0.060730185\n",
            "---> iteration:  68  partial loss: 0.08932349\n",
            "---> iteration:  69  partial loss: 0.014622783\n",
            "---> iteration:  70  partial loss: 0.044784002\n",
            "---> iteration:  71  partial loss: 0.10689558\n",
            "---> iteration:  72  partial loss: 0.044068094\n",
            "---> iteration:  73  partial loss: 0.06922091\n",
            "---> iteration:  74  partial loss: 0.04044213\n",
            "---> iteration:  75  partial loss: 0.04356993\n",
            "---> iteration:  76  partial loss: 0.085466765\n",
            "---> iteration:  77  partial loss: 0.06626587\n",
            "---> iteration:  78  partial loss: 0.04340231\n",
            "---> iteration:  79  partial loss: 0.06759607\n",
            "---> iteration:  80  partial loss: 0.01892827\n",
            "---> iteration:  81  partial loss: 0.088827804\n",
            "---> iteration:  82  partial loss: 0.057650227\n",
            "---> iteration:  83  partial loss: 0.024041547\n",
            "---> iteration:  84  partial loss: 0.02139289\n",
            "---> iteration:  85  partial loss: 0.06617405\n",
            "---> iteration:  86  partial loss: 0.021721562\n",
            "---> iteration:  87  partial loss: 0.027712705\n",
            "---> iteration:  88  partial loss: 0.022738563\n",
            "---> iteration:  89  partial loss: 0.059164926\n",
            "---> iteration:  90  partial loss: 0.04148143\n",
            "---> iteration:  91  partial loss: 0.06292889\n",
            "---> iteration:  92  partial loss: 0.037816223\n",
            "---> iteration:  93  partial loss: 0.065683775\n",
            "---> iteration:  94  partial loss: 0.39831403\n",
            "---> iteration:  95  partial loss: 0.078757904\n",
            "---> iteration:  96  partial loss: 0.027198996\n",
            "---> iteration:  97  partial loss: 0.40519866\n",
            "---> iteration:  98  partial loss: 0.06622887\n",
            "---> iteration:  99  partial loss: 0.29597095\n",
            "---> iteration:  100  partial loss: 0.14911816\n",
            "---> iteration:  101  partial loss: 0.08677042\n",
            "---> iteration:  102  partial loss: 0.36787063\n",
            "---> iteration:  103  partial loss: 0.02977484\n",
            "---> iteration:  104  partial loss: 0.22946598\n",
            "---> iteration:  105  partial loss: 0.058730323\n",
            "---> iteration:  106  partial loss: 0.08632427\n",
            "---> iteration:  107  partial loss: 0.08285371\n",
            "---> iteration:  108  partial loss: 0.09246143\n",
            "---> iteration:  109  partial loss: 0.073782966\n",
            "---> iteration:  110  partial loss: 0.22198643\n",
            "---> iteration:  111  partial loss: 0.09089088\n",
            "---> iteration:  112  partial loss: 0.08638271\n",
            "---> iteration:  113  partial loss: 0.06723498\n",
            "---> iteration:  114  partial loss: 0.042959303\n",
            "---> iteration:  115  partial loss: 0.11773347\n",
            "---> iteration:  116  partial loss: 0.08110487\n",
            "---> iteration:  117  partial loss: 0.11124416\n",
            "---> iteration:  118  partial loss: 0.16426478\n",
            "---> iteration:  119  partial loss: 0.10174997\n",
            "---> iteration:  120  partial loss: 0.10473497\n",
            "---> iteration:  121  partial loss: 0.08735571\n",
            "---> iteration:  122  partial loss: 0.041483626\n",
            "---> iteration:  123  partial loss: 0.08459851\n",
            "---> iteration:  124  partial loss: 0.15669702\n",
            "---> iteration:  125  partial loss: 0.08100677\n",
            "---> iteration:  126  partial loss: 0.12476949\n",
            "---> iteration:  127  partial loss: 0.07027493\n",
            "---> iteration:  128  partial loss: 0.10504795\n",
            "---> iteration:  129  partial loss: 0.028556785\n",
            "---> iteration:  130  partial loss: 0.24935938\n",
            "---> iteration:  131  partial loss: 0.23339729\n",
            "---> iteration:  132  partial loss: 0.031679027\n",
            "---> iteration:  133  partial loss: 0.117664486\n",
            "---> iteration:  134  partial loss: 0.087988794\n",
            "---> iteration:  135  partial loss: 0.096823946\n",
            "---> iteration:  136  partial loss: 0.14124879\n",
            "---> iteration:  137  partial loss: 0.120166205\n",
            "---> iteration:  138  partial loss: 0.08930937\n",
            "---> iteration:  139  partial loss: 0.04703455\n",
            "---> iteration:  140  partial loss: 0.08414572\n",
            "---> iteration:  141  partial loss: 0.05874941\n",
            "---> iteration:  142  partial loss: 0.082848236\n",
            "---> iteration:  143  partial loss: 0.065801725\n",
            "---> iteration:  144  partial loss: 0.06878913\n",
            "---> iteration:  145  partial loss: 0.14588024\n",
            "---> iteration:  146  partial loss: 0.14701717\n",
            "---> iteration:  147  partial loss: 0.07961098\n",
            "---> iteration:  148  partial loss: 0.043949224\n",
            "---> iteration:  149  partial loss: 0.028014809\n",
            "---> iteration:  150  partial loss: 0.045030244\n",
            "---> iteration:  151  partial loss: 0.085928686\n",
            "---> iteration:  152  partial loss: 0.103496745\n",
            "---> iteration:  153  partial loss: 0.042495217\n",
            "---> iteration:  154  partial loss: 0.08855082\n",
            "---> iteration:  155  partial loss: 0.056283925\n",
            "---> iteration:  156  partial loss: 0.058959357\n",
            "---> iteration:  157  partial loss: 0.1764995\n",
            "---> iteration:  158  partial loss: 0.07547557\n",
            "---> iteration:  159  partial loss: 0.03412859\n",
            "---> iteration:  160  partial loss: 0.08826988\n",
            "---> iteration:  161  partial loss: 0.04739175\n",
            "---> iteration:  162  partial loss: 0.07162352\n",
            "---> iteration:  163  partial loss: 0.06346452\n",
            "---> iteration:  164  partial loss: 0.08539568\n",
            "---> iteration:  165  partial loss: 0.13058898\n",
            "---> iteration:  166  partial loss: 0.07651397\n",
            "---> iteration:  167  partial loss: 0.034339644\n",
            "---> iteration:  168  partial loss: 0.049686972\n",
            "---> iteration:  169  partial loss: 0.08010975\n",
            "---> iteration:  170  partial loss: 0.03727772\n",
            "---> iteration:  171  partial loss: 0.08708228\n",
            "---> iteration:  172  partial loss: 0.087855935\n",
            "---> iteration:  173  partial loss: 0.056260437\n",
            "---> iteration:  174  partial loss: 0.038507495\n",
            "---> iteration:  175  partial loss: 0.080082566\n",
            "---> iteration:  176  partial loss: 0.04302562\n",
            "---> iteration:  177  partial loss: 0.10085477\n",
            "---> iteration:  178  partial loss: 0.07565419\n",
            "---> iteration:  179  partial loss: 0.04838158\n",
            "---> iteration:  180  partial loss: 0.033296272\n",
            "---> iteration:  181  partial loss: 0.0930519\n",
            "---> iteration:  182  partial loss: 0.0671372\n",
            "---> iteration:  183  partial loss: 0.0190494\n",
            "---> iteration:  184  partial loss: 0.08191787\n",
            "---> iteration:  185  partial loss: 0.2351081\n",
            "---> iteration:  186  partial loss: 0.047845818\n",
            "---> iteration:  187  partial loss: 0.053973515\n",
            "---> iteration:  188  partial loss: 0.045278125\n",
            "---> iteration:  189  partial loss: 0.05212035\n",
            "---> iteration:  190  partial loss: 0.06931418\n",
            "---> iteration:  191  partial loss: 0.112856895\n",
            "---> iteration:  192  partial loss: 0.05967953\n",
            "---> iteration:  193  partial loss: 0.036588337\n",
            "---> iteration:  194  partial loss: 0.06731295\n",
            "---> iteration:  195  partial loss: 0.098607615\n",
            "---> iteration:  196  partial loss: 0.068980314\n",
            "---> iteration:  197  partial loss: 0.06618416\n",
            "---> iteration:  198  partial loss: 0.034403183\n",
            "---> iteration:  199  partial loss: 0.048971802\n",
            "---> iteration:  200  partial loss: 0.21816021\n",
            "---> iteration:  201  partial loss: 0.083444946\n",
            "---> iteration:  202  partial loss: 0.07006982\n",
            "---> iteration:  203  partial loss: 0.041077472\n",
            "---> iteration:  204  partial loss: 0.09514936\n",
            "---> iteration:  205  partial loss: 0.040041436\n",
            "---> iteration:  206  partial loss: 0.04006258\n",
            "---> iteration:  207  partial loss: 0.040121034\n",
            "---> iteration:  208  partial loss: 0.028755443\n",
            "---> iteration:  209  partial loss: 0.11127793\n",
            "---> iteration:  210  partial loss: 0.055843797\n",
            "---> iteration:  211  partial loss: 0.28364575\n",
            "---> iteration:  212  partial loss: 0.06856407\n",
            "---> iteration:  213  partial loss: 0.05277998\n",
            "---> iteration:  214  partial loss: 0.0426828\n",
            "---> iteration:  215  partial loss: 0.048721664\n",
            "---> iteration:  216  partial loss: 0.1570946\n",
            "---> iteration:  217  partial loss: 0.09741389\n",
            "---> iteration:  218  partial loss: 0.03353167\n",
            "---> iteration:  219  partial loss: 0.022321519\n",
            "---> iteration:  220  partial loss: 0.06577324\n",
            "---> iteration:  221  partial loss: 0.11504317\n",
            "---> iteration:  222  partial loss: 0.052010663\n",
            "---> iteration:  223  partial loss: 0.16533248\n",
            "---> iteration:  224  partial loss: 0.08630849\n",
            "---> iteration:  225  partial loss: 0.19641726\n",
            "---> iteration:  226  partial loss: 0.04663889\n",
            "---> iteration:  227  partial loss: 0.11597224\n",
            "---> iteration:  228  partial loss: 0.056344148\n",
            "---> iteration:  229  partial loss: 0.16166957\n",
            "---> iteration:  230  partial loss: 0.07016969\n",
            "---> iteration:  231  partial loss: 0.06943542\n",
            "---> iteration:  232  partial loss: 0.064050354\n",
            "---> iteration:  233  partial loss: 0.03325532\n",
            "---> iteration:  234  partial loss: 0.1658855\n",
            "---> iteration:  235  partial loss: 0.057955507\n",
            "---> iteration:  236  partial loss: 0.042562407\n",
            "---> iteration:  237  partial loss: 0.103000775\n",
            "---> iteration:  238  partial loss: 0.12761492\n",
            "---> iteration:  239  partial loss: 0.13650022\n",
            "---> iteration:  240  partial loss: 0.036915436\n",
            "---> iteration:  241  partial loss: 0.05835689\n",
            "---> iteration:  242  partial loss: 0.1165131\n",
            "---> iteration:  243  partial loss: 0.06692525\n",
            "---> iteration:  244  partial loss: 0.10029963\n",
            "---> iteration:  245  partial loss: 0.06871235\n",
            "---> iteration:  246  partial loss: 0.03314664\n",
            "---> iteration:  247  partial loss: 0.058144633\n",
            "---> iteration:  248  partial loss: 0.045935344\n",
            "---> iteration:  249  partial loss: 0.024537574\n",
            "---> iteration:  250  partial loss: 0.06909391\n",
            "---> iteration:  251  partial loss: 0.029715125\n",
            "---> iteration:  252  partial loss: 0.041478597\n",
            "---> iteration:  253  partial loss: 0.099606216\n",
            "---> iteration:  254  partial loss: 0.057424646\n",
            "---> iteration:  255  partial loss: 0.05231974\n",
            "---> iteration:  256  partial loss: 0.07959047\n",
            "---> iteration:  257  partial loss: 0.0497663\n",
            "---> iteration:  258  partial loss: 0.06714276\n",
            "---> iteration:  259  partial loss: 0.17862612\n",
            "---> iteration:  260  partial loss: 0.057815116\n",
            "---> iteration:  261  partial loss: 0.10523274\n",
            "---> iteration:  262  partial loss: 0.03468337\n",
            "---> iteration:  263  partial loss: 0.07624742\n",
            "---> iteration:  264  partial loss: 0.05125449\n",
            "---> iteration:  265  partial loss: 0.052600425\n",
            "---> iteration:  266  partial loss: 0.08621695\n",
            "---> iteration:  267  partial loss: 0.06650039\n",
            "---> iteration:  268  partial loss: 0.08385938\n",
            "---> iteration:  269  partial loss: 0.1651702\n",
            "---> iteration:  270  partial loss: 0.078171715\n",
            "---> iteration:  271  partial loss: 0.11358047\n",
            "---> iteration:  272  partial loss: 0.08393125\n",
            "---> iteration:  273  partial loss: 0.02491355\n",
            "---> iteration:  274  partial loss: 0.07566946\n",
            "---> iteration:  275  partial loss: 0.042090923\n",
            "---> iteration:  276  partial loss: 0.032307167\n",
            "---> iteration:  277  partial loss: 0.08678073\n",
            "---> iteration:  278  partial loss: 0.06439428\n",
            "---> iteration:  279  partial loss: 0.055376634\n",
            "---> iteration:  280  partial loss: 0.046101455\n",
            "---> iteration:  281  partial loss: 0.07032164\n",
            "---> iteration:  282  partial loss: 0.11319514\n",
            "---> iteration:  283  partial loss: 0.0740248\n",
            "---> iteration:  284  partial loss: 0.14987661\n",
            "---> iteration:  285  partial loss: 0.034996532\n",
            "---> iteration:  286  partial loss: 0.11642988\n",
            "---> iteration:  287  partial loss: 0.06861477\n",
            "---> iteration:  288  partial loss: 0.0859773\n",
            "---> iteration:  289  partial loss: 0.04793318\n",
            "------------------\n",
            "epoch:  16  of  20 training loss:  0.07535435807179003\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.05357559\n",
            "---> iteration:  2  partial loss: 0.04803587\n",
            "---> iteration:  3  partial loss: 0.0676382\n",
            "---> iteration:  4  partial loss: 0.032106753\n",
            "---> iteration:  5  partial loss: 0.11331563\n",
            "---> iteration:  6  partial loss: 0.11127735\n",
            "---> iteration:  7  partial loss: 0.022763796\n",
            "---> iteration:  8  partial loss: 0.06641677\n",
            "---> iteration:  9  partial loss: 0.07350231\n",
            "---> iteration:  10  partial loss: 0.061012503\n",
            "---> iteration:  11  partial loss: 0.050067987\n",
            "---> iteration:  12  partial loss: 0.078632675\n",
            "---> iteration:  13  partial loss: 0.06447829\n",
            "---> iteration:  14  partial loss: 0.033390123\n",
            "---> iteration:  15  partial loss: 0.04307896\n",
            "---> iteration:  16  partial loss: 0.06649559\n",
            "---> iteration:  17  partial loss: 0.1161754\n",
            "---> iteration:  18  partial loss: 0.02553525\n",
            "---> iteration:  19  partial loss: 0.06531815\n",
            "---> iteration:  20  partial loss: 0.032647748\n",
            "---> iteration:  21  partial loss: 0.024180932\n",
            "---> iteration:  22  partial loss: 0.01556634\n",
            "---> iteration:  23  partial loss: 0.03451763\n",
            "---> iteration:  24  partial loss: 0.092994444\n",
            "---> iteration:  25  partial loss: 0.06456782\n",
            "---> iteration:  26  partial loss: 0.08673326\n",
            "---> iteration:  27  partial loss: 0.059789002\n",
            "---> iteration:  28  partial loss: 0.04801677\n",
            "---> iteration:  29  partial loss: 0.03944085\n",
            "---> iteration:  30  partial loss: 0.043105494\n",
            "---> iteration:  31  partial loss: 0.095289335\n",
            "---> iteration:  32  partial loss: 0.022235977\n",
            "---> iteration:  33  partial loss: 0.09381746\n",
            "---> iteration:  34  partial loss: 0.111964144\n",
            "---> iteration:  35  partial loss: 0.061934173\n",
            "---> iteration:  36  partial loss: 0.13520847\n",
            "---> iteration:  37  partial loss: 0.054909527\n",
            "---> iteration:  38  partial loss: 0.022526413\n",
            "---> iteration:  39  partial loss: 0.056077145\n",
            "---> iteration:  40  partial loss: 0.061528042\n",
            "---> iteration:  41  partial loss: 0.0580838\n",
            "---> iteration:  42  partial loss: 0.022392087\n",
            "---> iteration:  43  partial loss: 0.09807813\n",
            "---> iteration:  44  partial loss: 0.072224945\n",
            "---> iteration:  45  partial loss: 0.08220103\n",
            "---> iteration:  46  partial loss: 0.07001398\n",
            "---> iteration:  47  partial loss: 0.066096015\n",
            "---> iteration:  48  partial loss: 0.042720467\n",
            "---> iteration:  49  partial loss: 0.08133649\n",
            "---> iteration:  50  partial loss: 0.050603013\n",
            "---> iteration:  51  partial loss: 0.025509622\n",
            "---> iteration:  52  partial loss: 0.12101854\n",
            "---> iteration:  53  partial loss: 0.05971453\n",
            "---> iteration:  54  partial loss: 0.08022538\n",
            "---> iteration:  55  partial loss: 0.047529437\n",
            "---> iteration:  56  partial loss: 0.023023028\n",
            "---> iteration:  57  partial loss: 0.022770422\n",
            "---> iteration:  58  partial loss: 0.026876193\n",
            "---> iteration:  59  partial loss: 0.024338102\n",
            "---> iteration:  60  partial loss: 0.07899831\n",
            "---> iteration:  61  partial loss: 0.08344409\n",
            "---> iteration:  62  partial loss: 0.064897105\n",
            "---> iteration:  63  partial loss: 0.03630096\n",
            "---> iteration:  64  partial loss: 0.049161658\n",
            "---> iteration:  65  partial loss: 0.04885223\n",
            "---> iteration:  66  partial loss: 0.057938464\n",
            "---> iteration:  67  partial loss: 0.0419741\n",
            "---> iteration:  68  partial loss: 0.04038211\n",
            "---> iteration:  69  partial loss: 0.026977101\n",
            "---> iteration:  70  partial loss: 0.053856634\n",
            "---> iteration:  71  partial loss: 0.018679034\n",
            "---> iteration:  72  partial loss: 0.039244078\n",
            "---> iteration:  73  partial loss: 0.15405191\n",
            "---> iteration:  74  partial loss: 0.037849523\n",
            "---> iteration:  75  partial loss: 0.077870436\n",
            "---> iteration:  76  partial loss: 0.033074368\n",
            "---> iteration:  77  partial loss: 0.04743714\n",
            "---> iteration:  78  partial loss: 0.060828608\n",
            "---> iteration:  79  partial loss: 0.029644726\n",
            "---> iteration:  80  partial loss: 0.014725518\n",
            "---> iteration:  81  partial loss: 0.044173088\n",
            "---> iteration:  82  partial loss: 0.051358435\n",
            "---> iteration:  83  partial loss: 0.051097997\n",
            "---> iteration:  84  partial loss: 0.068394355\n",
            "---> iteration:  85  partial loss: 0.057399787\n",
            "---> iteration:  86  partial loss: 0.029926226\n",
            "---> iteration:  87  partial loss: 0.110417165\n",
            "---> iteration:  88  partial loss: 0.110943265\n",
            "---> iteration:  89  partial loss: 0.037836228\n",
            "---> iteration:  90  partial loss: 0.05599161\n",
            "---> iteration:  91  partial loss: 0.07647402\n",
            "---> iteration:  92  partial loss: 0.05025039\n",
            "---> iteration:  93  partial loss: 0.091007\n",
            "---> iteration:  94  partial loss: 0.031070312\n",
            "---> iteration:  95  partial loss: 0.079592004\n",
            "---> iteration:  96  partial loss: 0.038367234\n",
            "---> iteration:  97  partial loss: 0.039936516\n",
            "---> iteration:  98  partial loss: 0.15162924\n",
            "---> iteration:  99  partial loss: 0.108890526\n",
            "---> iteration:  100  partial loss: 0.033900347\n",
            "---> iteration:  101  partial loss: 0.04124663\n",
            "---> iteration:  102  partial loss: 0.0405017\n",
            "---> iteration:  103  partial loss: 0.06272183\n",
            "---> iteration:  104  partial loss: 0.024692543\n",
            "---> iteration:  105  partial loss: 0.034374774\n",
            "---> iteration:  106  partial loss: 0.043385845\n",
            "---> iteration:  107  partial loss: 0.079027645\n",
            "---> iteration:  108  partial loss: 0.13456964\n",
            "---> iteration:  109  partial loss: 0.020270148\n",
            "---> iteration:  110  partial loss: 0.059811443\n",
            "---> iteration:  111  partial loss: 0.11247635\n",
            "---> iteration:  112  partial loss: 0.029003488\n",
            "---> iteration:  113  partial loss: 0.058872633\n",
            "---> iteration:  114  partial loss: 0.043312464\n",
            "---> iteration:  115  partial loss: 0.06645281\n",
            "---> iteration:  116  partial loss: 0.02823684\n",
            "---> iteration:  117  partial loss: 0.05112755\n",
            "---> iteration:  118  partial loss: 0.018339854\n",
            "---> iteration:  119  partial loss: 0.027126927\n",
            "---> iteration:  120  partial loss: 0.10817729\n",
            "---> iteration:  121  partial loss: 0.07403206\n",
            "---> iteration:  122  partial loss: 0.08413563\n",
            "---> iteration:  123  partial loss: 0.046117246\n",
            "---> iteration:  124  partial loss: 0.050702605\n",
            "---> iteration:  125  partial loss: 0.08220643\n",
            "---> iteration:  126  partial loss: 0.025658967\n",
            "---> iteration:  127  partial loss: 0.059409015\n",
            "---> iteration:  128  partial loss: 0.0888037\n",
            "---> iteration:  129  partial loss: 0.06363143\n",
            "---> iteration:  130  partial loss: 0.050297722\n",
            "---> iteration:  131  partial loss: 0.023453366\n",
            "---> iteration:  132  partial loss: 0.08754175\n",
            "---> iteration:  133  partial loss: 0.032480516\n",
            "---> iteration:  134  partial loss: 0.0637578\n",
            "---> iteration:  135  partial loss: 0.033184607\n",
            "---> iteration:  136  partial loss: 0.030630369\n",
            "---> iteration:  137  partial loss: 0.09057\n",
            "---> iteration:  138  partial loss: 0.036534168\n",
            "---> iteration:  139  partial loss: 0.035662238\n",
            "---> iteration:  140  partial loss: 0.16677615\n",
            "---> iteration:  141  partial loss: 0.051642857\n",
            "---> iteration:  142  partial loss: 0.046436615\n",
            "---> iteration:  143  partial loss: 0.036607288\n",
            "---> iteration:  144  partial loss: 0.01440472\n",
            "---> iteration:  145  partial loss: 0.055181894\n",
            "---> iteration:  146  partial loss: 0.0504346\n",
            "---> iteration:  147  partial loss: 0.04463355\n",
            "---> iteration:  148  partial loss: 0.061927043\n",
            "---> iteration:  149  partial loss: 0.06692401\n",
            "---> iteration:  150  partial loss: 0.052238062\n",
            "---> iteration:  151  partial loss: 0.050449573\n",
            "---> iteration:  152  partial loss: 0.049971044\n",
            "---> iteration:  153  partial loss: 0.07244374\n",
            "---> iteration:  154  partial loss: 0.024079638\n",
            "---> iteration:  155  partial loss: 0.037417985\n",
            "---> iteration:  156  partial loss: 0.040066905\n",
            "---> iteration:  157  partial loss: 0.019653255\n",
            "---> iteration:  158  partial loss: 0.037899036\n",
            "---> iteration:  159  partial loss: 0.089916736\n",
            "---> iteration:  160  partial loss: 0.056085058\n",
            "---> iteration:  161  partial loss: 0.05054036\n",
            "---> iteration:  162  partial loss: 0.05231049\n",
            "---> iteration:  163  partial loss: 0.057045083\n",
            "---> iteration:  164  partial loss: 0.04030898\n",
            "---> iteration:  165  partial loss: 0.044746548\n",
            "---> iteration:  166  partial loss: 0.0359759\n",
            "---> iteration:  167  partial loss: 0.03791121\n",
            "---> iteration:  168  partial loss: 0.061067402\n",
            "---> iteration:  169  partial loss: 0.05075997\n",
            "---> iteration:  170  partial loss: 0.023543024\n",
            "---> iteration:  171  partial loss: 0.026442213\n",
            "---> iteration:  172  partial loss: 0.06373993\n",
            "---> iteration:  173  partial loss: 0.04093857\n",
            "---> iteration:  174  partial loss: 0.07159401\n",
            "---> iteration:  175  partial loss: 0.022870395\n",
            "---> iteration:  176  partial loss: 0.026851505\n",
            "---> iteration:  177  partial loss: 0.05710582\n",
            "---> iteration:  178  partial loss: 0.046541028\n",
            "---> iteration:  179  partial loss: 0.020954337\n",
            "---> iteration:  180  partial loss: 0.0732963\n",
            "---> iteration:  181  partial loss: 0.049391486\n",
            "---> iteration:  182  partial loss: 0.06870691\n",
            "---> iteration:  183  partial loss: 0.07757952\n",
            "---> iteration:  184  partial loss: 0.024248172\n",
            "---> iteration:  185  partial loss: 0.030572634\n",
            "---> iteration:  186  partial loss: 0.029295007\n",
            "---> iteration:  187  partial loss: 0.019045528\n",
            "---> iteration:  188  partial loss: 0.021792417\n",
            "---> iteration:  189  partial loss: 0.0863446\n",
            "---> iteration:  190  partial loss: 0.02925147\n",
            "---> iteration:  191  partial loss: 0.06121259\n",
            "---> iteration:  192  partial loss: 0.032263614\n",
            "---> iteration:  193  partial loss: 0.040986285\n",
            "---> iteration:  194  partial loss: 0.10661331\n",
            "---> iteration:  195  partial loss: 0.031898893\n",
            "---> iteration:  196  partial loss: 0.06566736\n",
            "---> iteration:  197  partial loss: 0.017682897\n",
            "---> iteration:  198  partial loss: 0.06375684\n",
            "---> iteration:  199  partial loss: 0.08625769\n",
            "---> iteration:  200  partial loss: 0.020957572\n",
            "---> iteration:  201  partial loss: 0.054398138\n",
            "---> iteration:  202  partial loss: 0.019840656\n",
            "---> iteration:  203  partial loss: 0.026044345\n",
            "---> iteration:  204  partial loss: 0.0272128\n",
            "---> iteration:  205  partial loss: 0.058854505\n",
            "---> iteration:  206  partial loss: 0.05572551\n",
            "---> iteration:  207  partial loss: 0.029152272\n",
            "---> iteration:  208  partial loss: 0.030757902\n",
            "---> iteration:  209  partial loss: 0.023840733\n",
            "---> iteration:  210  partial loss: 0.078347564\n",
            "---> iteration:  211  partial loss: 0.056255236\n",
            "---> iteration:  212  partial loss: 0.02974815\n",
            "---> iteration:  213  partial loss: 0.038032606\n",
            "---> iteration:  214  partial loss: 0.08730471\n",
            "---> iteration:  215  partial loss: 0.05657452\n",
            "---> iteration:  216  partial loss: 0.22142696\n",
            "---> iteration:  217  partial loss: 0.050947793\n",
            "---> iteration:  218  partial loss: 0.028361\n",
            "---> iteration:  219  partial loss: 0.080551155\n",
            "---> iteration:  220  partial loss: 0.09264556\n",
            "---> iteration:  221  partial loss: 0.07643679\n",
            "---> iteration:  222  partial loss: 0.101313874\n",
            "---> iteration:  223  partial loss: 0.19618887\n",
            "---> iteration:  224  partial loss: 0.10740932\n",
            "---> iteration:  225  partial loss: 0.04857637\n",
            "---> iteration:  226  partial loss: 0.07042\n",
            "---> iteration:  227  partial loss: 0.0770362\n",
            "---> iteration:  228  partial loss: 0.03594562\n",
            "---> iteration:  229  partial loss: 0.10302406\n",
            "---> iteration:  230  partial loss: 0.054566182\n",
            "---> iteration:  231  partial loss: 0.040897056\n",
            "---> iteration:  232  partial loss: 0.05279257\n",
            "---> iteration:  233  partial loss: 0.09451517\n",
            "---> iteration:  234  partial loss: 0.019940214\n",
            "---> iteration:  235  partial loss: 0.16902407\n",
            "---> iteration:  236  partial loss: 0.06004916\n",
            "---> iteration:  237  partial loss: 0.06087\n",
            "---> iteration:  238  partial loss: 0.092664644\n",
            "---> iteration:  239  partial loss: 0.057596035\n",
            "---> iteration:  240  partial loss: 0.040350992\n",
            "---> iteration:  241  partial loss: 0.06267916\n",
            "---> iteration:  242  partial loss: 0.100839615\n",
            "---> iteration:  243  partial loss: 0.0657167\n",
            "---> iteration:  244  partial loss: 0.032593116\n",
            "---> iteration:  245  partial loss: 0.07025197\n",
            "---> iteration:  246  partial loss: 0.0738994\n",
            "---> iteration:  247  partial loss: 0.116476856\n",
            "---> iteration:  248  partial loss: 0.1442414\n",
            "---> iteration:  249  partial loss: 0.05729386\n",
            "---> iteration:  250  partial loss: 0.05058164\n",
            "---> iteration:  251  partial loss: 0.07448728\n",
            "---> iteration:  252  partial loss: 0.033867598\n",
            "---> iteration:  253  partial loss: 0.06851983\n",
            "---> iteration:  254  partial loss: 0.044078153\n",
            "---> iteration:  255  partial loss: 0.05211275\n",
            "---> iteration:  256  partial loss: 0.03393212\n",
            "---> iteration:  257  partial loss: 0.050597366\n",
            "---> iteration:  258  partial loss: 0.033103924\n",
            "---> iteration:  259  partial loss: 0.040313974\n",
            "---> iteration:  260  partial loss: 0.043560036\n",
            "---> iteration:  261  partial loss: 0.06305714\n",
            "---> iteration:  262  partial loss: 0.028076105\n",
            "---> iteration:  263  partial loss: 0.02599793\n",
            "---> iteration:  264  partial loss: 0.0448304\n",
            "---> iteration:  265  partial loss: 0.018394232\n",
            "---> iteration:  266  partial loss: 0.046189055\n",
            "---> iteration:  267  partial loss: 0.10680084\n",
            "---> iteration:  268  partial loss: 0.020306429\n",
            "---> iteration:  269  partial loss: 0.0285277\n",
            "---> iteration:  270  partial loss: 0.070837684\n",
            "---> iteration:  271  partial loss: 0.053038873\n",
            "---> iteration:  272  partial loss: 0.05590208\n",
            "---> iteration:  273  partial loss: 0.028120248\n",
            "---> iteration:  274  partial loss: 0.016155494\n",
            "---> iteration:  275  partial loss: 0.051085923\n",
            "---> iteration:  276  partial loss: 0.052807868\n",
            "---> iteration:  277  partial loss: 0.02656872\n",
            "---> iteration:  278  partial loss: 0.07605698\n",
            "---> iteration:  279  partial loss: 0.053265944\n",
            "---> iteration:  280  partial loss: 0.13702439\n",
            "---> iteration:  281  partial loss: 0.06016015\n",
            "---> iteration:  282  partial loss: 0.10504402\n",
            "---> iteration:  283  partial loss: 0.040269643\n",
            "---> iteration:  284  partial loss: 0.077000074\n",
            "---> iteration:  285  partial loss: 0.042460997\n",
            "---> iteration:  286  partial loss: 0.021160826\n",
            "---> iteration:  287  partial loss: 0.080632225\n",
            "---> iteration:  288  partial loss: 0.18866989\n",
            "---> iteration:  289  partial loss: 0.04368542\n",
            "------------------\n",
            "epoch:  17  of  20 training loss:  0.05775839519915799\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.13376749\n",
            "---> iteration:  2  partial loss: 0.034388147\n",
            "---> iteration:  3  partial loss: 0.06872313\n",
            "---> iteration:  4  partial loss: 0.05728543\n",
            "---> iteration:  5  partial loss: 0.07093658\n",
            "---> iteration:  6  partial loss: 0.0716233\n",
            "---> iteration:  7  partial loss: 0.0280427\n",
            "---> iteration:  8  partial loss: 0.05337467\n",
            "---> iteration:  9  partial loss: 0.05848247\n",
            "---> iteration:  10  partial loss: 0.03974152\n",
            "---> iteration:  11  partial loss: 0.0401107\n",
            "---> iteration:  12  partial loss: 0.056787077\n",
            "---> iteration:  13  partial loss: 0.07828016\n",
            "---> iteration:  14  partial loss: 0.023124982\n",
            "---> iteration:  15  partial loss: 0.041370787\n",
            "---> iteration:  16  partial loss: 0.044159785\n",
            "---> iteration:  17  partial loss: 0.06838229\n",
            "---> iteration:  18  partial loss: 0.086439475\n",
            "---> iteration:  19  partial loss: 0.02287559\n",
            "---> iteration:  20  partial loss: 0.043247815\n",
            "---> iteration:  21  partial loss: 0.03894435\n",
            "---> iteration:  22  partial loss: 0.23063113\n",
            "---> iteration:  23  partial loss: 0.040102813\n",
            "---> iteration:  24  partial loss: 0.056469776\n",
            "---> iteration:  25  partial loss: 0.07720756\n",
            "---> iteration:  26  partial loss: 0.03199891\n",
            "---> iteration:  27  partial loss: 0.070123196\n",
            "---> iteration:  28  partial loss: 0.05197388\n",
            "---> iteration:  29  partial loss: 0.06694768\n",
            "---> iteration:  30  partial loss: 0.031285614\n",
            "---> iteration:  31  partial loss: 0.041830566\n",
            "---> iteration:  32  partial loss: 0.021651518\n",
            "---> iteration:  33  partial loss: 0.039782953\n",
            "---> iteration:  34  partial loss: 0.028959254\n",
            "---> iteration:  35  partial loss: 0.05391677\n",
            "---> iteration:  36  partial loss: 0.04535793\n",
            "---> iteration:  37  partial loss: 0.024546474\n",
            "---> iteration:  38  partial loss: 0.049712874\n",
            "---> iteration:  39  partial loss: 0.01831269\n",
            "---> iteration:  40  partial loss: 0.056528408\n",
            "---> iteration:  41  partial loss: 0.094024055\n",
            "---> iteration:  42  partial loss: 0.08055045\n",
            "---> iteration:  43  partial loss: 0.08209751\n",
            "---> iteration:  44  partial loss: 0.06727905\n",
            "---> iteration:  45  partial loss: 0.044848654\n",
            "---> iteration:  46  partial loss: 0.048946243\n",
            "---> iteration:  47  partial loss: 0.02284375\n",
            "---> iteration:  48  partial loss: 0.052303024\n",
            "---> iteration:  49  partial loss: 0.07338217\n",
            "---> iteration:  50  partial loss: 0.029896302\n",
            "---> iteration:  51  partial loss: 0.045599118\n",
            "---> iteration:  52  partial loss: 0.05305948\n",
            "---> iteration:  53  partial loss: 0.047842607\n",
            "---> iteration:  54  partial loss: 0.04986851\n",
            "---> iteration:  55  partial loss: 0.05284818\n",
            "---> iteration:  56  partial loss: 0.07846167\n",
            "---> iteration:  57  partial loss: 0.07778873\n",
            "---> iteration:  58  partial loss: 0.05401389\n",
            "---> iteration:  59  partial loss: 0.09691898\n",
            "---> iteration:  60  partial loss: 0.06598488\n",
            "---> iteration:  61  partial loss: 0.054589972\n",
            "---> iteration:  62  partial loss: 0.050771397\n",
            "---> iteration:  63  partial loss: 0.028208543\n",
            "---> iteration:  64  partial loss: 0.03730834\n",
            "---> iteration:  65  partial loss: 0.050218705\n",
            "---> iteration:  66  partial loss: 0.039139684\n",
            "---> iteration:  67  partial loss: 0.04098207\n",
            "---> iteration:  68  partial loss: 0.024253305\n",
            "---> iteration:  69  partial loss: 0.052915186\n",
            "---> iteration:  70  partial loss: 0.047451343\n",
            "---> iteration:  71  partial loss: 0.11007248\n",
            "---> iteration:  72  partial loss: 0.036220346\n",
            "---> iteration:  73  partial loss: 0.023587955\n",
            "---> iteration:  74  partial loss: 0.02439794\n",
            "---> iteration:  75  partial loss: 0.02044373\n",
            "---> iteration:  76  partial loss: 0.06432024\n",
            "---> iteration:  77  partial loss: 0.06801515\n",
            "---> iteration:  78  partial loss: 0.067938596\n",
            "---> iteration:  79  partial loss: 0.060191493\n",
            "---> iteration:  80  partial loss: 0.08094623\n",
            "---> iteration:  81  partial loss: 0.043502767\n",
            "---> iteration:  82  partial loss: 0.057302225\n",
            "---> iteration:  83  partial loss: 0.054547433\n",
            "---> iteration:  84  partial loss: 0.055660546\n",
            "---> iteration:  85  partial loss: 0.035583336\n",
            "---> iteration:  86  partial loss: 0.034686126\n",
            "---> iteration:  87  partial loss: 0.057495594\n",
            "---> iteration:  88  partial loss: 0.030886676\n",
            "---> iteration:  89  partial loss: 0.025931811\n",
            "---> iteration:  90  partial loss: 0.040412556\n",
            "---> iteration:  91  partial loss: 0.034045607\n",
            "---> iteration:  92  partial loss: 0.06819526\n",
            "---> iteration:  93  partial loss: 0.032747813\n",
            "---> iteration:  94  partial loss: 0.052481957\n",
            "---> iteration:  95  partial loss: 0.031416193\n",
            "---> iteration:  96  partial loss: 0.032306723\n",
            "---> iteration:  97  partial loss: 0.02185792\n",
            "---> iteration:  98  partial loss: 0.07843262\n",
            "---> iteration:  99  partial loss: 0.071626425\n",
            "---> iteration:  100  partial loss: 0.09560047\n",
            "---> iteration:  101  partial loss: 0.03065895\n",
            "---> iteration:  102  partial loss: 0.04833657\n",
            "---> iteration:  103  partial loss: 0.046942107\n",
            "---> iteration:  104  partial loss: 0.02729601\n",
            "---> iteration:  105  partial loss: 0.035722993\n",
            "---> iteration:  106  partial loss: 0.012993907\n",
            "---> iteration:  107  partial loss: 0.030068107\n",
            "---> iteration:  108  partial loss: 0.0424024\n",
            "---> iteration:  109  partial loss: 0.04784934\n",
            "---> iteration:  110  partial loss: 0.05747867\n",
            "---> iteration:  111  partial loss: 0.06818306\n",
            "---> iteration:  112  partial loss: 0.051276382\n",
            "---> iteration:  113  partial loss: 0.040518872\n",
            "---> iteration:  114  partial loss: 0.026869003\n",
            "---> iteration:  115  partial loss: 0.017486822\n",
            "---> iteration:  116  partial loss: 0.017007725\n",
            "---> iteration:  117  partial loss: 0.04238075\n",
            "---> iteration:  118  partial loss: 0.040818375\n",
            "---> iteration:  119  partial loss: 0.037752394\n",
            "---> iteration:  120  partial loss: 0.021053357\n",
            "---> iteration:  121  partial loss: 0.03004093\n",
            "---> iteration:  122  partial loss: 0.044094816\n",
            "---> iteration:  123  partial loss: 0.043991476\n",
            "---> iteration:  124  partial loss: 0.06575949\n",
            "---> iteration:  125  partial loss: 0.11650751\n",
            "---> iteration:  126  partial loss: 0.049788676\n",
            "---> iteration:  127  partial loss: 0.021681793\n",
            "---> iteration:  128  partial loss: 0.08208194\n",
            "---> iteration:  129  partial loss: 0.046340875\n",
            "---> iteration:  130  partial loss: 0.054667324\n",
            "---> iteration:  131  partial loss: 0.14926305\n",
            "---> iteration:  132  partial loss: 0.034591448\n",
            "---> iteration:  133  partial loss: 0.051310576\n",
            "---> iteration:  134  partial loss: 0.013693611\n",
            "---> iteration:  135  partial loss: 0.045218956\n",
            "---> iteration:  136  partial loss: 0.02698804\n",
            "---> iteration:  137  partial loss: 0.05953948\n",
            "---> iteration:  138  partial loss: 0.015397937\n",
            "---> iteration:  139  partial loss: 0.041882202\n",
            "---> iteration:  140  partial loss: 0.096010536\n",
            "---> iteration:  141  partial loss: 0.053877544\n",
            "---> iteration:  142  partial loss: 0.019595284\n",
            "---> iteration:  143  partial loss: 0.05290787\n",
            "---> iteration:  144  partial loss: 0.019570647\n",
            "---> iteration:  145  partial loss: 0.04878212\n",
            "---> iteration:  146  partial loss: 0.051490884\n",
            "---> iteration:  147  partial loss: 0.036044206\n",
            "---> iteration:  148  partial loss: 0.03399547\n",
            "---> iteration:  149  partial loss: 0.029015241\n",
            "---> iteration:  150  partial loss: 0.02764415\n",
            "---> iteration:  151  partial loss: 0.0501233\n",
            "---> iteration:  152  partial loss: 0.047598198\n",
            "---> iteration:  153  partial loss: 0.021609087\n",
            "---> iteration:  154  partial loss: 0.048215825\n",
            "---> iteration:  155  partial loss: 0.030797713\n",
            "---> iteration:  156  partial loss: 0.018911686\n",
            "---> iteration:  157  partial loss: 0.02516968\n",
            "---> iteration:  158  partial loss: 0.02900851\n",
            "---> iteration:  159  partial loss: 0.024444781\n",
            "---> iteration:  160  partial loss: 0.024368646\n",
            "---> iteration:  161  partial loss: 0.04965373\n",
            "---> iteration:  162  partial loss: 0.047363624\n",
            "---> iteration:  163  partial loss: 0.045844607\n",
            "---> iteration:  164  partial loss: 0.07649618\n",
            "---> iteration:  165  partial loss: 0.043500155\n",
            "---> iteration:  166  partial loss: 0.02170114\n",
            "---> iteration:  167  partial loss: 0.04419194\n",
            "---> iteration:  168  partial loss: 0.04725267\n",
            "---> iteration:  169  partial loss: 0.064525805\n",
            "---> iteration:  170  partial loss: 0.05184617\n",
            "---> iteration:  171  partial loss: 0.058124427\n",
            "---> iteration:  172  partial loss: 0.04115443\n",
            "---> iteration:  173  partial loss: 0.04115492\n",
            "---> iteration:  174  partial loss: 0.016258316\n",
            "---> iteration:  175  partial loss: 0.046868723\n",
            "---> iteration:  176  partial loss: 0.035518844\n",
            "---> iteration:  177  partial loss: 0.106788\n",
            "---> iteration:  178  partial loss: 0.047584545\n",
            "---> iteration:  179  partial loss: 0.02119242\n",
            "---> iteration:  180  partial loss: 0.018824773\n",
            "---> iteration:  181  partial loss: 0.046312567\n",
            "---> iteration:  182  partial loss: 0.0659002\n",
            "---> iteration:  183  partial loss: 0.037885442\n",
            "---> iteration:  184  partial loss: 0.14238007\n",
            "---> iteration:  185  partial loss: 0.027450893\n",
            "---> iteration:  186  partial loss: 0.04324706\n",
            "---> iteration:  187  partial loss: 0.055616114\n",
            "---> iteration:  188  partial loss: 0.07996423\n",
            "---> iteration:  189  partial loss: 0.023305506\n",
            "---> iteration:  190  partial loss: 0.041370053\n",
            "---> iteration:  191  partial loss: 0.03805168\n",
            "---> iteration:  192  partial loss: 0.034216616\n",
            "---> iteration:  193  partial loss: 0.085739985\n",
            "---> iteration:  194  partial loss: 0.0349918\n",
            "---> iteration:  195  partial loss: 0.020016443\n",
            "---> iteration:  196  partial loss: 0.0945626\n",
            "---> iteration:  197  partial loss: 0.13741915\n",
            "---> iteration:  198  partial loss: 0.03676177\n",
            "---> iteration:  199  partial loss: 0.051166598\n",
            "---> iteration:  200  partial loss: 0.056209564\n",
            "---> iteration:  201  partial loss: 0.018024752\n",
            "---> iteration:  202  partial loss: 0.042474452\n",
            "---> iteration:  203  partial loss: 0.069568686\n",
            "---> iteration:  204  partial loss: 0.08988819\n",
            "---> iteration:  205  partial loss: 0.031066831\n",
            "---> iteration:  206  partial loss: 0.06331961\n",
            "---> iteration:  207  partial loss: 0.07000237\n",
            "---> iteration:  208  partial loss: 0.05296473\n",
            "---> iteration:  209  partial loss: 0.05868952\n",
            "---> iteration:  210  partial loss: 0.050617047\n",
            "---> iteration:  211  partial loss: 0.066859\n",
            "---> iteration:  212  partial loss: 0.05753398\n",
            "---> iteration:  213  partial loss: 0.020004325\n",
            "---> iteration:  214  partial loss: 0.041975647\n",
            "---> iteration:  215  partial loss: 0.04159208\n",
            "---> iteration:  216  partial loss: 0.016971173\n",
            "---> iteration:  217  partial loss: 0.039447088\n",
            "---> iteration:  218  partial loss: 0.03979752\n",
            "---> iteration:  219  partial loss: 0.021577511\n",
            "---> iteration:  220  partial loss: 0.013321736\n",
            "---> iteration:  221  partial loss: 0.024794163\n",
            "---> iteration:  222  partial loss: 0.044028964\n",
            "---> iteration:  223  partial loss: 0.05772247\n",
            "---> iteration:  224  partial loss: 0.032060772\n",
            "---> iteration:  225  partial loss: 0.06462453\n",
            "---> iteration:  226  partial loss: 0.055308633\n",
            "---> iteration:  227  partial loss: 0.03258985\n",
            "---> iteration:  228  partial loss: 0.035431813\n",
            "---> iteration:  229  partial loss: 0.08519355\n",
            "---> iteration:  230  partial loss: 0.03357386\n",
            "---> iteration:  231  partial loss: 0.024551738\n",
            "---> iteration:  232  partial loss: 0.018620817\n",
            "---> iteration:  233  partial loss: 0.06868021\n",
            "---> iteration:  234  partial loss: 0.06890265\n",
            "---> iteration:  235  partial loss: 0.048995793\n",
            "---> iteration:  236  partial loss: 0.058215734\n",
            "---> iteration:  237  partial loss: 0.04579632\n",
            "---> iteration:  238  partial loss: 0.0733504\n",
            "---> iteration:  239  partial loss: 0.07527382\n",
            "---> iteration:  240  partial loss: 0.048076555\n",
            "---> iteration:  241  partial loss: 0.07048668\n",
            "---> iteration:  242  partial loss: 0.020409925\n",
            "---> iteration:  243  partial loss: 0.028008312\n",
            "---> iteration:  244  partial loss: 0.017918918\n",
            "---> iteration:  245  partial loss: 0.02755125\n",
            "---> iteration:  246  partial loss: 0.03271257\n",
            "---> iteration:  247  partial loss: 0.057427887\n",
            "---> iteration:  248  partial loss: 0.03476143\n",
            "---> iteration:  249  partial loss: 0.0648557\n",
            "---> iteration:  250  partial loss: 0.036973376\n",
            "---> iteration:  251  partial loss: 0.027565142\n",
            "---> iteration:  252  partial loss: 0.038413886\n",
            "---> iteration:  253  partial loss: 0.062319733\n",
            "---> iteration:  254  partial loss: 0.04625179\n",
            "---> iteration:  255  partial loss: 0.027625285\n",
            "---> iteration:  256  partial loss: 0.036960676\n",
            "---> iteration:  257  partial loss: 0.0183339\n",
            "---> iteration:  258  partial loss: 0.059808478\n",
            "---> iteration:  259  partial loss: 0.03191147\n",
            "---> iteration:  260  partial loss: 0.072748266\n",
            "---> iteration:  261  partial loss: 0.015183086\n",
            "---> iteration:  262  partial loss: 0.029493866\n",
            "---> iteration:  263  partial loss: 0.07454454\n",
            "---> iteration:  264  partial loss: 0.038314126\n",
            "---> iteration:  265  partial loss: 0.026204813\n",
            "---> iteration:  266  partial loss: 0.02197058\n",
            "---> iteration:  267  partial loss: 0.07286297\n",
            "---> iteration:  268  partial loss: 0.026906973\n",
            "---> iteration:  269  partial loss: 0.02217449\n",
            "---> iteration:  270  partial loss: 0.032610286\n",
            "---> iteration:  271  partial loss: 0.018521177\n",
            "---> iteration:  272  partial loss: 0.061055247\n",
            "---> iteration:  273  partial loss: 0.017004058\n",
            "---> iteration:  274  partial loss: 0.022258522\n",
            "---> iteration:  275  partial loss: 0.09283691\n",
            "---> iteration:  276  partial loss: 0.08637234\n",
            "---> iteration:  277  partial loss: 0.109557495\n",
            "---> iteration:  278  partial loss: 0.038437877\n",
            "---> iteration:  279  partial loss: 0.092543155\n",
            "---> iteration:  280  partial loss: 0.027548485\n",
            "---> iteration:  281  partial loss: 0.045594428\n",
            "---> iteration:  282  partial loss: 0.021797832\n",
            "---> iteration:  283  partial loss: 0.08725599\n",
            "---> iteration:  284  partial loss: 0.027972499\n",
            "---> iteration:  285  partial loss: 0.08141577\n",
            "---> iteration:  286  partial loss: 0.030540077\n",
            "---> iteration:  287  partial loss: 0.07372795\n",
            "---> iteration:  288  partial loss: 0.018670788\n",
            "---> iteration:  289  partial loss: 0.052387778\n",
            "------------------\n",
            "epoch:  18  of  20 training loss:  0.048569228970622935\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.040857427\n",
            "---> iteration:  2  partial loss: 0.062897354\n",
            "---> iteration:  3  partial loss: 0.031147193\n",
            "---> iteration:  4  partial loss: 0.02106048\n",
            "---> iteration:  5  partial loss: 0.027673282\n",
            "---> iteration:  6  partial loss: 0.041267354\n",
            "---> iteration:  7  partial loss: 0.020237615\n",
            "---> iteration:  8  partial loss: 0.039204195\n",
            "---> iteration:  9  partial loss: 0.061083242\n",
            "---> iteration:  10  partial loss: 0.038836367\n",
            "---> iteration:  11  partial loss: 0.09504985\n",
            "---> iteration:  12  partial loss: 0.029102411\n",
            "---> iteration:  13  partial loss: 0.029141622\n",
            "---> iteration:  14  partial loss: 0.051159106\n",
            "---> iteration:  15  partial loss: 0.01760304\n",
            "---> iteration:  16  partial loss: 0.035984777\n",
            "---> iteration:  17  partial loss: 0.059404984\n",
            "---> iteration:  18  partial loss: 0.04393014\n",
            "---> iteration:  19  partial loss: 0.05436274\n",
            "---> iteration:  20  partial loss: 0.03735293\n",
            "---> iteration:  21  partial loss: 0.025993166\n",
            "---> iteration:  22  partial loss: 0.05418047\n",
            "---> iteration:  23  partial loss: 0.04914352\n",
            "---> iteration:  24  partial loss: 0.032823842\n",
            "---> iteration:  25  partial loss: 0.022592852\n",
            "---> iteration:  26  partial loss: 0.07271683\n",
            "---> iteration:  27  partial loss: 0.016452475\n",
            "---> iteration:  28  partial loss: 0.037201457\n",
            "---> iteration:  29  partial loss: 0.030376326\n",
            "---> iteration:  30  partial loss: 0.044221994\n",
            "---> iteration:  31  partial loss: 0.08718105\n",
            "---> iteration:  32  partial loss: 0.0739553\n",
            "---> iteration:  33  partial loss: 0.04083478\n",
            "---> iteration:  34  partial loss: 0.09656768\n",
            "---> iteration:  35  partial loss: 0.04074993\n",
            "---> iteration:  36  partial loss: 0.023678932\n",
            "---> iteration:  37  partial loss: 0.026360437\n",
            "---> iteration:  38  partial loss: 0.043306485\n",
            "---> iteration:  39  partial loss: 0.020703437\n",
            "---> iteration:  40  partial loss: 0.053202983\n",
            "---> iteration:  41  partial loss: 0.037924152\n",
            "---> iteration:  42  partial loss: 0.04941916\n",
            "---> iteration:  43  partial loss: 0.06743299\n",
            "---> iteration:  44  partial loss: 0.017032709\n",
            "---> iteration:  45  partial loss: 0.0241239\n",
            "---> iteration:  46  partial loss: 0.045208137\n",
            "---> iteration:  47  partial loss: 0.06246931\n",
            "---> iteration:  48  partial loss: 0.058280382\n",
            "---> iteration:  49  partial loss: 0.048138816\n",
            "---> iteration:  50  partial loss: 0.109808564\n",
            "---> iteration:  51  partial loss: 0.02099163\n",
            "---> iteration:  52  partial loss: 0.011807369\n",
            "---> iteration:  53  partial loss: 0.042155467\n",
            "---> iteration:  54  partial loss: 0.08475765\n",
            "---> iteration:  55  partial loss: 0.049052518\n",
            "---> iteration:  56  partial loss: 0.025740849\n",
            "---> iteration:  57  partial loss: 0.025442086\n",
            "---> iteration:  58  partial loss: 0.014529172\n",
            "---> iteration:  59  partial loss: 0.074508786\n",
            "---> iteration:  60  partial loss: 0.068940096\n",
            "---> iteration:  61  partial loss: 0.06542635\n",
            "---> iteration:  62  partial loss: 0.04390365\n",
            "---> iteration:  63  partial loss: 0.04312565\n",
            "---> iteration:  64  partial loss: 0.089107595\n",
            "---> iteration:  65  partial loss: 0.06196518\n",
            "---> iteration:  66  partial loss: 0.042094436\n",
            "---> iteration:  67  partial loss: 0.019418798\n",
            "---> iteration:  68  partial loss: 0.028290737\n",
            "---> iteration:  69  partial loss: 0.053543203\n",
            "---> iteration:  70  partial loss: 0.07522811\n",
            "---> iteration:  71  partial loss: 0.030665396\n",
            "---> iteration:  72  partial loss: 0.03000461\n",
            "---> iteration:  73  partial loss: 0.0369115\n",
            "---> iteration:  74  partial loss: 0.06737074\n",
            "---> iteration:  75  partial loss: 0.014949626\n",
            "---> iteration:  76  partial loss: 0.03183385\n",
            "---> iteration:  77  partial loss: 0.071195155\n",
            "---> iteration:  78  partial loss: 0.05453697\n",
            "---> iteration:  79  partial loss: 0.018102601\n",
            "---> iteration:  80  partial loss: 0.04828217\n",
            "---> iteration:  81  partial loss: 0.035908073\n",
            "---> iteration:  82  partial loss: 0.051812097\n",
            "---> iteration:  83  partial loss: 0.05985542\n",
            "---> iteration:  84  partial loss: 0.036317848\n",
            "---> iteration:  85  partial loss: 0.035218004\n",
            "---> iteration:  86  partial loss: 0.016508741\n",
            "---> iteration:  87  partial loss: 0.0151418345\n",
            "---> iteration:  88  partial loss: 0.09074572\n",
            "---> iteration:  89  partial loss: 0.044903815\n",
            "---> iteration:  90  partial loss: 0.013325469\n",
            "---> iteration:  91  partial loss: 0.022705957\n",
            "---> iteration:  92  partial loss: 0.07510248\n",
            "---> iteration:  93  partial loss: 0.023194026\n",
            "---> iteration:  94  partial loss: 0.02372083\n",
            "---> iteration:  95  partial loss: 0.019096125\n",
            "---> iteration:  96  partial loss: 0.069422044\n",
            "---> iteration:  97  partial loss: 0.016583186\n",
            "---> iteration:  98  partial loss: 0.017309811\n",
            "---> iteration:  99  partial loss: 0.024250481\n",
            "---> iteration:  100  partial loss: 0.027198775\n",
            "---> iteration:  101  partial loss: 0.06239532\n",
            "---> iteration:  102  partial loss: 0.05093192\n",
            "---> iteration:  103  partial loss: 0.050295364\n",
            "---> iteration:  104  partial loss: 0.027798636\n",
            "---> iteration:  105  partial loss: 0.020830711\n",
            "---> iteration:  106  partial loss: 0.058325067\n",
            "---> iteration:  107  partial loss: 0.033961516\n",
            "---> iteration:  108  partial loss: 0.041552227\n",
            "---> iteration:  109  partial loss: 0.04830256\n",
            "---> iteration:  110  partial loss: 0.035519328\n",
            "---> iteration:  111  partial loss: 0.016866146\n",
            "---> iteration:  112  partial loss: 0.055049907\n",
            "---> iteration:  113  partial loss: 0.040801007\n",
            "---> iteration:  114  partial loss: 0.048565887\n",
            "---> iteration:  115  partial loss: 0.04282891\n",
            "---> iteration:  116  partial loss: 0.041786995\n",
            "---> iteration:  117  partial loss: 0.032366842\n",
            "---> iteration:  118  partial loss: 0.030286958\n",
            "---> iteration:  119  partial loss: 0.04035047\n",
            "---> iteration:  120  partial loss: 0.041424096\n",
            "---> iteration:  121  partial loss: 0.064055294\n",
            "---> iteration:  122  partial loss: 0.05756283\n",
            "---> iteration:  123  partial loss: 0.018582117\n",
            "---> iteration:  124  partial loss: 0.02994909\n",
            "---> iteration:  125  partial loss: 0.049766917\n",
            "---> iteration:  126  partial loss: 0.11705303\n",
            "---> iteration:  127  partial loss: 0.10286783\n",
            "---> iteration:  128  partial loss: 0.031808913\n",
            "---> iteration:  129  partial loss: 0.075946696\n",
            "---> iteration:  130  partial loss: 0.06794408\n",
            "---> iteration:  131  partial loss: 0.042402033\n",
            "---> iteration:  132  partial loss: 0.02881343\n",
            "---> iteration:  133  partial loss: 0.055688493\n",
            "---> iteration:  134  partial loss: 0.030318767\n",
            "---> iteration:  135  partial loss: 0.051331077\n",
            "---> iteration:  136  partial loss: 0.049676854\n",
            "---> iteration:  137  partial loss: 0.045888837\n",
            "---> iteration:  138  partial loss: 0.03757513\n",
            "---> iteration:  139  partial loss: 0.021843541\n",
            "---> iteration:  140  partial loss: 0.022267014\n",
            "---> iteration:  141  partial loss: 0.023075555\n",
            "---> iteration:  142  partial loss: 0.029266113\n",
            "---> iteration:  143  partial loss: 0.043051906\n",
            "---> iteration:  144  partial loss: 0.023290824\n",
            "---> iteration:  145  partial loss: 0.051452465\n",
            "---> iteration:  146  partial loss: 0.014617398\n",
            "---> iteration:  147  partial loss: 0.022644201\n",
            "---> iteration:  148  partial loss: 0.045176033\n",
            "---> iteration:  149  partial loss: 0.016635044\n",
            "---> iteration:  150  partial loss: 0.03145633\n",
            "---> iteration:  151  partial loss: 0.022926932\n",
            "---> iteration:  152  partial loss: 0.020389356\n",
            "---> iteration:  153  partial loss: 0.04104864\n",
            "---> iteration:  154  partial loss: 0.042668346\n",
            "---> iteration:  155  partial loss: 0.03330928\n",
            "---> iteration:  156  partial loss: 0.04469007\n",
            "---> iteration:  157  partial loss: 0.13910457\n",
            "---> iteration:  158  partial loss: 0.026440023\n",
            "---> iteration:  159  partial loss: 0.06853713\n",
            "---> iteration:  160  partial loss: 0.06245292\n",
            "---> iteration:  161  partial loss: 0.060625933\n",
            "---> iteration:  162  partial loss: 0.028048912\n",
            "---> iteration:  163  partial loss: 0.04504406\n",
            "---> iteration:  164  partial loss: 0.04731547\n",
            "---> iteration:  165  partial loss: 0.034296308\n",
            "---> iteration:  166  partial loss: 0.021998137\n",
            "---> iteration:  167  partial loss: 0.04554925\n",
            "---> iteration:  168  partial loss: 0.0176979\n",
            "---> iteration:  169  partial loss: 0.046746016\n",
            "---> iteration:  170  partial loss: 0.023724416\n",
            "---> iteration:  171  partial loss: 0.042337634\n",
            "---> iteration:  172  partial loss: 0.041757897\n",
            "---> iteration:  173  partial loss: 0.10266364\n",
            "---> iteration:  174  partial loss: 0.023766277\n",
            "---> iteration:  175  partial loss: 0.058077045\n",
            "---> iteration:  176  partial loss: 0.012635847\n",
            "---> iteration:  177  partial loss: 0.043450896\n",
            "---> iteration:  178  partial loss: 0.019697793\n",
            "---> iteration:  179  partial loss: 0.065791056\n",
            "---> iteration:  180  partial loss: 0.01929464\n",
            "---> iteration:  181  partial loss: 0.045478918\n",
            "---> iteration:  182  partial loss: 0.021171663\n",
            "---> iteration:  183  partial loss: 0.059193008\n",
            "---> iteration:  184  partial loss: 0.06826898\n",
            "---> iteration:  185  partial loss: 0.04007345\n",
            "---> iteration:  186  partial loss: 0.017622292\n",
            "---> iteration:  187  partial loss: 0.016511189\n",
            "---> iteration:  188  partial loss: 0.082032196\n",
            "---> iteration:  189  partial loss: 0.028080584\n",
            "---> iteration:  190  partial loss: 0.031448305\n",
            "---> iteration:  191  partial loss: 0.041714963\n",
            "---> iteration:  192  partial loss: 0.042343944\n",
            "---> iteration:  193  partial loss: 0.04460913\n",
            "---> iteration:  194  partial loss: 0.01340991\n",
            "---> iteration:  195  partial loss: 0.046297878\n",
            "---> iteration:  196  partial loss: 0.043553703\n",
            "---> iteration:  197  partial loss: 0.03274322\n",
            "---> iteration:  198  partial loss: 0.1201618\n",
            "---> iteration:  199  partial loss: 0.08934081\n",
            "---> iteration:  200  partial loss: 0.049527943\n",
            "---> iteration:  201  partial loss: 0.024276631\n",
            "---> iteration:  202  partial loss: 0.029613476\n",
            "---> iteration:  203  partial loss: 0.015995163\n",
            "---> iteration:  204  partial loss: 0.050549094\n",
            "---> iteration:  205  partial loss: 0.04840081\n",
            "---> iteration:  206  partial loss: 0.028693637\n",
            "---> iteration:  207  partial loss: 0.021840166\n",
            "---> iteration:  208  partial loss: 0.05146958\n",
            "---> iteration:  209  partial loss: 0.07448892\n",
            "---> iteration:  210  partial loss: 0.02129987\n",
            "---> iteration:  211  partial loss: 0.0147565\n",
            "---> iteration:  212  partial loss: 0.019752163\n",
            "---> iteration:  213  partial loss: 0.07052707\n",
            "---> iteration:  214  partial loss: 0.10818549\n",
            "---> iteration:  215  partial loss: 0.06357155\n",
            "---> iteration:  216  partial loss: 0.029737337\n",
            "---> iteration:  217  partial loss: 0.067498565\n",
            "---> iteration:  218  partial loss: 0.051267877\n",
            "---> iteration:  219  partial loss: 0.030814918\n",
            "---> iteration:  220  partial loss: 0.022984754\n",
            "---> iteration:  221  partial loss: 0.05552969\n",
            "---> iteration:  222  partial loss: 0.01957778\n",
            "---> iteration:  223  partial loss: 0.040029403\n",
            "---> iteration:  224  partial loss: 0.07263947\n",
            "---> iteration:  225  partial loss: 0.056340355\n",
            "---> iteration:  226  partial loss: 0.065258384\n",
            "---> iteration:  227  partial loss: 0.02306076\n",
            "---> iteration:  228  partial loss: 0.013334122\n",
            "---> iteration:  229  partial loss: 0.035880394\n",
            "---> iteration:  230  partial loss: 0.08107302\n",
            "---> iteration:  231  partial loss: 0.025018983\n",
            "---> iteration:  232  partial loss: 0.023344299\n",
            "---> iteration:  233  partial loss: 0.17189549\n",
            "---> iteration:  234  partial loss: 0.07884325\n",
            "---> iteration:  235  partial loss: 0.03554161\n",
            "---> iteration:  236  partial loss: 0.018749746\n",
            "---> iteration:  237  partial loss: 0.022712179\n",
            "---> iteration:  238  partial loss: 0.04529476\n",
            "---> iteration:  239  partial loss: 0.024160266\n",
            "---> iteration:  240  partial loss: 0.047440927\n",
            "---> iteration:  241  partial loss: 0.032332607\n",
            "---> iteration:  242  partial loss: 0.038127385\n",
            "---> iteration:  243  partial loss: 0.032448586\n",
            "---> iteration:  244  partial loss: 0.029745668\n",
            "---> iteration:  245  partial loss: 0.02448687\n",
            "---> iteration:  246  partial loss: 0.041765135\n",
            "---> iteration:  247  partial loss: 0.049552076\n",
            "---> iteration:  248  partial loss: 0.025432745\n",
            "---> iteration:  249  partial loss: 0.017961234\n",
            "---> iteration:  250  partial loss: 0.08585929\n",
            "---> iteration:  251  partial loss: 0.061468285\n",
            "---> iteration:  252  partial loss: 0.07089196\n",
            "---> iteration:  253  partial loss: 0.06442091\n",
            "---> iteration:  254  partial loss: 0.015637776\n",
            "---> iteration:  255  partial loss: 0.037175238\n",
            "---> iteration:  256  partial loss: 0.03375185\n",
            "---> iteration:  257  partial loss: 0.02990353\n",
            "---> iteration:  258  partial loss: 0.020223517\n",
            "---> iteration:  259  partial loss: 0.030325338\n",
            "---> iteration:  260  partial loss: 0.015624956\n",
            "---> iteration:  261  partial loss: 0.041193996\n",
            "---> iteration:  262  partial loss: 0.013941468\n",
            "---> iteration:  263  partial loss: 0.054390278\n",
            "---> iteration:  264  partial loss: 0.033079695\n",
            "---> iteration:  265  partial loss: 0.047632545\n",
            "---> iteration:  266  partial loss: 0.054623775\n",
            "---> iteration:  267  partial loss: 0.021194346\n",
            "---> iteration:  268  partial loss: 0.049531154\n",
            "---> iteration:  269  partial loss: 0.059549883\n",
            "---> iteration:  270  partial loss: 0.04733091\n",
            "---> iteration:  271  partial loss: 0.026609654\n",
            "---> iteration:  272  partial loss: 0.02610399\n",
            "---> iteration:  273  partial loss: 0.0516326\n",
            "---> iteration:  274  partial loss: 0.0714331\n",
            "---> iteration:  275  partial loss: 0.05471873\n",
            "---> iteration:  276  partial loss: 0.055401698\n",
            "---> iteration:  277  partial loss: 0.040489193\n",
            "---> iteration:  278  partial loss: 0.044342127\n",
            "---> iteration:  279  partial loss: 0.051005956\n",
            "---> iteration:  280  partial loss: 0.055171274\n",
            "---> iteration:  281  partial loss: 0.034745533\n",
            "---> iteration:  282  partial loss: 0.06079731\n",
            "---> iteration:  283  partial loss: 0.037477396\n",
            "---> iteration:  284  partial loss: 0.07631088\n",
            "---> iteration:  285  partial loss: 0.03418365\n",
            "---> iteration:  286  partial loss: 0.05617784\n",
            "---> iteration:  287  partial loss: 0.032078344\n",
            "---> iteration:  288  partial loss: 0.071836405\n",
            "---> iteration:  289  partial loss: 0.06079855\n",
            "------------------\n",
            "epoch:  19  of  20 training loss:  0.04357067321565737\n",
            "------------------\n",
            "---> iteration:  1  partial loss: 0.053585645\n",
            "---> iteration:  2  partial loss: 0.03616045\n",
            "---> iteration:  3  partial loss: 0.019427167\n",
            "---> iteration:  4  partial loss: 0.017410466\n",
            "---> iteration:  5  partial loss: 0.07901819\n",
            "---> iteration:  6  partial loss: 0.029282847\n",
            "---> iteration:  7  partial loss: 0.06532577\n",
            "---> iteration:  8  partial loss: 0.024200326\n",
            "---> iteration:  9  partial loss: 0.02602436\n",
            "---> iteration:  10  partial loss: 0.023548074\n",
            "---> iteration:  11  partial loss: 0.048635446\n",
            "---> iteration:  12  partial loss: 0.042271342\n",
            "---> iteration:  13  partial loss: 0.1135192\n",
            "---> iteration:  14  partial loss: 0.020535817\n",
            "---> iteration:  15  partial loss: 0.029277794\n",
            "---> iteration:  16  partial loss: 0.021313546\n",
            "---> iteration:  17  partial loss: 0.041608047\n",
            "---> iteration:  18  partial loss: 0.04142734\n",
            "---> iteration:  19  partial loss: 0.03187048\n",
            "---> iteration:  20  partial loss: 0.027497478\n",
            "---> iteration:  21  partial loss: 0.047241263\n",
            "---> iteration:  22  partial loss: 0.0450774\n",
            "---> iteration:  23  partial loss: 0.014418847\n",
            "---> iteration:  24  partial loss: 0.023562144\n",
            "---> iteration:  25  partial loss: 0.049471192\n",
            "---> iteration:  26  partial loss: 0.049823765\n",
            "---> iteration:  27  partial loss: 0.054969683\n",
            "---> iteration:  28  partial loss: 0.043076657\n",
            "---> iteration:  29  partial loss: 0.041654486\n",
            "---> iteration:  30  partial loss: 0.01778135\n",
            "---> iteration:  31  partial loss: 0.013047442\n",
            "---> iteration:  32  partial loss: 0.04453465\n",
            "---> iteration:  33  partial loss: 0.015779145\n",
            "---> iteration:  34  partial loss: 0.022563433\n",
            "---> iteration:  35  partial loss: 0.0215219\n",
            "---> iteration:  36  partial loss: 0.056817226\n",
            "---> iteration:  37  partial loss: 0.033982735\n",
            "---> iteration:  38  partial loss: 0.022680601\n",
            "---> iteration:  39  partial loss: 0.02660603\n",
            "---> iteration:  40  partial loss: 0.03024989\n",
            "---> iteration:  41  partial loss: 0.040329494\n",
            "---> iteration:  42  partial loss: 0.05796006\n",
            "---> iteration:  43  partial loss: 0.047105264\n",
            "---> iteration:  44  partial loss: 0.021821134\n",
            "---> iteration:  45  partial loss: 0.032924723\n",
            "---> iteration:  46  partial loss: 0.023823664\n",
            "---> iteration:  47  partial loss: 0.031173486\n",
            "---> iteration:  48  partial loss: 0.013685085\n",
            "---> iteration:  49  partial loss: 0.04131605\n",
            "---> iteration:  50  partial loss: 0.05847846\n",
            "---> iteration:  51  partial loss: 0.04736755\n",
            "---> iteration:  52  partial loss: 0.036760483\n",
            "---> iteration:  53  partial loss: 0.01875472\n",
            "---> iteration:  54  partial loss: 0.038418032\n",
            "---> iteration:  55  partial loss: 0.049881246\n",
            "---> iteration:  56  partial loss: 0.06466164\n",
            "---> iteration:  57  partial loss: 0.097814366\n",
            "---> iteration:  58  partial loss: 0.031058306\n",
            "---> iteration:  59  partial loss: 0.05805026\n",
            "---> iteration:  60  partial loss: 0.05217291\n",
            "---> iteration:  61  partial loss: 0.0363005\n",
            "---> iteration:  62  partial loss: 0.10000576\n",
            "---> iteration:  63  partial loss: 0.05179617\n",
            "---> iteration:  64  partial loss: 0.040267818\n",
            "---> iteration:  65  partial loss: 0.06384445\n",
            "---> iteration:  66  partial loss: 0.0146970255\n",
            "---> iteration:  67  partial loss: 0.048882995\n",
            "---> iteration:  68  partial loss: 0.060340215\n",
            "---> iteration:  69  partial loss: 0.050472658\n",
            "---> iteration:  70  partial loss: 0.016542645\n",
            "---> iteration:  71  partial loss: 0.07658341\n",
            "---> iteration:  72  partial loss: 0.021318745\n",
            "---> iteration:  73  partial loss: 0.044254236\n",
            "---> iteration:  74  partial loss: 0.023507135\n",
            "---> iteration:  75  partial loss: 0.03150109\n",
            "---> iteration:  76  partial loss: 0.057815563\n",
            "---> iteration:  77  partial loss: 0.021376804\n",
            "---> iteration:  78  partial loss: 0.03909856\n",
            "---> iteration:  79  partial loss: 0.027097948\n",
            "---> iteration:  80  partial loss: 0.04618719\n",
            "---> iteration:  81  partial loss: 0.026567038\n",
            "---> iteration:  82  partial loss: 0.06421051\n",
            "---> iteration:  83  partial loss: 0.055368107\n",
            "---> iteration:  84  partial loss: 0.051797412\n",
            "---> iteration:  85  partial loss: 0.03366009\n",
            "---> iteration:  86  partial loss: 0.042385455\n",
            "---> iteration:  87  partial loss: 0.04645418\n",
            "---> iteration:  88  partial loss: 0.025032196\n",
            "---> iteration:  89  partial loss: 0.024405316\n",
            "---> iteration:  90  partial loss: 0.028931549\n",
            "---> iteration:  91  partial loss: 0.04847316\n",
            "---> iteration:  92  partial loss: 0.03568005\n",
            "---> iteration:  93  partial loss: 0.066842414\n",
            "---> iteration:  94  partial loss: 0.07945984\n",
            "---> iteration:  95  partial loss: 0.02382232\n",
            "---> iteration:  96  partial loss: 0.062191524\n",
            "---> iteration:  97  partial loss: 0.1374318\n",
            "---> iteration:  98  partial loss: 0.043260083\n",
            "---> iteration:  99  partial loss: 0.029044326\n",
            "---> iteration:  100  partial loss: 0.065722644\n",
            "---> iteration:  101  partial loss: 0.024802055\n",
            "---> iteration:  102  partial loss: 0.06463078\n",
            "---> iteration:  103  partial loss: 0.044022225\n",
            "---> iteration:  104  partial loss: 0.04571917\n",
            "---> iteration:  105  partial loss: 0.03599478\n",
            "---> iteration:  106  partial loss: 0.064929314\n",
            "---> iteration:  107  partial loss: 0.015335556\n",
            "---> iteration:  108  partial loss: 0.045413293\n",
            "---> iteration:  109  partial loss: 0.043878105\n",
            "---> iteration:  110  partial loss: 0.024579726\n",
            "---> iteration:  111  partial loss: 0.0259049\n",
            "---> iteration:  112  partial loss: 0.027502192\n",
            "---> iteration:  113  partial loss: 0.029821929\n",
            "---> iteration:  114  partial loss: 0.027085254\n",
            "---> iteration:  115  partial loss: 0.033248812\n",
            "---> iteration:  116  partial loss: 0.017938497\n",
            "---> iteration:  117  partial loss: 0.045421954\n",
            "---> iteration:  118  partial loss: 0.03333714\n",
            "---> iteration:  119  partial loss: 0.018374436\n",
            "---> iteration:  120  partial loss: 0.03457956\n",
            "---> iteration:  121  partial loss: 0.032940082\n",
            "---> iteration:  122  partial loss: 0.027610885\n",
            "---> iteration:  123  partial loss: 0.07170428\n",
            "---> iteration:  124  partial loss: 0.030281004\n",
            "---> iteration:  125  partial loss: 0.046855226\n",
            "---> iteration:  126  partial loss: 0.019113453\n",
            "---> iteration:  127  partial loss: 0.020977534\n",
            "---> iteration:  128  partial loss: 0.12360043\n",
            "---> iteration:  129  partial loss: 0.035665337\n",
            "---> iteration:  130  partial loss: 0.05235171\n",
            "---> iteration:  131  partial loss: 0.033123195\n",
            "---> iteration:  132  partial loss: 0.02153411\n",
            "---> iteration:  133  partial loss: 0.05087584\n",
            "---> iteration:  134  partial loss: 0.043847736\n",
            "---> iteration:  135  partial loss: 0.033836465\n",
            "---> iteration:  136  partial loss: 0.06455446\n",
            "---> iteration:  137  partial loss: 0.025529332\n",
            "---> iteration:  138  partial loss: 0.047282018\n",
            "---> iteration:  139  partial loss: 0.036175065\n",
            "---> iteration:  140  partial loss: 0.045054287\n",
            "---> iteration:  141  partial loss: 0.041399375\n",
            "---> iteration:  142  partial loss: 0.054501746\n",
            "---> iteration:  143  partial loss: 0.028467989\n",
            "---> iteration:  144  partial loss: 0.010979559\n",
            "---> iteration:  145  partial loss: 0.06536765\n",
            "---> iteration:  146  partial loss: 0.028945396\n",
            "---> iteration:  147  partial loss: 0.039170075\n",
            "---> iteration:  148  partial loss: 0.016941167\n",
            "---> iteration:  149  partial loss: 0.10198442\n",
            "---> iteration:  150  partial loss: 0.029515155\n",
            "---> iteration:  151  partial loss: 0.03089855\n",
            "---> iteration:  152  partial loss: 0.049997117\n",
            "---> iteration:  153  partial loss: 0.047955547\n",
            "---> iteration:  154  partial loss: 0.065245606\n",
            "---> iteration:  155  partial loss: 0.03195344\n",
            "---> iteration:  156  partial loss: 0.03619241\n",
            "---> iteration:  157  partial loss: 0.03714897\n",
            "---> iteration:  158  partial loss: 0.018018208\n",
            "---> iteration:  159  partial loss: 0.06643986\n",
            "---> iteration:  160  partial loss: 0.03754769\n",
            "---> iteration:  161  partial loss: 0.034619227\n",
            "---> iteration:  162  partial loss: 0.059085608\n",
            "---> iteration:  163  partial loss: 0.021997077\n",
            "---> iteration:  164  partial loss: 0.04604829\n",
            "---> iteration:  165  partial loss: 0.07215189\n",
            "---> iteration:  166  partial loss: 0.015126708\n",
            "---> iteration:  167  partial loss: 0.037261266\n",
            "---> iteration:  168  partial loss: 0.0139972\n",
            "---> iteration:  169  partial loss: 0.046550624\n",
            "---> iteration:  170  partial loss: 0.02524903\n",
            "---> iteration:  171  partial loss: 0.01531392\n",
            "---> iteration:  172  partial loss: 0.069548436\n",
            "---> iteration:  173  partial loss: 0.07300965\n",
            "---> iteration:  174  partial loss: 0.020997606\n",
            "---> iteration:  175  partial loss: 0.024115693\n",
            "---> iteration:  176  partial loss: 0.08587827\n",
            "---> iteration:  177  partial loss: 0.02907203\n",
            "---> iteration:  178  partial loss: 0.069393165\n",
            "---> iteration:  179  partial loss: 0.01956442\n",
            "---> iteration:  180  partial loss: 0.021886358\n",
            "---> iteration:  181  partial loss: 0.025175156\n",
            "---> iteration:  182  partial loss: 0.013853694\n",
            "---> iteration:  183  partial loss: 0.029787721\n",
            "---> iteration:  184  partial loss: 0.024111021\n",
            "---> iteration:  185  partial loss: 0.07380661\n",
            "---> iteration:  186  partial loss: 0.033573322\n",
            "---> iteration:  187  partial loss: 0.04656482\n",
            "---> iteration:  188  partial loss: 0.056424692\n",
            "---> iteration:  189  partial loss: 0.021664603\n",
            "---> iteration:  190  partial loss: 0.08496198\n",
            "---> iteration:  191  partial loss: 0.024279928\n",
            "---> iteration:  192  partial loss: 0.021611065\n",
            "---> iteration:  193  partial loss: 0.016797023\n",
            "---> iteration:  194  partial loss: 0.017755296\n",
            "---> iteration:  195  partial loss: 0.022399442\n",
            "---> iteration:  196  partial loss: 0.08566128\n",
            "---> iteration:  197  partial loss: 0.041759104\n",
            "---> iteration:  198  partial loss: 0.061195616\n",
            "---> iteration:  199  partial loss: 0.048571672\n",
            "---> iteration:  200  partial loss: 0.064371176\n",
            "---> iteration:  201  partial loss: 0.068047345\n",
            "---> iteration:  202  partial loss: 0.02878181\n",
            "---> iteration:  203  partial loss: 0.019222302\n",
            "---> iteration:  204  partial loss: 0.0322729\n",
            "---> iteration:  205  partial loss: 0.053248204\n",
            "---> iteration:  206  partial loss: 0.029819703\n",
            "---> iteration:  207  partial loss: 0.0661647\n",
            "---> iteration:  208  partial loss: 0.04428953\n",
            "---> iteration:  209  partial loss: 0.044020265\n",
            "---> iteration:  210  partial loss: 0.060473546\n",
            "---> iteration:  211  partial loss: 0.03712839\n",
            "---> iteration:  212  partial loss: 0.034357592\n",
            "---> iteration:  213  partial loss: 0.06540771\n",
            "---> iteration:  214  partial loss: 0.041860066\n",
            "---> iteration:  215  partial loss: 0.06963412\n",
            "---> iteration:  216  partial loss: 0.014874461\n",
            "---> iteration:  217  partial loss: 0.037760995\n",
            "---> iteration:  218  partial loss: 0.050956048\n",
            "---> iteration:  219  partial loss: 0.023471324\n",
            "---> iteration:  220  partial loss: 0.024630027\n",
            "---> iteration:  221  partial loss: 0.019452674\n",
            "---> iteration:  222  partial loss: 0.021191634\n",
            "---> iteration:  223  partial loss: 0.045691088\n",
            "---> iteration:  224  partial loss: 0.022648774\n",
            "---> iteration:  225  partial loss: 0.04389712\n",
            "---> iteration:  226  partial loss: 0.014137863\n",
            "---> iteration:  227  partial loss: 0.06283957\n",
            "---> iteration:  228  partial loss: 0.0356724\n",
            "---> iteration:  229  partial loss: 0.06453578\n",
            "---> iteration:  230  partial loss: 0.042586055\n",
            "---> iteration:  231  partial loss: 0.034287926\n",
            "---> iteration:  232  partial loss: 0.06384149\n",
            "---> iteration:  233  partial loss: 0.040102456\n",
            "---> iteration:  234  partial loss: 0.031725403\n",
            "---> iteration:  235  partial loss: 0.01921508\n",
            "---> iteration:  236  partial loss: 0.024630753\n",
            "---> iteration:  237  partial loss: 0.053304747\n",
            "---> iteration:  238  partial loss: 0.08528737\n",
            "---> iteration:  239  partial loss: 0.12499719\n",
            "---> iteration:  240  partial loss: 0.01650996\n",
            "---> iteration:  241  partial loss: 0.03674414\n",
            "---> iteration:  242  partial loss: 0.013475283\n",
            "---> iteration:  243  partial loss: 0.021810606\n",
            "---> iteration:  244  partial loss: 0.05003909\n",
            "---> iteration:  245  partial loss: 0.01905681\n",
            "---> iteration:  246  partial loss: 0.026919698\n",
            "---> iteration:  247  partial loss: 0.05230679\n",
            "---> iteration:  248  partial loss: 0.071245536\n",
            "---> iteration:  249  partial loss: 0.016405934\n",
            "---> iteration:  250  partial loss: 0.030149458\n",
            "---> iteration:  251  partial loss: 0.0385684\n",
            "---> iteration:  252  partial loss: 0.06792913\n",
            "---> iteration:  253  partial loss: 0.048362635\n",
            "---> iteration:  254  partial loss: 0.01196786\n",
            "---> iteration:  255  partial loss: 0.033006262\n",
            "---> iteration:  256  partial loss: 0.04975872\n",
            "---> iteration:  257  partial loss: 0.043381996\n",
            "---> iteration:  258  partial loss: 0.043691814\n",
            "---> iteration:  259  partial loss: 0.044631682\n",
            "---> iteration:  260  partial loss: 0.052518748\n",
            "---> iteration:  261  partial loss: 0.019740447\n",
            "---> iteration:  262  partial loss: 0.026347373\n",
            "---> iteration:  263  partial loss: 0.06332906\n",
            "---> iteration:  264  partial loss: 0.06613581\n",
            "---> iteration:  265  partial loss: 0.016462231\n",
            "---> iteration:  266  partial loss: 0.014895896\n",
            "---> iteration:  267  partial loss: 0.039669923\n",
            "---> iteration:  268  partial loss: 0.017046005\n",
            "---> iteration:  269  partial loss: 0.03978715\n",
            "---> iteration:  270  partial loss: 0.0386221\n",
            "---> iteration:  271  partial loss: 0.061232544\n",
            "---> iteration:  272  partial loss: 0.024729202\n",
            "---> iteration:  273  partial loss: 0.03475912\n",
            "---> iteration:  274  partial loss: 0.06469475\n",
            "---> iteration:  275  partial loss: 0.025635995\n",
            "---> iteration:  276  partial loss: 0.03487125\n",
            "---> iteration:  277  partial loss: 0.019776123\n",
            "---> iteration:  278  partial loss: 0.042151585\n",
            "---> iteration:  279  partial loss: 0.053701326\n",
            "---> iteration:  280  partial loss: 0.017979898\n",
            "---> iteration:  281  partial loss: 0.019273525\n",
            "---> iteration:  282  partial loss: 0.027195003\n",
            "---> iteration:  283  partial loss: 0.028497253\n",
            "---> iteration:  284  partial loss: 0.059405264\n",
            "---> iteration:  285  partial loss: 0.05072067\n",
            "---> iteration:  286  partial loss: 0.019513858\n",
            "---> iteration:  287  partial loss: 0.01709039\n",
            "---> iteration:  288  partial loss: 0.030415786\n",
            "---> iteration:  289  partial loss: 0.021536421\n",
            "------------------\n",
            "epoch:  20  of  20 training loss:  0.04045828421854746\n",
            "------------------\n",
            "Training Finished. Saving test images to: ./runs/1542998131.3562002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "ntLLzcRsT95G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "82342fa7-3551-4973-c459-26702c6849a8"
      },
      "cell_type": "code",
      "source": [
        "all_training_losses"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3864147978670456,\n",
              " 0.5864714098430422,\n",
              " 0.2810078793331001,\n",
              " 0.20897125022221602,\n",
              " 0.1675355089087181,\n",
              " 0.14571132211846052,\n",
              " 0.12593279903993063,\n",
              " 0.1125898343546374,\n",
              " 0.09757398710840713,\n",
              " 0.08638471780041922,\n",
              " 0.07825098389753214,\n",
              " 0.0667007923139111,\n",
              " 0.06830250870139953,\n",
              " 0.069513045322266,\n",
              " 0.058692295287951675,\n",
              " 0.07535435807179003,\n",
              " 0.05775839519915799,\n",
              " 0.048569228970622935,\n",
              " 0.04357067321565737,\n",
              " 0.04045828421854746]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "fCKQXuX24F25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e3906b84-2bfe-4601-d17d-6ffcedfd0a37"
      },
      "cell_type": "code",
      "source": [
        "!zip ./runs/1542998131.3562002"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tzip warning: missing end signature--probably not a zip file (did you\n",
            "\tzip warning: remember to use binary mode when you transferred it?)\n",
            "\tzip warning: (if you are trying to read a damaged archive try -F)\n",
            "\n",
            "zip error: Zip file structure invalid (./runs/1542998131.3562002)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VY6l9YF06CSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9e8c50ac-2126-432a-fad9-0799bba1b7ee"
      },
      "cell_type": "code",
      "source": [
        "!zip ."
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tzip warning: missing end signature--probably not a zip file (did you\n",
            "\tzip warning: remember to use binary mode when you transferred it?)\n",
            "\tzip warning: (if you are trying to read a damaged archive try -F)\n",
            "\n",
            "zip error: Zip file structure invalid (.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YOSWos8Q4fGQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b7740ca2-4b4f-4f93-fd63-efb41cba5d03"
      },
      "cell_type": "code",
      "source": [
        "!git add"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "zip error: Nothing to do! (data_road.zip)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hoarxyjY5Axs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}